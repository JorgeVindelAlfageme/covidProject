## 1) dendGen():

# dendGen() functions produces a dendrogram which distance measure calculation
# and clustering method can be selected. After that, the generated object can
# be plotted.

dendGen <- function(scaledData, distMethod = "correlation", linkMethod = "complete"){
  if(distMethod == "euclidean" | distMethod == "manhattan"){
    distance <- dist(x = t(scaledData), method = distMethod)
  }
  if(distMethod == "correlation"){
    distance <- as.dist((1-cor(x = scaledData, use = "pairwise.complete.obs"))/2)
  }
  dendrogram <- hclust(d = distance, method = linkMethod)
  return(dendrogram)
}

dendA <- dendGen(scaledData = scData, distMethod = "correlation", linkMethod = "average")
dendB <- dendGen(scaledData = scData, distMethod = "manhattan", linkMethod = "complete")

## 2) dendPlot():

# It represents a dendrogram previously generated by dendGen().

dendPlot <- function(dend){
  if(is.null(dend$dist.method)){
    dend$dist.method <- "correlation"
  }
  plot(dend, xlab = paste0("Distance: ", dend$dist.method, ".", sep = ""),
       sub = paste0("Linkage: ", dend$method, ".", sep = ""))
}

dendPlot(dendA)

## 3) heat() # requires "gplots" package

# This function requires the "gplots" package. An input containing only the data
# in the form of a matrix or data frame is needed, as well as the distance
# method calculation as a string. The data only have to contain the samples and
# protein levels in their columns and rows, respectively .Possible distance
# calculations are: "euclidean", "manhattan" and "correlation". The key index
# shows the deviation from a mean value in terms of Z-score (number of standard
# deviations) calculated using the protein levels from all samples. In each
# axis, a dendrogram is plotted. While the distance function is specified,
# clustering method is not.
# heat() function does require NA values omission.

heat <- function(dataF,
                 distance = "correlation",
                 xcex = 0.75,
                 ycex = 0.75,
                 ylab = TRUE,
                 rowD = TRUE,
                 colD = TRUE,
                 colSet = "greenred",
                 rotateXLabs = NULL,
                 rotateYLabs = NULL,
                 ADJCOL = c(NA, 0),
                 ADJROW = c(0, NA)){
  if(!("package:gplots" %in% base::search())){
    library(gplots)
  }
  
  if(colSet == "greenred"){
    colsUsed <- colorRampPalette(colors = c("green", "black", "red"))(75)
  }
  if(colSet == "bluered"){
    colsUsed <- colorRampPalette(colors = c("blue", "black", "red"))(75)
  }
  if(colSet == "redgreen"){
    colsUsed <- colorRampPalette(colors = c("red", "black", "green"))(75)
  }
  
  if(ylab){
    if(distance == "euclidean" | distance == "manhattan"){
      heatmap.2(x = dataF,
                distfun = function(x) {dist(x, method = distance)},
                trace = "none",
                scale = "row",
                density.info = "none",
                key.title = "",
                cexRow = ycex,
                cexCol = xcex,
                Rowv = rowD,
                Colv = colD,
                col = colsUsed,
                srtCol = rotateXLabs,
                srtRow = rotateYLabs,
                adjCol = ADJCOL,
                adjRow = ADJROW)
    }
    if(distance == "correlation"){
      heatmap.2(x = dataF,
                distfun = function(x)
                  as.dist((1 - cor(t(x), use = "pairwise.complete.obs"))/2),
                trace = "none",
                scale = "row",
                density.info = "none",
                key.title = "",
                cexRow = ycex,
                cexCol = xcex,
                Rowv = rowD,
                Colv = colD,
                col = colsUsed,
                srtCol = rotateXLabs,
                srtRow = rotateYLabs,
                adjCol = ADJCOL,
                adjRow = ADJROW)
    }
  }else{
    if(distance == "euclidean" | distance == "manhattan"){
      heatmap.2(x = dataF, distfun = function(x) {dist(x, method = distance)},
                trace = "none",
                scale = "row",
                density.info = "none",
                key.title = "",
                cexRow = ycex,
                cexCol = xcex,
                labRow = ylab,
                Rowv = rowD,
                Colv = colD,
                col = colsUsed,
                srtCol = rotateXLabs,
                srtRow = rotateYLabs,
                adjCol = ADJCOL,
                adjRow = ADJROW)
    }
    if(distance == "correlation"){
      heatmap.2(x = dataF,
                distfun = function(x)
                  as.dist((1 - cor(t(x), use = "pairwise.complete.obs"))/2),
                trace = "none",
                scale = "row",
                density.info = "none",
                key.title = "",
                cexRow = ycex,
                cexCol = xcex,
                labRow = ylab,
                Rowv = rowD,
                Colv = colD,
                col = colsUsed,
                srtCol = rotateXLabs,
                srtRow = rotateYLabs,
                adjCol = ADJCOL,
                adjRow = ADJROW)
    }
  }
}

heat(dataF = top20, distance = "correlation")

## 4) PCACal():

# It computes the PCA object from the given data. To do so, the R base function
# employed is "prcomp()".

PCACal <- function(scaledData, wanna.scale = FALSE){
  
  PCA <- prcomp(x = t(na.omit(scaledData)), scale. = wanna.scale)
  return(PCA)
  
}

PCA <- PCACal(scaledData = scData)

## 5) elbowM():

# Elbow method is a criterion used in machine learning after graphical
# representation. It is a rule followed after the value that produces the most
# drastic reduction in data variance for choosing the number of clusters or
# others for machine learning models. This is also a method utilized for PCA.
# When choosing the two principal components for an scatterplot, elbow method
# can be used to select those two principal components by finding the one that
# implies the most relative variance reduction.

elbowM <- function(vec, namedVec = FALSE){
  
  ratesVec <- c()
  diffsVec <- c()
  len <- length(vec)
  for(i in 2:len){
    if(i <= (len-1)){
      rate1 <- unname(vec[i-1]) - unname(vec[i])
      rate2 <- unname(vec[i]) - unname(vec[i+1])
      rate <- round(rate1/rate2, 5)
      ratesVec <- append(x = ratesVec, values = rate)
      diff <- vec[i-1] - vec[i]
      diffsVec <- append(x = diffsVec, values = diff)
    }else{
      diff <- vec[i-1] - vec[i]
      diffsVec <- append(x = diffsVec, values = diff)
    }
  }
  ratesVec <- c(NA, ratesVec, NA)
  copyDiffs <- diffsVec
  diffsVec <- c(NA, diffsVec)
  dataF <- rbind(vec, ratesVec, diffsVec)
  rownames(dataF) <- c("Original vector",
                       "Continuous difference rate",
                       "Continuous difference")
  if(namedVec == TRUE){
    colnames(dataF) <- names(vec)
  }else{
    colnames(dataF) <- 1:len
  }
  print(dataF)
  orderedVec <- copyDiffs[order(copyDiffs, decreasing = TRUE)]
  if(all(as.numeric(copyDiffs) == as.numeric(orderedVec))){
    return(paste0("Recommended plotting components: ",
                  as.character(colnames(dataF)[which.max(ratesVec)-1]),
                  ", ",
                  as.character(colnames(dataF)[which.max(ratesVec)]),
                  sep = ""))
  }else{
    return(paste0("Recommended plotting components: ",
                  as.character(colnames(dataF)[which.max(diffsVec)-1]),
                  ", ",
                  as.character(colnames(dataF)[which.max(diffsVec)]),
                  sep = ""))
  }
}

elbowM(summary(PCA)$importance[2,], namedVec = TRUE)

## 6) PCABar():

# It represents a barplot consisting of either the variance the different
# principal components have, or their cummulative variance. It is only needed
# to supply the PCA object as an input.

PCABar <- function(PCAObj,
                   yMag = "var",
                   noPCs = ncol(summary(PCAObj$x)),
                   col2 = "grey",
                   las2 = 2,
                   cexLab2 = 0.8,
                   main2 = "Principal Components (PC) variance barplot"){
  if(yMag == "var"){
    heightValues <- summary(PCAObj)$importance[2,][1:noPCs]
  }
  if(yMag == "cumm" | yMag == "cummulative"){
    heightValues <- summary(PCAObj)$importance[3,][1:noPCs]
  }
  barplot(height = heightValues,
          ylim = range(pretty(c(0,max(heightValues)))),
          main = main2,
          xlab = "Principal Components (PC)",
          ylab = "Variance per Principal Component (PC)",
          col = col2,
          las = las2,
          cex.names = cexLab2,
          names.arg =  colnames(PCAObj$x))
}

PCABar(PCAObj = PCA, yMag = "var", noPCs = 10)

## 7) plotComposition():

# This function shows the variance percentage each variable contributes to all
# the variance proportioned by one of the principal components (PC) from the
# PCA object. This variables appear ordered considering a decreasing variance
# percentage contribution in a line plot. This representation also shows a
# threshold corresponding to the mean variance percentage (the result of
# dividing 100% of the variance and the number of variables) and a vertical
# line locating the first 5% variables with the most variance percentage
# contribution. Finally, a vertical line showing the cut-off point between the
# line plot and the mean variance plot is showed. The closer this line is to
# the vertical axis, the less the number of variables is that which gathers the
# most variance.

plotComposition <- function(PCAObj, chosenPC, chosenProp = 0.05){
  if(!("factoextra" %in% installed.packages()[,1])){
    install.packages("factoextra")
  }
  if(!("package:factoextra" %in% base::search())){
    library(factoextra)
  }
  composition <- get_pca_var(res.pca = PCAObj)$contrib[,chosenPC] # variable variances
  composition <- composition[order(composition, decreasing = TRUE)] # variances ordered
  len <- length(composition)
  significance <- ceiling(chosenProp * len) # red line
  meanVar <- 100/len # horizontal grey line
  which(composition <= meanVar)[1] # vertical grey line
  plot(x = 1:len,
       y = composition, # maybe this won't do. Before: x = composition
       type = "l",
       xlim = range(pretty(c(0,len))),
       ylim = range(pretty(c(0,max(composition)))),
       main = paste0("Decreasing PC",
                     as.character(chosenPC),
                     " variables variance composition",
                     sep = ""),
       xlab = "Index",
       ylab = "Variable variance percentage")
  abline(h = meanVar, lty = 2)
  abline(v = significance, lty = 2, col = "red")
  abline(v = which(composition <= meanVar)[1])
  legend(x = "topright",
         legend = c("Mean variance per variable", 
                    paste0("First ",
                           as.character(round(x = (chosenProp * 100), 2)),
                           "% contributing variance variables indices",
                           sep = ""),
                    "Mean variance and variance plot lines cut-off point"),
         lty = c(2, 2, 1),
         col = c("black", "red", "black"))
}

plotComposition(PCAObj = PCA, chosenPC = 2)

## 8) PCprot():

# It returns the proportion of variance of those proteins that contribute most
# to the selected principal component variance. The PCA object and the number
# of principal component is required.

PCprot <- function(PCAObj, chosenPC, top = 10, perc = FALSE){
  if(!("factoextra" %in% installed.packages()[,1])){
    install.packages("factoextra")
  }
  if(!("package:factoextra" %in% base::search())){
    library(factoextra)
  }
  composition <- get_pca_var(res.pca = PCAObj)$contrib[,chosenPC]
  composition <- composition[order(composition, decreasing = TRUE)]
  if(perc == TRUE){
    composition <- composition[1:top]
  }else{
    composition <- composition[1:top]/100
  }
  return(composition)
}

PCprot(PCAObj = PCA, chosenPC = 2)

## 9) PCAPlot():

# It plots a PCA representation. It requires a PCA object as input.

PCAPlot <- function(PCAObject,
                    is.chosen = FALSE,
                    firstPC,
                    secPC,
                    groups,
                    colVec,
                    legPos = "topright",
                    main2 = "default",
                    cexLeg = 1,
                    cexPoints = 1,
                    cexMain = 1,
                    cexLabels = 1,
                    cexAxes = 1){
  if(is.chosen == FALSE){
    
    elbow <- elbowM(summary(PCAObject)$importance[2,], namedVec = FALSE)
    
    firstPC <- as.numeric(substr(x = elbow,
                                 start = nchar(elbow)-3,
                                 stop = nchar(elbow)-3))
    secPC <- as.numeric(substr(x = elbow,
                               start = nchar(elbow),
                               stop = nchar(elbow)))
  }
  
  if(main2 == "default"){
    
    main2 <- paste0("PC",
                    as.character(firstPC),
                    " vs. PC",
                    as.character(secPC),
                    sep = "")
    
  }
  
  plot(x = PCAObject$x[,firstPC], y = PCAObject$x[,secPC],
       xlim = range(pretty(c(min(PCAObject$x[,firstPC]), max(PCAObject$x[,firstPC])))),
       ylim = range(pretty(c(min(PCAObject$x[,secPC]), max(PCAObject$x[,secPC])))),
       main = main2,
       xlab = paste0("PC", as.character(firstPC), " (",
                     as.character(round(100*summary(PCAObject)$importance[2,firstPC],1)),
                     "%)",
                     sep = ""),
       ylab = paste0("PC", as.character(secPC), " (",
                     as.character(round(100*summary(PCAObject)$importance[2,secPC],1)),
                     "%)",
                     sep = ""),
       cex = cexPoints,
       cex.main = cexMain,
       cex.lab = cexLabels,
       cex.axis = cexAxes)
  
  for(i in 1:length(groups)){
    
    idx <- which(grepl(pattern = groups[i], x = rownames(PCAObject$x), fixed = TRUE))
    
    points(x = PCAObject$x[idx,firstPC],
           y = PCAObject$x[idx,secPC],
           pch = 21,
           col = "black",
           bg = colVec[i],
           cex = cexPoints)
  
  }
  
  legend(x = legPos,
         legend = groups,
         pch = 21,
         col = "black",
         pt.bg = colVec,
         cex = cexLeg)

}

PCAPlot(PCAObject = PCA, is.chosen = FALSE, groups = sampleTags, colVec = chosenCols)
PCAPlot(PCAObject = PCA, is.chosen = FALSE,
        groups = c("Alagille", "Atresia", "DAAT", "PFIC", "Control"),
        colVec = col5)

## 10) kmcluster():

# It executes k-means and plots its results in a PCA plot, so sample
# classification can be observed in a tow-dimensional plot. It requires a
# normalized data matrix.

kmcluster <- function(data,
                      maxClus = 10,
                      maxIter = 100,
                      chCol = c("lawngreen", "aquamarine4", "skyblue",
                                "palevioletred2", "lemonchiffon4", "orange", "brown2",
                                "darkorchid", "yellow", "navyblue"),
                      main2 = "default",
                      legPos = "bottomright",
                      is.chosen = TRUE,
                      firstPC = 1,
                      secPC = 2,
                      wanna.scale2 = FALSE,
                      cexLeg = 1,
                      cexPoints = 1,
                      cexMain = 1,
                      cexLabels = 1,
                      cexAxes = 1){
  
  tWith = rep(NA, maxClus)
  for(i in 1:maxClus){
    KM = kmeans(x = t(data), center = i, nstart = maxIter) # transposes data
    tWith[i] = KM$tot.withinss
  }
  barplot(height = tWith, names.arg = 1:length(tWith),
          main = "Total within-cluster sum of squares per number of clusters",
          xlab = "Number of clusters",
          ylab = "Total within-cluster sum of squares",
          ylim = range(pretty(c(0,max(tWith)))))
  eRes <- elbowM(vec = tWith, namedVec = FALSE)
  chosenK <- as.numeric(substr(x = eRes,
                               start = nchar(eRes),
                               stop = nchar(eRes)))
  KM = kmeans(x = t(data), center = chosenK, nstart = maxIter)
  KClasses <- KM$cluster
  KMPalette <- sample(x = chCol, size = chosenK, replace = FALSE)
  
  PCAObj <- PCACal(scaledData = data, wanna.scale = wanna.scale2)
  if(!is.chosen){
    eRes <- elbowM(summary(PCAObj)$importance[2,], namedVec = FALSE)
    PCx <- as.numeric(substr(x = eRes, start = nchar(eRes)-3, stop = nchar(eRes)-3))
    PCy <- as.numeric(substr(x = eRes, start = nchar(eRes), stop = nchar(eRes)))
  }else{
    PCx <- firstPC
    PCy <- secPC
  }
  
  
  if(main2 == "default"){
    main2 = paste0("PC", as.character(PCx),
                   " vs. PC", as.character(PCy),
                   sep = "")
  }
  
  plot(x = PCAObj$x[,PCx], y = PCAObj$x[,PCy],
       xlim = range(pretty(c(min(PCAObj$x[,PCx]), max(PCAObj$x[,PCx])))),
       ylim = range(pretty(c(min(PCAObj$x[,PCy]), max(PCAObj$x[,PCy])))),
       main = main2,
       xlab = paste0("PC", as.character(PCx), " (",
                     as.character(round(100*summary(PCAObj)$importance[2,PCx],1)),
                     "%)",
                     sep = ""),
       ylab = paste0("PC", as.character(PCy), " (",
                     as.character(round(100*summary(PCAObj)$importance[2,PCy],1)),
                     "%)",
                     sep = ""),
       cex = cexPoints,
       cex.main = cexMain,
       cex.lab = cexLabels,
       cex.axis = cexAxes)
  
  clus <- c()
  for(i in 1:chosenK){
    bool <- unname(i == KClasses)
    points(x = PCAObj$x[bool,PCx],
           y = PCAObj$x[bool,PCy],
           pch = 21,
           col = "black",
           bg = KMPalette[i],
           cex = cexPoints)
    clus <- append(x = clus, values = paste0("Cluster ", as.character(i), sep = ""))
  }
  
  legend(x = legPos,
         legend = clus,
         pch = 21,
         col = "black",
         pt.bg = KMPalette,
         cex = cexLeg)
  
}

kmcluster(data = normData,
          kmTitle = "Total within-cluster sum of squares per number of clusters
          (all proteins)")

## 11) MDS2():

# It plots a multidimensional scaling (MDS) plot from the results of a random
# forest classification if "proximity = TRUE" was specified when creating the
# random forest.

MDS2 <- function(rfObj,
                 classCol,
                 areChosenColors = FALSE,
                 chosenColors,
                 main2 = "Multidimensional scaling (MDS) plot",
                 legPos = "bottomleft",
                 pointCex = 1.2,
                 legSize = 1,
                 cexMain = 1,
                 cexLabels = 1,
                 cexAxes = 1){
  
  if(!("package:randomForest" %in% base::search())){
    library(randomForest)
  }
  if(!("package:RColorBrewer" %in% base::search())){
    library(RColorBrewer)
  }
  
  prox <- cmdscale(1 - rfObj$proximity, eig = TRUE)
  uc <- unique(as.character(classCol))
  if(areChosenColors){
    myPal <- chosenColors
  }else{
    myPal <- brewer.pal(n = length(uc), name = "Set1")[1:length(uc)]
  }
  
  plot(x = prox$points[,1],
       y = prox$points[,2],
       xlab = "Dim. 1",
       ylab = "Dim. 2",
       xlim = range(pretty(c(min(prox$points[,1]), max(prox$points[,1])))),
       ylim = range(pretty(c(min(prox$points[,2]), max(prox$points[,2])))),
       pch = 21,
       col = "black",
       main = main2,
       cex = pointCex,
       cex.main = cexMain,
       cex.lab = cexLabels,
       cex.axis = cexAxes)
  
  for(i in 1:length(uc)){
    bool <- classCol == uc[i]
    points(x = prox$points[,1][bool],
           y = prox$points[,2][bool],
           pch = 21,
           col = "black",
           bg = myPal[i],
           cex = pointCex)
  }
  
  legend(x = legPos,
         legend = uc,
         pch = 21,
         col = "black",
         pt.bg = myPal,
         cex = legSize)
  
}

## 12) artificialShell3():

# 

artificialShell3 <- function(dat, samplesPerGroup = 100, is.pos = TRUE){
  
  classIndex <- ncol(dat)
  uniqueClasses <- unique(as.character(dat[,classIndex]))
  fillMe <- matrix(data = rep(NA, (samplesPerGroup * length(uniqueClasses) * ncol(dat))),
                   ncol = ncol(dat),
                   nrow = samplesPerGroup * length(uniqueClasses))
  colnames(fillMe) <- colnames(dat)
  
  for(i in 1:length(uniqueClasses)){
    chosenClass <- uniqueClasses[i]
    subData <- dat[which(dat[,classIndex] == chosenClass),]
    means <- unname(apply(X = subData[,-ncol(subData)], MARGIN = 2, FUN = mean))
    sds <- unname(apply(X = subData[,-ncol(subData)], MARGIN = 2, FUN = sd))
    sds[sds == 0] <- 0.1
    subFill <- matrix(data = rep(NA, (samplesPerGroup * ncol(subData))),
                      ncol = ncol(subData),
                      nrow = samplesPerGroup)
    for(j in 1:samplesPerGroup){
      variableIndex <- sample(x = (ncol(subData)-1),
                              size = 1,
                              replace = FALSE)
      randomValue <- rnorm(n = 1,
                           mean = means[variableIndex],
                           sd = sds[variableIndex])
      meansCoeff <- means/means[variableIndex]
      newSample <- rep(NA, ncol(dat))
      newSample <- c(randomValue*meansCoeff, chosenClass)
      subFill[j,] <- newSample
    }
    if(i == 1){
      fillMe[1:samplesPerGroup,] <- subFill
    }else{
      if(samplesPerGroup == 1){
        fillMe[(samplesPerGroup*i),] <- subFill
      }else{
        start <- (samplesPerGroup*(i-1)) + 1
        end <- start + samplesPerGroup - 1
        fillMe[(start:end),] <- subFill
      }
    }
  }
  
  if(!(is.pos)){
    fillMe <- abs(fillMe)
  }
  fillMe <- as.data.frame(fillMe)
  fillMe[,ncol(fillMe)] <- as.factor(fillMe[,ncol(fillMe)])
  fillMe[,-ncol(fillMe)] <- apply(X = fillMe[ ,-ncol(fillMe)],
                                  MARGIN = 2,
                                  FUN = as.numeric)
  rownames(fillMe) <- sprintf("AD%s", seq(1:nrow(fillMe)))
  return(fillMe)
}

library(randomForest)
library(caret)

B <- artificialShell3(dat = iris, samplesPerGroup = 100)
View(B)

rf <- randomForest::randomForest(x = iris[,-5], y = iris[,5], proximity = TRUE)
pred <- predict(object = rf, B)
confusionMatrix(pred, B[,5])

randomForest::MDSplot(rf = rf, fac = iris[,5])

rf2 <- randomForest(x = rbind(iris[,-5], B[,-5]), y = c(iris[,5], B[,5]),
                    proximity = TRUE)
randomForest::MDSplot(rf = rf2, fac = c(iris[,5], B[,5]))
print(rf2)

## 13) dendot():

# 

dendot <- function(dat, distanceMethod = "correlation",
                   linkageMethod = "single", legendPosition = "bottomleft",
                   legendCex = 0.8, maxClus = 10, maxIter = 100,
                   is.optimalK = FALSE, optimalK, cex.axis2 = 1,
                   inset2 = c(0,0)){
  
  if(!("package:factoextra" %in% base::search())){
    library(factoextra)
  }
  if(!("package:cluster" %in% base::search())){
    library(cluster)
  }
  if(!("package:RColorBrewer" %in% base::search())){
    library(RColorBrewer)
  }
  
  dendGen <- function(scaledData, distMethod, linkMethod){
    if(distMethod == "euclidean" | distMethod == "manhattan"){
      distance <- dist(x = t(scaledData), method = distMethod)
    }
    if(distMethod == "correlation"){
      distance <- as.dist((1-cor(x = scaledData, use = "pairwise.complete.obs"))/2)
    }
    dendrogram <- hclust(d = distance, method = linkMethod)
    return(dendrogram)
  }
  dendPlot <- function(dend, main2 = "Cluster Dendrogram"){
    if(is.null(dend$dist.method)){
      dend$dist.method <- "correlation"
    }
    plot(dend, xlab = paste0("Distance: ", dend$dist.method, ".", sep = ""),
         sub = paste0("Linkage: ", dend$method, ".", sep = ""),
         main = main2)
  }
  elbowM <- function(vec, namedVec = FALSE){
    ratesVec <- c()
    diffsVec <- c()
    len <- length(vec)
    for(i in 2:len){
      if(i <= (len-1)){
        rate1 <- unname(vec[i-1]) - unname(vec[i])
        rate2 <- unname(vec[i]) - unname(vec[i+1])
        rate <- round(rate1/rate2, 5)
        ratesVec <- append(x = ratesVec, values = rate)
        diff <- vec[i-1] - vec[i]
        diffsVec <- append(x = diffsVec, values = diff)
      }else{
        diff <- vec[i-1] - vec[i]
        diffsVec <- append(x = diffsVec, values = diff)
      }
    }
    ratesVec <- c(NA, ratesVec, NA)
    copyDiffs <- diffsVec
    diffsVec <- c(NA, diffsVec)
    dataF <- rbind(vec, ratesVec, diffsVec)
    rownames(dataF) <- c("Original vector",
                         "Continuous difference rate",
                         "Continuous difference")
    if(namedVec == TRUE){
      colnames(dataF) <- names(vec)
    }else{
      colnames(dataF) <- 1:len
    }
    print(dataF)
    orderedVec <- copyDiffs[order(copyDiffs, decreasing = TRUE)]
    if(all(as.numeric(copyDiffs) == as.numeric(orderedVec))){
      return(paste0("Recommended plotting components: ",
                    as.character(colnames(dataF)[which.max(ratesVec)-1]),
                    ", ",
                    as.character(colnames(dataF)[which.max(ratesVec)]),
                    sep = ""))
    }else{
      return(paste0("Recommended plotting components: ",
                    as.character(colnames(dataF)[which.max(diffsVec)-1]),
                    ", ",
                    as.character(colnames(dataF)[which.max(diffsVec)]),
                    sep = ""))
    }
  }
  
  dat <- t(dat)
  dendrogram <- dendGen(scaledData = dat,
                        distMethod = distanceMethod,
                        linkMethod = linkageMethod)
  
  if((ncol(dat) - 1) < maxClus){
    maxClus <- ncol(dat) - 1
  }
  
  tWith <- rep(NA, maxClus)
  for(i in 1:maxClus){
    KM <- kmeans(x = t(dat), center = i, nstart = maxIter) # transposes data
    tWith[i] <- KM$tot.withinss
  }
  eRes <- elbowM(vec = tWith, namedVec = FALSE)
  optk <- as.numeric(substr(x = eRes,
                            start = nchar(eRes),
                            stop = nchar(eRes)))
  if(is.optimalK){
    optk <- optimalK
  }
  
  colorsVector <- brewer.pal(optk, "Set1")
  if(optk < 3){
    colorsVector <- colorsVector[-3]
  }
  dendPlot(dendrogram)
  rect <- rect.hclust(tree = dendrogram, k = optk, border = colorsVector)
  for(i in 1:length(rect)){
    rect[[i]] <- names(rect[[i]])
  }
  
  carcass <- matrix(data = rep(1, prod(dim(dat))), ncol = ncol(dat))
  carcass <- carcass * (1:nrow(carcass))
  plot(x = as.vector(t(carcass)), y = as.vector(t(dat)),
       xlim = range(pretty(c(1, nrow(dat)))),
       ylim = range(pretty(c(min(dat), max(dat)))),
       main = "Standardized protein levels dot plot (with clusters)",
       ylab = "Median-standardized normalized protein levels", cex = 1, pch = 21,
       col = "black", xaxt = "n", xlab = "")
  
  axis(side = 1, at = 1:nrow(dat), labels = rownames(dat), las = 2, cex.axis = cex.axis2)
  
  means <- matrix(data = rep(NA, (optk*nrow(dat))), nrow = optk)
  colnames(means) <- rownames(dat)
  rownames(means) <- sprintf("Cluster %s", seq(1:optk))
  
  for(i in 1:nrow(dat)){
    for(j in 1:optk){
      clus <- which(names(dat[i,]) %in% rect[[j]])
      means[j,i] <- mean(as.numeric(dat[i,][clus]))
      points(x = carcass[i,][clus], y = dat[i,][clus], pch = 21,
             col = "black", bg = colorsVector[j])
    }
  }
  for(i in 1:nrow(means)){
    points(x = 1:nrow(dat), y = means[i,], col = colorsVector[i], type = "l")
  }
  
  pointsLeg <- sprintf("Cluster %s data point", seq(1:optk))
  meansLeg <- sprintf("Cluster %s mean value", seq(1:optk))
  
  legend(x = legendPosition,
         legend = c(pointsLeg, meansLeg), cex = legendCex,
         pch = c(rep(21, optk), rep(NA, optk)),
         col = c(rep("black", optk), colorsVector),
         pt.bg = c(colorsVector, rep(NA, optk)),
         lty = c(rep(NA, optk), rep(1, optk)),
         inset = inset2)
}

dendot(dat = as.matrix(ultData[,-ncol(ultData)]), legendCex = 0.7)

## 14) fightMe():

# 

fightMe <- function(firstNorm, experiments, classes, method = "covariates",
                    referenceBatch){
  
  if(!("package:sva" %in% base::search())){
    library("sva")
  }
  quant
  experiments <- as.numeric(as.factor(experiments))
  
  if(method == "parametric"){
    normalizedMatrix <- ComBat(dat = firstNorm,
                               batch = experiments,
                               mod = NULL,
                               par.prior = TRUE,
                               prior.plots = FALSE)
  }
  if(method == "mean"){
    normalizedMatrix <- ComBat(dat = firstNorm,
                               batch = experiments,
                               mod = NULL,
                               par.prior = FALSE,
                               mean.only = TRUE)
  }
  if(method == "covariates"){
    modelClasses <- model.matrix(~as.factor(classes),
                                 data = as.data.frame(firstNorm))
    normalizedMatrix <- ComBat(dat = firstNorm,
                               batch = experiments,
                               mod = modelClasses,
                               par.prior = TRUE,
                               ref.batch = referenceBatch)
  }
  if(method == "soft"){
    modelClasses <- model.matrix(~as.factor(classes),
                                 data = as.data.frame(firstNorm))
    normalizedMatrix <- ComBat(dat = firstNorm,
                               batch = experiments,
                               mod = modelClasses,
                               par.prior = TRUE,
                               mean.only = TRUE)
  }
  if(method == "soft2"){
    modelClasses <- model.matrix(~1, data = as.data.frame(firstNorm))
    normalizedMatrix <- ComBat(dat = firstNorm,
                               batch = experiments,
                               mod = modelClasses,
                               par.prior = TRUE,
                               mean.only = TRUE)
  }
  
  return(normalizedMatrix)
}

## 15) volcanoLorena():

# 

volcanoLorena <- function(neoOut,
                          is.FC = TRUE,
                          chFC = 1,
                          chAlpha = 0.05,
                          chMain = "Volcano plot",
                          legPos = "topleft",
                          chInset = c(0.025,0.025),
                          clSize = 0.75,
                          ptsCex = 0.65,
                          is.legend = TRUE,
                          colorDown = "forestgreen",
                          colorUp = "brown1"){
  foldRg <- paste0("(",
                   as.character(-chFC),
                   ", ",
                   as.character(chFC),
                   ")",
                   sep = "")
  if(is.FC == TRUE){
    legText <- c(paste0("q-value <= ",
                        as.character(chAlpha),
                        ", log2(FC) <= ",
                        as.character(-chFC),
                        sep = ""),
                 paste0("q-value <= ",
                        as.character(chAlpha),
                        ", log2(FC) >= ",
                        as.character(chFC),
                        sep = ""),
                 paste0("q-value <= ",
                        as.character(chAlpha),
                        " and log2(FC) not in ",
                        foldRg,
                        sep = ""),
                 paste0("p-value > ",
                        as.character(chAlpha),
                        " or log2(FC) in ",
                        foldRg,
                        sep = ""),
                 paste0("Threshold: p-value = ",
                        as.character(chAlpha),
                        sep = ""),
                 paste0("Threshold: log2(FC) = ",
                        as.character(-chFC),
                        sep = ""),
                 paste0("Threshold: log2(FC) = ",
                        as.character(chFC),
                        sep = ""))
  }else{
    legText <- c(paste0("q-value <= ",
                        as.character(chAlpha),
                        ", log2(FC) < ",
                        as.character(0),
                        sep = ""),
                 paste0("q-value <= ",
                        as.character(chAlpha),
                        ", log2(FC) >= ",
                        as.character(0),
                        sep = ""),
                 paste0("p-value <= ",
                        as.character(chAlpha),
                        sep = ""),
                 paste0("p-value > ",
                        as.character(chAlpha),
                        sep = ""),
                 paste0("Threshold: p-value = ",
                        as.character(chAlpha),
                        sep = ""))
  }
  plot(x = neoOut[,"log2.vec.FC"], y = neoOut[,"-log10.pval"],
       xlim = range(pretty(c(-max(abs(neoOut[,"log2.vec.FC"])),
                             max(abs(neoOut[,"log2.vec.FC"]))))),
       ylim = range(pretty(c(0,max(neoOut[,"-log10.pval"])))),
       pch = 19, col = "grey", xlab = "log2(fold change)",
       ylab = "-log10(p-value)", cex = ptsCex, main = chMain)
  I1 <- which(neoOut[,"log2.vec.FC"] <= -chFC |
                neoOut[,"log2.vec.FC"] >= chFC)
  I2 <- which(neoOut[,"pval"] <= chAlpha)
  I1.2 <- intersect(I1, I2)
  I3 <- which(neoOut[,"adj.pval"] <= chAlpha)
  I1.3 <- intersect(I1, I3)
  I4 <- which(neoOut[,"log2.vec.FC"] >= chFC)
  I3.4 <- intersect(I3, I4)
  I5 <- which(neoOut[,"log2.vec.FC"] <= -chFC)
  I3.5 <- intersect(I3, I5)
  I6 <- which(neoOut[,"log2.vec.FC"] < 0)
  I7 <- which(neoOut[,"log2.vec.FC"] >= 0)
  I3.6 <- intersect(I3, I6)
  I3.7 <- intersect(I3, I7)
  if(is.FC == TRUE){
    points(x = neoOut[I1.2,"log2.vec.FC"], y = neoOut[I1.2,"-log10.pval"],
           pch = 19, col = "black", cex = ptsCex)
    points(x = neoOut[I3.5,"log2.vec.FC"], y = neoOut[I3.5,"-log10.pval"],
           pch = 19, col = colorDown, cex = ptsCex)
    points(x = neoOut[I3.4,"log2.vec.FC"], y = neoOut[I3.4,"-log10.pval"],
           pch = 19, col = colorUp, cex = ptsCex)
    abline(v = -chFC, col = colorDown, lty = 1)
    abline(v = chFC, col = colorUp, lty = 1)
    abline(h = -log10(chAlpha), col = "#393A3F", lty = 3)
    if(is.legend){
      legend(x = legPos, legend = legText, cex = clSize,
             pch = c(19, 19, 19, 19, NA, NA, NA),
             col = c(colorDown, colorUp, "black","grey",
                     "#393A3F", colorDown, colorUp),
             inset = chInset, lty = c(NA, NA, NA, NA, 3, 1, 1))
    }
  }else{
    points(x = neoOut[I2,"log2.vec.FC"], y = neoOut[I2,"-log10.pval"],
           pch = 19, col = "black", cex = ptsCex)
    points(x = neoOut[I3.6,"log2.vec.FC"], y = neoOut[I3.6,"-log10.pval"],
           pch = 19, col = colorDown, cex = ptsCex)
    points(x = neoOut[I3.7,"log2.vec.FC"], y = neoOut[I3.7,"-log10.pval"],
           pch = 19, col = colorUp, cex = ptsCex)
    abline(h = -log10(chAlpha), col = "#393A3F", lty = 3)
    if(is.legend){
      legend(x = legPos, legend = legText, cex = clSize,
             pch = c(19, 19, 19, 19, NA), col = c(colorDown,colorUp,"black","grey","#393A3F"),
             inset = chInset, lty = c(NA, NA, NA, NA, 3))
    }
  }
}

volcanoLorena(neoOut = cleanlimma, is.FC = FALSE)
volcanoLorena(neoOut = cleanlimma, is.FC = TRUE, chFC = 0.1)

## 16) PCA3D():

# 

PCA3D <- function(PCAObject, firstPC = 1, secondPC = 2, thirdPC = 3, groupsVector,
                  type3D = "s", size3D = 0.6, main3D = "default",
                  legPos = "topright", legSize = 1.5, legInset = c(0.05),
                  chosenColors = NULL){
  
  if(!("package:rgl" %in% base::search())){
    library(rgl)
  }
  if(!("package:RColorBrewer" %in% base::search())){
    library(RColorBrewer)
  }
  if(!("package:stringi" %in% base::search())){
    library(stringi)
  }
  
  uniqueGroups <- unique(as.character(groupsVector))
  if(is.null(chosenColors)){
    tempPalette <- brewer.pal(n = length(uniqueGroups), name = "Set1")
    if(length(uniqueGroups) == 2){
      tempPalette <- tempPalette[1:2]
    }
  }else{
    tempPalette <- chosenColors
  }
  
  sampleColor <- stri_replace_all_regex(as.character(groupsVector),
                                        pattern = uniqueGroups,
                                        replacement = tempPalette,
                                        vectorize = FALSE)
  
  if(main3D == "default"){
    main3D = paste0("PC", as.character(firstPC), " vs. PC", as.character(secondPC),
                    " vs. PC", as.character(thirdPC), sep = "")
  }
  xlab3D = paste0("PC", as.character(firstPC), " (",
                  as.character(round(100*summary(PCAObject)$importance[2,firstPC],1)),
                  "%)",
                  sep = "")
  ylab3D = paste0("PC", as.character(secondPC), " (",
                  as.character(round(100*summary(PCAObject)$importance[2,secondPC],1)),
                  "%)",
                  sep = "")
  zlab3D = paste0("PC", as.character(thirdPC), " (",
                  as.character(round(100*summary(PCAObject)$importance[2,thirdPC],1)),
                  "%)",
                  sep = "")
  
  xDif <- pretty(c(min(PCAObject$x[,firstPC]), max(PCAObject$x[,firstPC])))[2] -
    pretty(c(min(PCAObject$x[,firstPC]), max(PCAObject$x[,firstPC])))[1]
  xRangeMin <- min(PCAObject$x[,firstPC]) - xDif
  xRangeMax <- max(PCAObject$x[,firstPC]) + xDif
  
  yDif <- pretty(c(min(PCAObject$x[,secondPC]), max(PCAObject$x[,secondPC])))[2] -
    pretty(c(min(PCAObject$x[,secondPC]), max(PCAObject$x[,secondPC])))[1]
  yRangeMin <- min(PCAObject$x[,secondPC]) - yDif
  yRangeMax <- max(PCAObject$x[,secondPC]) + yDif
  
  zDif <- pretty(c(min(PCAObject$x[,thirdPC]), max(PCAObject$x[,thirdPC])))[2] -
    pretty(c(min(PCAObject$x[,thirdPC]), max(PCAObject$x[,thirdPC])))[1]
  zRangeMin <- min(PCAObject$x[,thirdPC]) - zDif
  zRangeMax <- max(PCAObject$x[,thirdPC]) + zDif
  
  plot3d(x = PCAObject$x[,firstPC],
         y = PCAObject$x[,secondPC],
         z = PCAObject$x[,thirdPC],
         main = main3D,
         xlab = xlab3D,
         ylab = ylab3D,
         zlab = zlab3D,
         type = type3D,
         size = size3D,
         col = sampleColor,
         xlim = range(pretty(c(xRangeMin, xRangeMax))),
         ylim = range(pretty(c(yRangeMin, yRangeMax))),
         zlim = range(pretty(c(zRangeMin, zRangeMax))))
  
  legend3d(x = legPos, legend = uniqueGroups, col = tempPalette, pch = 19,
           cex = legSize, inset = legInset)
}

PCA3D(PCAObject = PCA, groupsVector = iris$Species)

## 17) PCAGif():

# 

PCAGif <- function(sense = c(0,0,1), nameMe = "PCAGif"){
  if(!("package:rgl" %in% base::search())){
    library(rgl)
  }
  movie3d(spin3d(axis = sense, rpm = 4), duration = 15, dir = "./", movie = nameMe)
}

PCAGif()

## 18) MDSplotter3D():

# 

MDSplotter3D <- function(randomF,
                         groupsVector,
                         main3D = "3D multidimensional scaling (MDS) plot",
                         type3D = "s",
                         size3D = 0.6,
                         is.biplot = FALSE,
                         legPos = "topright",
                         legSize = 1.5,
                         legInset = c(0.05),
                         is.colors = FALSE,
                         chosenColors){
  if(!("package:randomForest" %in% base::search())){
    library(randomForest)
  }
  if(!("package:RColorBrewer" %in% base::search())){
    library(RColorBrewer)
  }
  if(!("package:stringi" %in% base::search())){
    library(stringi)
  }
  if(!("package:rgl" %in% base::search())){
    library(rgl)
  }
  
  uniqueGroups <- unique(as.character(groupsVector))
  if(is.colors){
    tempPalette <- chosenColors
  }else{
    tempPalette <- brewer.pal(n = length(uniqueGroups),
                              name = "Set1")[c(1:length(uniqueGroups))]
  }
  
  sampleColor <- stri_replace_all_regex(as.character(groupsVector),
                                        pattern = uniqueGroups,
                                        replacement = tempPalette,
                                        vectorize = FALSE)
  if(is.biplot){
    dimensions <- MDSplot(rf = randomF, palette = tempPalette, k = 3, fac = groupsVector)$points
  }else{
    dimensions <- cmdscale(1 - randomF$proximity, eig = TRUE, k = 3)$points
  }
  
  xDif <- pretty(c(min(dimensions[,1]), max(dimensions[,1])))[2] -
    pretty(c(min(dimensions[,1]), max(dimensions[,1])))[1]
  xRangeMin <- min(dimensions[,1]) - xDif
  xRangeMax <- max(dimensions[,1]) + xDif
  
  yDif <- pretty(c(min(dimensions[,2]), max(dimensions[,2])))[2] -
    pretty(c(min(dimensions[,2]), max(dimensions[,2])))[1]
  yRangeMin <- min(dimensions[,2]) - yDif
  yRangeMax <- max(dimensions[,2]) + yDif
  
  zDif <- pretty(c(min(dimensions[,3]), max(dimensions[,3])))[2] -
    pretty(c(min(dimensions[,3]), max(dimensions[,3])))[1]
  zRangeMin <- min(dimensions[,3]) - zDif
  zRangeMax <- max(dimensions[,3]) + zDif
  
  plot3d(x = dimensions[,1],
         y = dimensions[,2],
         z = dimensions[,3],
         main = main3D,
         xlab = "Dimension 1",
         ylab = "Dimension 2",
         zlab = "Dimension 3",
         type = type3D,
         size = size3D,
         col = sampleColor,
         xlim = range(pretty(c(xRangeMin, xRangeMax))),
         ylim = range(pretty(c(yRangeMin, yRangeMax))),
         zlim = range(pretty(c(zRangeMin, zRangeMax))))
  
  legend3d(x = legPos, legend = uniqueGroups, col = tempPalette, pch = 19,
           cex = legSize, inset = legInset)
}

MDSplotter3D(randomF = rf.iris, groupsVector = iris[,5])

PCAGif(nameMe = "MDS3D")

## 19) 

#  

multiROC <- function(groupsReal,
                     groupsPredicted,
                     predictionProb,
                     insetLegend = c(0.025, 0.6)){
  
  if(!("package:pROC" %in% base::search())){
    library(pROC)
  }
  if(!("package:RColorBrewer" %in% base::search())){
    library(RColorBrewer)
  }
  
  uniqueClasses <- unique(as.character(groupsReal))
  mypalette <- brewer.pal(n = length(uniqueClasses), name = "Set1")
  
  aucs <- c()
  fillMeObs <- c()
  fillMePred <- c()
  
  if(length(uniqueClasses) == 2){ # new! At the end I kept it the same.
    
    # classiReal <- groupsReal == uniqueClasses[1]
    # classiPredicted <- groupsPredicted == uniqueClasses[1]
    # 
    # classiReal[classiReal == 1] <- uniqueClasses[1]
    # classiReal[classiReal == "FALSE"] <- uniqueClasses[2]
    # 
    # classiPredicted[classiPredicted == 1] <- uniqueClasses[1]
    # classiPredicted[classiPredicted == "FALSE"] <- uniqueClasses[2]
    
    wrong <- classiReal != classiPredicted
    right <- classiReal == classiPredicted
    
    controlBool <- classiReal != uniqueClasses[2]
    casesBool <- classiReal == uniqueClasses[2]
    
    pseudoreal <- apply(X = predictionProb, MARGIN = 1, FUN = min)
    predicted <- apply(X = predictionProb, MARGIN = 1, FUN = max)
    
    pseudoreal[wrong] <- mean(predicted[right & casesBool])
    predicted[wrong] <-  mean(pseudoreal[right & controlBool])
    
    control <- pseudoreal[controlBool]
    control <- control + abs(rnorm(n = length(control), mean = 0, sd = 0.00001))
    cases <- predicted[casesBool]
    cases <- abs(cases - abs(rnorm(n = length(cases), mean = 0, sd = 0.00001)))
    
    par(pty = "s")
    myROC <- roc(control = control,
                 cases = cases,
                 plot = TRUE,
                 col = "black",
                 lwd = 2,
                 print.auc = FALSE,
                 print.auc.x = 0.2,
                 print.auc.y = 0.65,
                 legacy.axes = TRUE)
    
    aucs <- append(x = aucs, values = auc(myROC)[1])
    
    legend(x = "topright",
           legend = paste("'",
                          uniqueClasses[1],
                          "' vs. '",
                          uniqueClasses[2],
                          "' (AUC: ",
                          as.character(round(aucs, 2)),
                          ")",
                          sep = ""),
           pch = 22,
           col = "black",
           pt.bg = "black",
           cex = 0.9,
           inset = insetLegend)
    
    par(pty = "m")
    
    return(list("control" = control,
                "cases" = cases,
                "AUC" = aucs))
    
  }else{
    
    for(i in 1:length(uniqueClasses)){
      
      classiReal <- groupsReal == uniqueClasses[i]
      classiPredicted <- groupsPredicted == uniqueClasses[i]
      
      classiReal[classiReal == 1] <- uniqueClasses[i]
      classiReal[classiReal == "FALSE"] <- "Other"
      
      classiPredicted[classiPredicted == 1] <- uniqueClasses[i]
      classiPredicted[classiPredicted == "FALSE"] <- "Other"
      
      wrong <- classiReal != classiPredicted
      right <- classiReal == classiPredicted
      
      pseudoreal <- apply(X = predictionProb, MARGIN = 1, FUN = min)
      predicted <- apply(X = predictionProb, MARGIN = 1, FUN = max)
      
      controlBool <- classiReal != "Other"
      casesBool <- classiReal == "Other"
      
      pseudoreal[wrong] <- mean(predicted[right & casesBool])
      predicted[wrong] <-  mean(pseudoreal[right & controlBool])
      
      control <- pseudoreal[controlBool]
      control <- control + abs(rnorm(n = length(control), mean = 0, sd = 0.001))
      cases <- predicted[casesBool]
      cases <- abs(cases - abs(rnorm(n = length(cases), mean = 0, sd = 0.001)))
      
      fillMeObs <- c(fillMeObs, control)
      fillMePred <- c(fillMePred, cases)
      
      if(i == 1){
        
        par(pty = "s")
        myROC <- roc(control = control,
                     cases = cases,
                     plot = TRUE,
                     col = mypalette[i],
                     lwd = 2,
                     print.auc = FALSE,
                     print.auc.x = 0.2,
                     print.auc.y = 0.65 - (0.05*(i-1)),
                     legacy.axes = TRUE)
        aucs <- append(x = aucs, values = round(auc(myROC)[1], 2))
        
      }else{
        
        myROC <- roc(control = control, cases = cases)
        aucs <- append(x = aucs, values = round(auc(myROC)[1], 2))
        plot.roc(x = myROC,
                 col = mypalette[i],
                 lwd = 2,
                 print.auc = FALSE,
                 print.auc.x = 0.2,
                 print.auc.y = 0.65 - (0.05*(i-1)),
                 add = TRUE)
        
      }
    }
    
    legend(x = "topright",
           legend = sprintf(paste0(sprintf("%s vs. All", uniqueClasses)," (AUC: %s)"), aucs),
           pch = 22,
           col = "black",
           pt.bg = mypalette,
           cex = 0.9,
           inset = insetLegend)
    
    par(pty = "s")
    
    myROC <- roc(control = fillMeObs,
                 cases = fillMePred,
                 plot = TRUE,
                 col = "black",
                 legacy.axes = TRUE)
    lastLegend <- paste0("Average predictor ROC curve (AUC: ",
                         as.character(round(auc(myROC)[1], 2)),
                         ")",
                         sep = "")
    legend(legend = lastLegend,
           x = "topright",
           pch = 15,
           col = "black",
           cex = 0.9,
           inset = c(0.025, 0.7))
    
    allAUCs <- c(aucs, auc(myROC)[1])
    names(allAUCs) <- c(uniqueClasses, "averageCurve")
    
    par(pty = "m")
    
    return(list("averageCases" = fillMeObs,
                "averagePred" = fillMePred,
                "allAUCs" = allAUCs))
    
  }
  
}

rm(groupsReal,
   groupsPredicted,
   predictionProb,
   insetLegend,
   
   uniqueClasses,
   mypalette,
   aucs,
   fillMeObs,
   fillMePred,
   
   u1,
   u2,
   groupIndex1,
   groupIndex2,
   littleMod,
   binaryControl,
   binaryCases,
   
   classiReal,
   classiPredicted,
   wrong,
   right,
   pseudoreal,
   predicted,
   controlBool,
   casesBool,
   control,
   cases,
   
   lastLegend)

library(pROC)
library(randomForest)

rf.iris <- randomForest(x = iris[,-5], y = iris[,5], proximity = TRUE,
                        importance = TRUE)

rf.iris

multiROC(groupsReal = iris[,5], groupsPredicted = rf.iris$predicted,
         predictionProb = rf.iris$votes)

## 20) multishapiro() and multilevene():

# 

multiShapiro <- function(protMat){
  
  shapiro <- unname(apply(X = as.matrix(protMat), MARGIN = 1,
                          FUN = function(x) shapiro.test(x)[[2]]))
  copyRowNames <- rownames(protMat)[which(shapiro >= 0.05)]
  protMat <- as.matrix(protMat[shapiro > 0.05,])
  if(dim(protMat)[2] == 1){
    protMat <- t(protMat)
    rownames(protMat) <- copyRowNames
  }
  
  return(protMat)
  
}

## 21) bioProcesses2():

# 

bioProcesses2 <- function(uniProtAccessionVector, pvalVec){
  
  if(!("package:UniprotR" %in% base::search())){
    library(UniprotR)
  }
  
  GOlist <- list()
  
  proteinProcesses <- GetProteinGOInfo(ProteinAccList = uniProtAccessionVector,
                                       directorypath = NULL)[,3]
  
  for(i in 1:length(proteinProcesses)){
    GOlist[[i]] <- unlist(strsplit(x = proteinProcesses[i], split = "; "))
  }
  names(GOlist) <- uniProtAccessionVector
  
  processesColumns<- unique(na.omit(unname(unlist(GOlist))))
  
  numberRowsProcesses <- length(uniProtAccessionVector)
  numberColumnsProcesses <- length(processesColumns)
  
  processesMatrix <- matrix(data = rep(0, numberRowsProcesses * numberColumnsProcesses),
                            nrow = numberRowsProcesses, byrow = TRUE)
  rownames(processesMatrix) <- uniProtAccessionVector
  colnames(processesMatrix) <- processesColumns
  
  for(i in 1:length(GOlist)){
    if(pvalVec[i] <= 0.05){
      processesMatrix[i,]  <- as.numeric(processesColumns %in% GOlist[[i]])
    }
  }
  
  processesMatrix <- processesMatrix[rowSums(processesMatrix) > 0,]
  
  return(processesMatrix)
  
}

## 22) pairwise.record():

# 

pairwise.record <- function(listResults,
                            filePath = "Z:/USUARIOS/JVINDEL/pairedwiseRecord.xlsx"){
  
  if(!("package:xlsx" %in% base::search())){
    library(xlsx)
  }
  
  namesSheets <- names(listResults)
  for(i in 1:length(namesSheets)){
    if(i == 1){
      write.xlsx2(x = listResults[[i]],
                  file = filePath,
                  row.names = TRUE,
                  col.names = TRUE,
                  sheetName = namesSheets[i])
    }else{
      write.xlsx2(x = listResults[[i]],
                  file = filePath,
                  row.names = TRUE,
                  col.names = TRUE,
                  sheetName = namesSheets[i],
                  append = TRUE)
    }
  }
  
}

pairwise.record(listResults = pairResults)

## 23) geneIDextraction():

# 

geneIDextraction <- function(geneDescription){
  
  genePattern <- "GN=(.*?) "
  geneID <- regmatches(geneDescription, regexpr(genePattern, geneDescription))
  geneID <- gsub(pattern = "GN=", replacement = "", x = geneID)
  geneID <- gsub(pattern = " ", replacement = "", x = geneID)
  
  realGeneID <- c()
  j <- 1
  for(i in 1:length(geneDescription)){
    istr <- geneDescription[i]
    if(grepl(geneID[j], istr, fixed = TRUE)){
      realGeneID <- append(x = realGeneID, values = geneID[j])
      j <- j + 1
    }else{
      realGeneID <- append(x = realGeneID, values = "")
    }
  }
  
  return(realGeneID)
}

## 24) adjANOVA():

# 

adjANOVA <- function(ANOVAres, adjMethod = "fdr"){
  
  postHocInd <- grep(pattern = "pval", x = colnames(ANOVAres))[-1]
  postHoc <- ANOVAres[,postHocInd]
  postHoc <- apply(X = postHoc, MARGIN = 2, FUN = as.numeric)
  rownames(postHoc) <- rownames(ANOVAres)
  postHoc <- apply(X = postHoc, MARGIN = 2, FUN = function(x) p.adjust(p = x, adjMethod))
  colnames(postHoc) <- paste0("adj.", colnames(postHoc), sep = "")
  ANOVAres[,postHocInd] <- postHoc
  colnames(ANOVAres)[postHocInd] <- paste0("adj.", colnames(ANOVAres)[postHocInd], sep = "")
  
  return(ANOVAres)

}

adjustedANOVA <- adjANOVA(ANOVAres = ANOVA)

## 25) justChangeIt():

# It transforms constant values along samples from the same groups for a
# certain feature, so t-test and ANOVA test can be computed normally, since
# variance will not equal zero:

justChangeIt <- function(dataset, classes){
  for(i in 1:nrow(dataset)){
    for(j in 1:length(classes)){
      jind <- classes == classes[j]
      if(length(unique(dataset[i,jind])) == 1){
        dataset[i,jind] <- abs(rnorm(n = length(dataset[i,jind]),
                                     mean = dataset[i,1],
                                     sd = dataset[i,1]/100))
      }
    }
  }
  return(dataset)
}

## 26) rescueAdj():

# It retrieves those proteins with at least one adjusted post-hoc p-value
# from all the adjusted post-hoc p-values generated after applying p-value
# adjustment for ANOVA results.

rescueAdj <- function(pvalsArr, chosen.pval = 0.05){
  chANOVA <- c()
  for(i in 1:nrow(pvalsArr)){
    if(sum(pvalsArr[i,] <= chosen.pval) > 0){
      chANOVA <- append(x = chANOVA, values = rownames(pvalsArr)[i])
    }
  }
  return(chANOVA)
}

## 27) specificAdj():

# From a matrix holding all ANOVA post-hoc p-values, you can selected between
# which groups you want statistical significance to be. This is chosen by
# introducing as an input a vector containing zeros and ones only, as long as
# there are columns in the matrix, where a zero represents no statistical
# significance, and a one represents statistical significance. This way,
# features with specific statistical significance properties can be retrieved.

specificAdj <- function(pvalsArr, zerosAndOnes){
  chANOVA <- c()
  for(i in 1:nrow(pvalsArr)){
    if(sum(as.numeric(pvalsArr[i,] <= 0.05) == zerosAndOnes) == length(zerosAndOnes)){
      chANOVA <- append(x = chANOVA, values = rownames(pvalsArr)[i])
    }
  }
  return(chANOVA)
}

## 28) multiBar():

# 

multiBar <- function(protValues, protName, groups,
                     pvals, onlySig = TRUE, chosenPVals = FALSE, whatPVals,
                     textCex = 1.5){
  
  protDataF <- data.frame(protValues, groups)
  colnames(protDataF) <- c(protName, "classes")
  
  height <- aggregate(protDataF[,1], list(protDataF[,2]), mean)[,2]
  error <- aggregate(protDataF[,1], list(protDataF[,2]), sd)[,2]
  
  chWidth <- 0.5
  chSpace <- 0.8
  firstPretty <- range(pretty(c(0, max(height))))[2]
  prodGroupSpaces <- length(unique(groups)) * (length(unique(groups)) - 1)
  
  rights <- c((chSpace/2) + (chWidth/2) + (chWidth/(2*prodGroupSpaces)))
  lefts <- c((chSpace/2) + (chWidth/2) + (chWidth/(2*prodGroupSpaces)))
  
  for(n in 1:(length(unique(groups))-1)){
    
    if(n == (length(unique(groups))-1)){
      tempRight <- (chSpace/2)*(n+1) +
        (chWidth/2)*((2*n)+1) -
        (chWidth/(2*prodGroupSpaces))
    }else{
      tempRight <- (chSpace/2)*(n+1) +
        (chWidth/2)*((2*n)+1) +
        (chWidth/(2*prodGroupSpaces))
    }
    
    tempLeft <- (chSpace/2)*(n+1) +
      (chWidth/2)*((2*n)+1) -
      (chWidth/(2*prodGroupSpaces))
    
    rights <- append(x = rights, values = tempRight)
    lefts <- append(x = lefts, values = tempLeft)
    
  }
  
  indComb <- list()
  namesIndComb <- c()
  k <- 1
  for(i in 1:length(unique(groups))){
    if(i < length(unique(groups))){
      for(j in (i+1):length(unique(groups))){
        indComb[[k]] <- c(i, j)
        tempPName <- paste(unique(groups)[i], unique(groups)[j], sep = "-")
        namesIndComb <- append(x = namesIndComb, values = tempPName)
        k <- k + 1
      }
    }
  }
  names(indComb) <- namesIndComb
  
  sigHeights <- c()
  textHeights <- c()
  
  if(onlySig){
    whichPVals <- which(pvals <= 0.05)
  }
  if(chosenPVals){
    whichPVals <- whatPVals
  }
  
  p <- 1
  q <- 2
  for(i in 1:length(whichPVals)){
    newSig <- max(height + error) + (p*(firstPretty/50))
    sigHeights <- append(x = sigHeights, values = newSig)
    newText <- max(height + error) + (q*(firstPretty/50))
    textHeights <- append(x = textHeights, values = newText)
    p <- p + 2
    q <- q + 2
  }
  
  finalPretty <- max(textHeights)
  
  ylabName <- paste(protName, " average normalized levels", sep = "")
  mainName <- paste(protName, " average levels barplot across groups", sep = "")
  
  bar <- barplot(height = height,
                 names.arg = unique(groups),
                 ylim = range(pretty(c(0, finalPretty))),
                 width = chWidth,
                 xlim = c(0,length(unique(groups))),
                 space = chSpace,
                 ylab = ylabName,
                 main = mainName,
                 xlab = "Groups")
  
  arrows(x0 = bar,
         y0 = height + error,
         y1 = height - error,
         angle = 90,
         code = 3,
         length = 0.25 * (5 / length(unique(groups))))
  
  if(length(whichPVals) >= 1){
    for(i in 1:length(whichPVals)){
      ########################################################################## !!!
      
      if(length(unique(groups)) == 2){
        tempStart <- 1
        tempEnd <- 2
      }
      ti <- whichPVals[i]
      newnames <- gsub(pattern = "adj.pval.", replacement = "", x = names(ti), fixed = TRUE)
      newnames <- gsub(pattern = "pval.", replacement = "", x = newnames, fixed = TRUE)
      group1 <- strsplit(x = newnames, split = "-", fixed = TRUE)[[1]][1]
      group2 <- strsplit(x = newnames, split = "-", fixed = TRUE)[[1]][2]
      orderMe <- c()
      orderMe <- append(x = orderMe, values = which(unique(groups) == group1))
      orderMe <- append(x = orderMe, values = which(unique(groups) == group2))
      orderMe <- orderMe[order(orderMe)]
      
      tempStart <- orderMe[1]
      tempEnd <- orderMe[2]
      ########################################################################## !!!
      # tempStart <- indComb[[ti]][1]
      # tempEnd <- indComb[[ti]][2]
      tempStart <- rights[tempStart]
      tempEnd <- lefts[tempEnd]
      tempMean <- (tempStart + tempEnd)/2
      littleSum <- firstPretty/100
      segments(x0 = tempStart,
               x1 = tempEnd,
               y0 = sigHeights[i])
      segments(x0 = tempStart,
               y0 = sigHeights[i],
               y1 = sigHeights[i] - littleSum)
      segments(x0 = tempEnd,
               y0 = sigHeights[i],
               y1 = sigHeights[i] - littleSum)
      tempPval <- pvals[ti]
      
      if(tempPval > 0.05){
        tempText <- "ns"
      }
      if(tempPval <= 0.05){
        tempText <- "*"
      }
      if(tempPval <= 0.01){
        tempText <- "**"
      }
      if(tempPval <= 0.001){
        tempText <- "***"
      }
      if(tempPval <= 0.0001){
        tempText <- "****"
      }
      
      text(x = tempMean, y = textHeights[i], labels = tempText, cex = textCex)
    }
  }
  
}

## 29) multiBox():

# 

multiBox <- function(protValues,
                     protName,
                     groups,
                     pvals,
                     onlySig = TRUE,
                     chosenPVals = FALSE,
                     whatPVals,
                     textCex = 1.5){
  
  protDataF <- data.frame(protValues, groups)
  colnames(protDataF) <- c(protName, "classes")
  
  rights <- 1:(length(unique(groups))) + 1/(length(unique(groups))*4)
  rights[length(rights)] <- length(rights) - 1/(length(rights)*4)
  lefts <- 1:(length(unique(groups))) - 1/(length(unique(groups))*4)
  lefts[1] <- 1 + 1/(length(lefts)*4)
  
  firstPretty <- range(pretty(c(min(protValues), max(protValues))))[2]
  secondPretty <- range(pretty(c(min(protValues), max(protValues))))[1]
  difPretty <- firstPretty - secondPretty
  
  indComb <- list()
  namesIndComb <- c()
  k <- 1
  for(i in 1:length(unique(groups))){
    if(i < length(unique(groups))){
      for(j in (i+1):length(unique(groups))){
        indComb[[k]] <- c(i, j)
        tempPName <- paste(unique(groups)[i], unique(groups)[j], sep = "-")
        namesIndComb <- append(x = namesIndComb, values = tempPName)
        k <- k + 1
      }
    }
  }
  names(indComb) <- namesIndComb
  
  sigHeights <- c()
  textHeights <- c()
  
  if(onlySig){
    whichPVals <- which(pvals <= 0.05)
  }
  if(chosenPVals){
    whichPVals <- whatPVals
  }
  
  p <- 1
  q <- 2
  for(i in 1:length(whichPVals)){
    newSig <- max(protValues) + (p*(difPretty/50))
    sigHeights <- append(x = sigHeights, values = newSig)
    newText <- max(protValues) + (q*(difPretty/50))
    textHeights <- append(x = textHeights, values = newText)
    p <- p + 2
    q <- q + 2
  }
  
  finalPretty <- max(textHeights)
  
  protDataF$classes <- factor(protDataF$classes , levels = unique(groups)) ########### !!!
  boxplot(protDataF[,1] ~ protDataF[,2],
          data = protDataF,
          pch = 21,
          bg = "grey",
          xaxt = "n",
          xlab = "Groups",
          ylab = paste(protName, " normalized levels", sep = ""),
          main = paste(protName, " normalized levels across groups", sep = ""),
          ylim = range(pretty(c(min(protValues), finalPretty))))
  
  axis(side = 1, at = 1:length(unique(groups)), labels = unique(groups))
  
  if(length(whichPVals) >= 1){
    for(i in 1:length(whichPVals)){
      ########################################################################## !!!
      
      if(length(unique(groups)) == 2){
        tempStart <- 1
        tempEnd <- 2
      }
      ti <- whichPVals[i]
      newnames <- gsub(pattern = "adj.pval.", replacement = "", x = names(ti), fixed = TRUE)
      newnames <- gsub(pattern = "pval.", replacement = "", x = newnames, fixed = TRUE)
      group1 <- strsplit(x = newnames, split = "-", fixed = TRUE)[[1]][1]
      group2 <- strsplit(x = newnames, split = "-", fixed = TRUE)[[1]][2]
      orderMe <- c()
      orderMe <- append(x = orderMe, values = which(unique(groups) == group1))
      orderMe <- append(x = orderMe, values = which(unique(groups) == group2))
      orderMe <- orderMe[order(orderMe)]
      
      tempStart <- orderMe[1]
      tempEnd <- orderMe[2]
      ########################################################################## !!!
      # tempStart <- indComb[[ti]][1]
      # tempEnd <- indComb[[ti]][2]
      
      tempStart <- rights[tempStart]
      tempEnd <- lefts[tempEnd]
      tempMean <- (tempStart + tempEnd)/2
      littleSum <- difPretty/100
      segments(x0 = tempStart,
               x1 = tempEnd,
               y0 = sigHeights[i])
      segments(x0 = tempStart,
               y0 = sigHeights[i],
               y1 = sigHeights[i] - littleSum)
      segments(x0 = tempEnd,
               y0 = sigHeights[i],
               y1 = sigHeights[i] - littleSum)
      tempPval <- pvals[ti]
      
      if(tempPval > 0.05){
        tempText <- "ns"
      }
      if(tempPval <= 0.05){
        tempText <- "*"
      }
      if(tempPval <= 0.01){
        tempText <- "**"
      }
      if(tempPval <= 0.001){
        tempText <- "***"
      }
      if(tempPval <= 0.0001){
        tempText <- "****"
      }
      
      text(x = tempMean, y = textHeights[i], labels = tempText, cex = textCex)
    }
  }
  
}

## 30) newAlteredProcesses():

# 

newAlteredProcesses <- function(refinedArr,
                                proteinVec){
  
  zero <- matrix(data = 0, nrow = nrow(refinedArr), ncol = ncol(refinedArr))
  rownames(zero) <- rownames(refinedArr)
  colnames(zero) <- colnames(refinedArr)
  
  trueProteins <- intersect(proteinVec, rownames(refinedArr))
  zero[trueProteins,] <- refinedArr[trueProteins,]
  
  refinedSum <- apply(X = refinedArr, MARGIN = 2, FUN = sum)
  zeroSum <- apply(X = zero, MARGIN = 2, FUN = sum)
  
  processesResults <- matrix(data = NA, nrow = length(refinedSum), ncol = 5)
  rownames(processesResults) <- names(refinedSum)
  colnames(processesResults) <- c("total.proteins",
                                  "altered.proteins",
                                  "protein.rate",
                                  "fisher.pvalue",
                                  "fisher.qvalue")
  processesResults[,1] <- refinedSum
  processesResults[,2] <- zeroSum
  processesResults[,3] <- zeroSum / refinedSum
  
  totalProteins <- nrow(refinedArr)
  alteredProteins <- length(trueProteins)
  sig <- alteredProteins
  noSig <- totalProteins - sig
  
  fisher.vector <- c()
  
  for(i in 1:length(refinedSum)){
    
    ni <- as.numeric(refinedSum[i])
    isig <- as.numeric(zeroSum[i])
    inosig <- ni - isig
    
    trueNoSig <- noSig - inosig
    trueSig <- sig - isig
    
    fisher.data <- data.frame("non.specific" = c(trueNoSig, trueSig),
                              "specific" = c(inosig, isig))
    rownames(fisher.data) <- c("non.significant", "significant")
    
    ipvalue <- as.numeric(fisher.test(fisher.data, alternative = "greater")$p.value)
    fisher.vector <- append(x = fisher.vector, values = ipvalue)
    
  }
  
  fisher.adjusted <- p.adjust(p = fisher.vector, "fdr")
  
  processesResults[,4] <- fisher.vector
  processesResults[,5] <- fisher.adjusted
  
  processesResults <- processesResults[order(processesResults[,4], decreasing = FALSE),]
  
  return(processesResults)
  
}

## 31) allProcessesExplained():

# 

allProcessesExplained <- function(refinedArr,
                                  descript,
                                  chosenPValue = 0.05,
                                  pValuesVector,
                                  logFCVector){
  
  zero <- matrix(data = 0, nrow = nrow(refinedArr), ncol = ncol(refinedArr))
  rownames(zero) <- rownames(refinedArr)
  colnames(zero) <- colnames(refinedArr)
  selectedProteins <- names(pValuesVector)[pValuesVector <= chosenPValue]
  trueSelectedProteins <- intersect(x = rownames(refinedArr), selectedProteins)
  zero[trueSelectedProteins,] <- refinedArr[trueSelectedProteins,]
  
  matList <- list()
  for(i in 1:ncol(refinedArr)){
    
    icol <- refinedArr[,i]
    iproteins <- names(icol)[icol == 1]
    imat <- data.frame(matrix(data = NA, nrow = length(iproteins), ncol = 8))
    imat[,1] <- colnames(refinedArr)[i]
    imat[,2] <- iproteins
    imat[,3] <- descript[iproteins,"description"]
    imat[,4] <- descript[iproteins,"gene.ID"]
    imat[,5] <- pValuesVector[iproteins]
    imat[,6] <- pValuesVector[iproteins] <= 0.05
    imat[,7] <- logFCVector[iproteins]
    isUpOrDown <- logFCVector[iproteins] >= 0
    isUpOrDown[isUpOrDown == TRUE] <- "Up"
    isUpOrDown[isUpOrDown == "FALSE"] <- "Down"
    imat[,8] <- isUpOrDown
    colnames(imat) <- c("biological.process",
                        "protein.code",
                        "description",
                        "gene.ID",
                        "q.value",
                        "is.significant.0.05",
                        "log2.FC",
                        "is.Up.Or.Down")
    imat <- imat[order(imat[,5], decreasing = FALSE),]
    matList[[i]] <- imat
    
  }
  names(matList) <- colnames(refinedArr)
  
  return(matList)
  
}

## 32) printTopProcesses():

# 

printTopProcesses <- function(processesMatrix,
                              processesExplained,
                              filePath,
                              howMany = 10){
  
  if(!("package:xlsx" %in% base::search())){
    library(xlsx)
  }
  
  topProcesses <- rownames(processesMatrix)[1:howMany]
  subList <- processesExplained[topProcesses]
  # topProcesses <- gsub(pattern = "\\s\\[.*\\]", replacement = "", x = topProcesses)
  topProcesses <- sprintf("process%s", 1:howMany)
  
  for(i in 1:length(subList)){
    if(i == 1){
      write.xlsx2(x = subList[[i]],
                  file = filePath,
                  sheetName = topProcesses[i],
                  col.names = TRUE,
                  row.names = FALSE,
                  append = FALSE)
    }else{
      write.xlsx2(x = subList[[i]],
                  file = filePath,
                  sheetName = topProcesses[i],
                  col.names = TRUE,
                  row.names = FALSE,
                  append = TRUE)
    }
  }
  
}

## 33) :

# 



## 34) photoBox() + photoBar():

# 

photoBox <- function(is.already = TRUE,
                     nameDir,
                     where,
                     dat,
                     chosenQuality = 100,
                     chosenWidth = 600,
                     chosenHeight = 480,
                     pvalues,
                     groups2,
                     is.ANOVA = TRUE){
  
  if(!(is.already)){
    where <- paste(where, nameDir, "/", sep = "")
    dir.create(path = where)
  }
  
  for(i in 1:nrow(dat)){
    fileName <- paste(rownames(dat)[i], ".jpeg", sep = "")
    filePath <- paste(where, fileName, sep = "")
    jpeg(file = filePath,
         quality = chosenQuality,
         width = chosenWidth,
         height = chosenHeight)
    if(is.ANOVA){
      multiBox(protValues = dat[rownames(dat)[i],],
               protName = rownames(dat)[i],
               groups = groups2,
               pvals = pvalues[i,],
               onlySig = TRUE,
               chosenPVals = FALSE)
    }else{
      multiBox(protValues = dat[rownames(dat)[i],],
               protName = rownames(dat)[i],
               groups = groups2,
               pvals = pvalues[i],
               onlySig = TRUE,
               chosenPVals = FALSE)
    }
    
    dev.off()
  }
  
}

photoBox(is.already = FALSE,
         nameDir = "test",
         where = "C:/Users/Centaurus2/Desktop/",
         dat = quantNia[prots,],
         pvalues = proteoMat[prots,2],
         groups2 = groupsNia1,
         is.ANOVA = FALSE)

photoBox(is.already = TRUE,
         where = "C:/Users/Centaurus2/Desktop/try/",
         dat = limmaRF,
         pvalues = ANOVA[rownames(limmaRF), grep(pattern = "pval.", x = colnames(ANOVA), fixed = TRUE)],
         groups2 = classes,
         is.ANOVA = TRUE)

photoBar <- function(is.already = TRUE,
                     nameDir,
                     where,
                     dat,
                     chosenQuality = 100,
                     chosenWidth = 600,
                     chosenHeight = 480,
                     pvalues,
                     groups2,
                     is.ANOVA = TRUE){
  
  if(!(is.already)){
    where <- paste(where, nameDir, "/", sep = "")
    dir.create(path = where)
  }
  
  for(i in 1:nrow(dat)){
    fileName <- paste(rownames(dat)[i], ".jpeg", sep = "")
    filePath <- paste(where, fileName, sep = "")
    jpeg(file = filePath,
         quality = chosenQuality,
         width = chosenWidth,
         height = chosenHeight)
    if(is.ANOVA){
      multiBar(protValues = dat[rownames(dat)[i],],
               protName = rownames(dat)[i],
               groups = groups2,
               pvals = pvalues[i,],
               onlySig = TRUE,
               chosenPVals = FALSE)
    }else{
      multiBar(protValues = dat[rownames(dat)[i],],
               protName = rownames(dat)[i],
               groups = groups2,
               pvals = pvalues[i],
               onlySig = TRUE,
               chosenPVals = FALSE)
    }
    
    dev.off()
  }
  
}

photoBar(is.already = FALSE,
         nameDir = "test",
         where = "C:/Users/Centaurus2/Desktop/",
         dat = quantNia[prots,],
         pvalues = proteoMat[prots,2],
         groups2 = groupsNia1,
         is.ANOVA = FALSE)

photoBar(is.already = TRUE,
         where = "C:/Users/Centaurus2/Desktop/try/",
         dat = limmaRF,
         pvalues = ANOVA[rownames(limmaRF), grep(pattern = "pval.", x = colnames(ANOVA), fixed = TRUE)],
         groups2 = classes,
         is.ANOVA = TRUE)

## 35) caretPartition():

# 

caretPartition <- function(dataSet,
                           classCol = ncol(dataSet),
                           prop = 0.8,
                           is.seed = FALSE,
                           nseed = 1){
  
  if(!("package:caret" %in% base::search())){
    library(caret)
  }
  
  if(is.seed){
    set.seed(nseed)
  }
  
  dataTrain <- createDataPartition(y = dataSet[, classCol], p = prop, list = FALSE)
  dataTest <- dataSet[-dataTrain,]
  dataTrain <- dataSet[dataTrain,]
  dataTrainValues <- dataTrain[,-classCol]
  dataTrainClasses <- dataTrain[,classCol]
  dataTestValues <- dataTest[,-classCol]
  dataTestClasses <- dataTest[,classCol]
  
  results <- list()
  results[[1]] <- dataTrain
  results[[2]] <- dataTrainValues
  results[[3]] <- dataTrainClasses
  results[[4]] <- dataTest
  results[[5]] <- dataTestValues
  results[[6]] <- dataTestClasses
  
  names(results) <- c("dataTrain",
                      "dataTrainValues",
                      "dataTrainClasses",
                      "dataTest",
                      "dataTestValues",
                      "dataTestClasses")
  
  return(results)
  
}

## 36) howManyLoops():

# 

howManyLoops <- function(nfeat, wantedLoops){
  prob <- seq(1 - 0.001, 0.001, by = -0.001)
  iterationsVector <- c()
  for(i in 1:length(prob)){
    remaining <- c()
    remember <- nfeat
    k <- 1
    while(remember > 1){
      remember <- floor(remember * prob[i])
      remaining <- append(x = remaining, values = remember)
    }
    iterationsVector <- append(x = iterationsVector, values = length(remaining))
  }
  
  return(prob[iterationsVector == wantedLoops])
}

## 37) recursiveRandomForest3():

# 

recursiveRandomForest3 <- function(dataset,
                                   groups,
                                   treeNumber = 1000,
                                   retentionProportion = 0.8,
                                   chosenIterationsNumber = 5,
                                   withNormalization = TRUE,
                                   topNumber = 25,
                                   iterationsBest = 100,
                                   searchForBest = TRUE,
                                   howManyFeats = 8,
                                   minimization = TRUE){
  
  if(!("package:randomForest" %in% base::search())){
    library(randomForest)
  }
  
  importanceMatrix <- matrix(data = 0,
                             nrow = ncol(dataset),
                             ncol = 4)
  rownames(importanceMatrix) <- colnames(dataset)
  colnames(importanceMatrix) <- c("feature.index",
                                  "importance",
                                  "normalized.importance",
                                  "standard.cumulative")
  importanceMatrix[,"feature.index"] <- 1:nrow(importanceMatrix)
  
  iterations <- 1
  
  while(iterations <= chosenIterationsNumber){
    
    print(paste("Iteration: ", as.character(iterations), sep = ""))
    tempDataset <- dataset
    
    retentionLoop <- 1
    
    while(!(is.null(ncol(tempDataset)))){
      
      tempRF <- randomForest(x = tempDataset,
                             y = groups,
                             importance = TRUE,
                             ntree = treeNumber)
      
      tempImportance <- tempRF$importance
      
      vecImp <- tempImportance[,"MeanDecreaseAccuracy"]
      
      boolImp <- vecImp > 0
      boolNoImp <- vecImp < 0
      
      if(withNormalization){
        sumImp <- sum(vecImp[boolImp])
        sumNoImp <- sum(vecImp[boolNoImp])
        vecImp[boolImp] <- vecImp[boolImp] / sumImp
        vecImp[boolNoImp] <- vecImp[boolNoImp] / sumNoImp
      }
      
      importanceMatrix[rownames(tempImportance),"importance"] <-
        importanceMatrix[rownames(tempImportance),"importance"] + vecImp
      
      newOrder <- order(vecImp, decreasing = TRUE)
      tempImportance <- tempImportance[newOrder,]
      # View(tempImportance)
      
      retention <- floor(nrow(tempImportance) * retentionProportion)
      print(paste("Retained features (iteration: ",
                  as.character(iterations),
                  "; retention loop: ",
                  as.character(retentionLoop),
                  "): ",
                  as.character(retention),
                  sep = ""))
      featsRetained <- rownames(tempImportance)[1:retention]
      
      tempDataset <- tempDataset[,featsRetained]
      
      retentionLoop <- retentionLoop + 1
    }
    
    iterations <- iterations + 1
  }
  
  orderedMatrix <- order(importanceMatrix[,"importance"], decreasing = TRUE)
  orderedMatrix <- importanceMatrix[orderedMatrix,]
  
  boolOrdGreat <- orderedMatrix[,"importance"] > 0
  boolOrdLess <- orderedMatrix[,"importance"] < 0
  
  sumGreat <- sum(orderedMatrix[boolOrdGreat,"importance"])
  sumLess <- sum(orderedMatrix[boolOrdLess,"importance"])
  
  orderedMatrix[boolOrdGreat,"normalized.importance"] <-
    orderedMatrix[boolOrdGreat,"importance"] / sumGreat
  orderedMatrix[boolOrdLess,"normalized.importance"] <-
    -(orderedMatrix[boolOrdLess,"importance"] / sumLess)
  
  orderedMatrix[,"standard.cumulative"] <- cumsum(orderedMatrix[,"normalized.importance"])
  
  print("Importance matrix calculation ended. Generating best random forest.")
  
  iterations <- 1
  
  oobFeats <- c()
  oobBest <- 1
  
  top <- rownames(orderedMatrix)[1:topNumber]
  
  bestDataset <- dataset[,top]
  
  while(iterations <= iterationsBest){
    
    tempDataset <- bestDataset
    if(searchForBest){
      print(paste("Number of iteration: ", as.character(iterations), sep = ""))
    }
    
    if(searchForBest){
      
      while(!(is.null(ncol(tempDataset)))){
        
        tempRF <- randomForest(x = tempDataset,
                               y = groups,
                               importance = TRUE,
                               proximity = TRUE,
                               ntree = treeNumber)
        
        conf <- tempRF$confusion[,-ncol(tempRF$confusion)]
        oob <- 1 - (sum(diag(conf)) / sum(sum(conf)))
        
        if(minimization){
          if(oob < oobBest){
            print(paste("New classifier found. OOB: ",
                        as.character(round(oob, 4)),
                        sep = ""))
            oobBest <- oob
            oobFeats <- colnames(tempDataset)
            bestRF <- tempRF
          }
          if(oob == oobBest & length(oobFeats) > length(colnames(tempDataset))){
            print(paste("Number of proteins reduced in new classifier. New number of proteins: ",
                        as.character(length(colnames(tempDataset))),
                        sep = ""))
            oobBest <- oob
            oobFeats <- colnames(tempDataset)
            bestRF <- tempRF
          }
        }else{
          if(oob < oobBest){
            print(paste("New classifier found. OOB: ",
                        as.character(round(oob, 4)),
                        sep = ""))
            oobBest <- oob
            oobFeats <- colnames(tempDataset)
            bestRF <- tempRF
          }
        }
        
        importanceRF <- tempRF$importance[,"MeanDecreaseAccuracy"]
        retainedFeats <- rownames(tempRF$importance[order(importanceRF, decreasing = TRUE),])
        retainedFeats <- retainedFeats[-length(retainedFeats)]
        tempDataset <- tempDataset[,retainedFeats]
        
      }
      
    }else{
      
      while(!(is.null(ncol(tempDataset)))){
        
        tempRF <- randomForest(x = tempDataset,
                               y = groups,
                               importance = TRUE,
                               proximity = TRUE,
                               ntree = treeNumber)
        
        if(ncol(tempDataset) == howManyFeats){
          print(paste("Number of iteration (selected number of features: ",
                      as.character(howManyFeats),
                      "): ",
                      as.character(iterations),
                      sep = ""))
          conf <- tempRF$confusion[,-ncol(tempRF$confusion)]
          oob <- 1 - (sum(diag(conf)) / sum(sum(conf)))
          if(oob < oobBest){
            print(paste("New classifier found. OOB: ",
                        as.character(round(oob, 4)),
                        sep = ""))
            oobBest <- oob
            oobFeats <- colnames(tempDataset)
            bestRF <- tempRF
          }
        }
        
        importanceRF <- tempRF$importance[,"MeanDecreaseAccuracy"]
        retainedFeats <- rownames(tempRF$importance[order(importanceRF, decreasing = TRUE),])
        retainedFeats <- retainedFeats[-length(retainedFeats)]
        tempDataset <- tempDataset[,retainedFeats]
        
      }
      
    }
    
    iterations <- iterations + 1
    if(oobBest == 0){
      
    }
    
  }
  
  print("Done.")
  
  resultsList <- list()
  resultsList[[1]] <- orderedMatrix
  resultsList[[2]] <- oobFeats
  resultsList[[3]] <- bestRF
  
  names(resultsList) <- c("importance.matrix", "chosen.features", "best.RF")
  
  return(resultsList)
  
}

## 38) neoProt5(), and pairwise.neoProt2(), multiANOVA3():

neoProt5 <- function(procMat,
                     indA = grep(pattern = "Control", x = colnames(procMat)),
                     indB = setdiff(1:ncol(procMat),indA),
                     varBool = TRUE,
                     pairBool = FALSE,
                     adjMet = "fdr",
                     altHyp = FALSE,
                     is.mu = FALSE){
  vec.pval <- c()
  vec.FC <- c()
  
  for(i in 1:nrow(procMat)){
    if(altHyp == TRUE & is.mu == FALSE){
      meanA <- mean(procMat[i, indA])
      meanB <- mean(procMat[i, indB])
      if(meanA >= meanB){
        alternativeValue <- "greater"
        pval <- t.test(x = procMat[i, indA],
                       y = procMat[i, indB],
                       var.equal = varBool,
                       paired = pairBool,
                       alternative = alternativeValue)$p.value
        FC <- mean(procMat[i, indA]) - mean(procMat[i, indB])
        vec.pval <- append(x = vec.pval, values = pval)
        vec.FC <- append(x = vec.FC, values = FC)
      }
      if(meanA < meanB){
        alternativeValue <- "less"
        pval <- t.test(x = procMat[i, indA],
                       y = procMat[i, indB],
                       var.equal = varBool,
                       paired = pairBool,
                       alternative = alternativeValue)$p.value
        FC <- mean(procMat[i, indA]) - mean(procMat[i, indB])
        vec.pval <- append(x = vec.pval, values = pval)
        vec.FC <- append(x = vec.FC, values = FC)
      }
    }
    if(altHyp == FALSE & is.mu == TRUE){
      meanA <- mean(procMat[i, indA])
      meanB <- mean(procMat[i, indB])
      if(meanA >= meanB){
        pval <- t.test(x = procMat[i, indA],
                       y = procMat[i, indB],
                       var.equal = varBool,
                       paired = pairBool,
                       mu = meanB - meanA)$p.value
        FC <- mean(procMat[i, indA]) - mean(procMat[i, indB])
        vec.pval <- append(x = vec.pval, values = pval)
        vec.FC <- append(x = vec.FC, values = FC)
      }
      if(meanA < meanB){
        pval <- t.test(x = procMat[i, indA],
                       y = procMat[i, indB],
                       var.equal = varBool,
                       paired = pairBool,
                       mu = meanB - meanA)$p.value
        FC <- mean(procMat[i, indA]) - mean(procMat[i, indB])
        vec.pval <- append(x = vec.pval, values = pval)
        vec.FC <- append(x = vec.FC, values = FC)
      }
    }
    if(altHyp == TRUE & is.mu == TRUE){
      meanA <- mean(procMat[i, indA])
      meanB <- mean(procMat[i, indB])
      if(meanA >= meanB){
        alternativeValue <- "greater"
        pval <- t.test(x = procMat[i, indA],
                       y = procMat[i, indB],
                       var.equal = varBool,
                       paired = pairBool,
                       alternative = alternativeValue,
                       mu = meanB - meanA)$p.value
        FC <- mean(procMat[i, indA]) - mean(procMat[i, indB])
        vec.pval <- append(x = vec.pval, values = pval)
        vec.FC <- append(x = vec.FC, values = FC)
      }
      if(meanA < meanB){
        alternativeValue <- "less"
        pval <- t.test(x = procMat[i, indA],
                       y = procMat[i, indB],
                       var.equal = varBool,
                       paired = pairBool,
                       alternative = alternativeValue,
                       mu = meanB - meanA)$p.value
        FC <- mean(procMat[i, indA]) - mean(procMat[i, indB])
        vec.pval <- append(x = vec.pval, values = pval)
        vec.FC <- append(x = vec.FC, values = FC)
      }
    }
    if(altHyp == FALSE & is.mu == FALSE){
      pval <- t.test(x = procMat[i, indA],
                     y = procMat[i, indB],
                     var.equal = varBool,
                     paired = pairBool)$p.value
      FC <- mean(procMat[i, indA]) - mean(procMat[i, indB])
      vec.pval <- append(x = vec.pval, values = pval)
      vec.FC <- append(x = vec.FC, values = FC)
    }
  }
  
  adj.pval <- p.adjust(p = vec.pval, method = adjMet)
  finalMat <- cbind("pval" = vec.pval,
                    "adj.pval" = adj.pval,
                    "-log10.pval" = -log10(vec.pval),
                    "-log10.adj.pval" = -log10(adj.pval),
                    "log2.vec.FC" = vec.FC)
  rownames(finalMat) <- rownames(procMat)
  return(finalMat)
}

################################################################################

pairwise.neoProt2 <- function(matr,
                              classes,
                              varBool2 = TRUE,
                              pairBool2 = FALSE,
                              adjMet2 = "fdr", 
                              altHyp2 = FALSE,
                              is.mu2 = FALSE){
  vecNames <- c()
  listCombinations <- list()
  k <- 1
  for(i in 1:length(classes)){
    if((i+1) %in% 1:length(classes)){
      for(j in (i+1):length(classes)){
        nameElement <- paste(classes[i],  "-", classes[j], sep = "")
        vecNames <- append(x = vecNames, values = nameElement)
        firstInd <- grep(pattern = classes[i], x = colnames(matr))
        secInd <- grep(pattern = classes[j], x = colnames(matr))
        tempMatr <- matr[,c(firstInd,secInd)]
        firstInd <- grep(pattern = classes[i], x = colnames(tempMatr))
        secInd <- grep(pattern = classes[j], x = colnames(tempMatr))
        tempResult <- neoProt5(procMat = tempMatr,
                               indA = firstInd,
                               indB = secInd,
                               varBool = varBool2,
                               pairBool = pairBool2,
                               adjMet = adjMet2,
                               altHyp = altHyp2,
                               is.mu = is.mu2)
        tempResult <- tempResult[order(tempResult[,1], decreasing = FALSE),]
        listCombinations[[k]] <- tempResult
        k <- k + 1
      }
    }
  }
  names(listCombinations) <- vecNames
  return(listCombinations)
}

################################################################################

multiANOVA3 <- function(dat, classes, adjMet = "BH", posthoc = "tukey"){
  
  if(!("package:DescTools" %in% base::search())){
    library(DescTools)
  }
  
  n <- nlevels(classes)
  nrowShellp <- nrow(dat)
  ncolShellp <- 1 + (n * ((n - 1)/2))
  ANOVAshellp <- matrix(data = rep(NA, (nrowShellp * ncolShellp)),
                        nrow = nrowShellp)
  rownames(ANOVAshellp) <- rownames(dat)
  
  nrowShellFC <- nrow(dat)
  ncolShellFC <- n * (n - 1)
  ANOVAshellFC <- matrix(data = rep(NA, (nrowShellFC * ncolShellFC)),
                         nrow = nrowShellFC)
  rownames(ANOVAshellFC) <- rownames(dat)
  allFCNames <- c()
  
  for(i in 1:nrowShellp){
    
    aovDataFrame <- cbind.data.frame(dat[i,], classes)
    firstColName <- rownames(dat)[i]
    colnames(aovDataFrame)[1] <- firstColName
    
    ANOVA <- aov(formula = aovDataFrame[,1] ~ aovDataFrame[,2], data = aovDataFrame)
    ANOVApval <- summary(ANOVA)[[1]][[5]][1]
    if(posthoc == "tukey"){
      tukey <- TukeyHSD(ANOVA)
      posthoc.pvals <- tukey[[1]][,4]
      allPVals <- unname(c(ANOVApval, posthoc.pvals))
    }else{
      posthocResults <- PostHocTest(x = ANOVA, method = posthoc)
      posthoc.pvals <- posthocResults[[1]][,4]
      allPVals <- unname(c(ANOVApval, posthoc.pvals))
    }
    
    if(i == 1){
      colnames(ANOVAshellp) <- c("pval.Ftest", paste("pval.", names(posthoc.pvals), sep = ""))
    }
    
    ANOVAshellp[i,] <- allPVals
    
    allFC <- c()
    aovMeans <- aggregate(aovDataFrame[,1], list(aovDataFrame[,2]), mean)
    for(j in 1:nrow(aovMeans)){
      for(k in 1:nrow(aovMeans)){
        if(j != k){
          if(i == 1){
            FCname <-  paste("log2.ratio.",
                             as.character(aovMeans[j,1]),
                             "-",
                             as.character(aovMeans[k,1]),
                             sep = "")
            allFCNames <- append(x = allFCNames, values = FCname)
          }
          FC <- aovMeans[j,2] - aovMeans[k,2]
          allFC <- append(x = allFC, values = FC)
        }
      }
    }
    
    if(i == 1){
      colnames(ANOVAshellFC) <- allFCNames
    }
    
    ANOVAshellFC[i,] <- allFC
  }
  ANOVAq <- p.adjust(p = ANOVAshellp[,1], method = adjMet)
  
  result <- cbind(ANOVAshellp[,1], ANOVAq, ANOVAshellp[,-1], ANOVAshellFC)
  colnames(result)[1:2] <- c("pvalue.Ftest", "qvalue.Ftest")
  return(result)
}

## 39) mfuzzing():

# 

mfuzzing <- function(aggregatedResult,
                     chosenRange = 2:50){
  
  if(!("package:Mfuzz" %in% base::search())){
    library(Mfuzz)
  } 
  
  allMyResults <- list()
  
  aggSet <- ExpressionSet(assayData = aggregatedResult)
  aggTmp <- filter.std(aggSet, min.std = 0)
  
  originalProteins <- rownames(aggSet)
  filteredProteins <- rownames(aggTmp@assayData$exprs)
  filteredOut <- setdiff(x = originalProteins, y = filteredProteins)
  allMyResults[[1]] <- originalProteins
  allMyResults[[2]] <- filteredProteins
  allMyResults[[3]] <- filteredOut
  
  standAgg <- standardise(aggTmp)
  allMyResults[[4]] <- standAgg
  mAgg <- mestimate(standAgg)
  allMyResults[[5]] <- mAgg
  dAgg <- Dmin(eset = standAgg, m = mAgg, crange = chosenRange)
  allMyResults[[6]] <- dAgg
  
  plot(x = chosenRange,
       y = dAgg,
       pch = 16,
       cex = 0.8,
       col = "black",
       xlab = "Number of clusters",
       ylab = "Minimum distance 'D min' between cluster centroid",
       main = "Minimum distance between cluster centroid vs. Number of clusters",
       xlim = range(pretty(chosenRange)),
       ylim = range(pretty(dAgg)))
  points(x = chosenRange,
         y = dAgg,
         col = "black",
         type = "l",
         cex = 1)
  
  names(allMyResults) <- c("original.features",
                           "filtered.in",
                           "filtered.out",
                           "standarized.data",
                           "m.fuzzification",
                           "d.parameter")
  
  return(allMyResults)
  
}

## 40) clAndPlot():

# 

clAndPlot <- function(mfuzzRes,
                      chosenC,
                      chosenMF = c(3, 2),
                      chosenTimes,
                      xlab2 = "Time (h)"){
  
  if(!("package:Mfuzz" %in% base::search())){
    library(Mfuzz)
  }
  
  clObj <- mfuzz(eset = mfuzzRes[["standarized.data"]],
                 centers = chosenC,
                 m = mfuzzRes[["m.fuzzification"]])
  mfuzz.plot2(eset = mfuzzRes[["standarized.data"]],
              cl = clObj,
              mfrow = chosenMF,
              time.labels = chosenTimes,
              xlab = xlab2)
  return(clObj)
  
}

## 41) reducedDescription():

# 

reducedDescription <- function(fullDescription){
  
  re <- regexpr(".* OS=", fullDescription[,2])
  ss <- substr(x = fullDescription[,2],
               start = re,
               stop = attr(x = re, which = "match.length") - 4)
  best <- paste(ss, " (", rownames(fullDescription), ")", sep = "")
  names(best) <- rownames(fullDescription)
  return(best)
  
}

## 42) multiBox2() + photoBox2():

multiBox2 <- function(protValues,
                      protName,
                      groups,
                      pvals,
                      onlySig = TRUE,
                      chosenPVals = FALSE,
                      whatPVals,
                      textCex = 1.5,
                      main2,
                      isNorm = TRUE){
  
  protDataF <- data.frame(protValues, groups)
  colnames(protDataF) <- c(protName, "classes")
  
  rights <- 1:(length(unique(groups))) + 1/(length(unique(groups))*4)
  rights[length(rights)] <- length(rights) - 1/(length(rights)*4)
  lefts <- 1:(length(unique(groups))) - 1/(length(unique(groups))*4)
  lefts[1] <- 1 + 1/(length(lefts)*4)
  
  firstPretty <- range(pretty(c(min(protValues), max(protValues))))[2]
  secondPretty <- range(pretty(c(min(protValues), max(protValues))))[1]
  difPretty <- firstPretty - secondPretty
  
  indComb <- list()
  namesIndComb <- c()
  k <- 1
  for(i in 1:length(unique(groups))){
    if(i < length(unique(groups))){
      for(j in (i+1):length(unique(groups))){
        indComb[[k]] <- c(i, j)
        tempPName <- paste(unique(groups)[i], unique(groups)[j], sep = "-")
        namesIndComb <- append(x = namesIndComb, values = tempPName)
        k <- k + 1
      }
    }
  }
  names(indComb) <- namesIndComb
  
  sigHeights <- c()
  textHeights <- c()
  
  if(onlySig){
    whichPVals <- which(pvals <= 0.05)
  }
  if(chosenPVals){
    whichPVals <- whatPVals
  }
  
  p <- 1
  q <- 2
  for(i in 1:length(whichPVals)){
    newSig <- max(protValues) + (p*(difPretty/50))
    sigHeights <- append(x = sigHeights, values = newSig)
    newText <- max(protValues) + (q*(difPretty/50))
    textHeights <- append(x = textHeights, values = newText)
    p <- p + 2
    q <- q + 2
  }
  
  finalPretty <- max(textHeights)
  
  protDataF$classes <- factor(protDataF$classes , levels = unique(groups)) ########### !!!
  
  if(isNorm){
    boxplotYLab <- paste(protName, " normalized levels", sep = "")
  }else{
    boxplotYLab <- paste(protName, " raw levels", sep = "")
  }
  
  boxplot(protDataF[,1] ~ protDataF[,2],
          data = protDataF,
          pch = 21,
          bg = "grey",
          xaxt = "n",
          # xlab = "", # 18/11/2022
          xlab = "Groups",
          ylab = boxplotYLab,
          main = main2,
          ylim = range(pretty(c(min(protValues), finalPretty))))
  
  # axis(side = 1, at = 1:length(unique(groups)), labels = unique(groups), las = 2) # 18/11/2022 las
  axis(side = 1, at = 1:length(unique(groups)), labels = unique(groups))
  
  if(length(whichPVals) >= 1){
    for(i in 1:length(whichPVals)){
      ########################################################################## !!!
      
      if(length(unique(groups)) == 2){
        tempStart <- 1
        tempEnd <- 2
      }
      ti <- whichPVals[i]
      newnames <- gsub(pattern = "adj.pval.", replacement = "", x = names(ti), fixed = TRUE)
      newnames <- gsub(pattern = "pval.", replacement = "", x = newnames, fixed = TRUE)
      group1 <- strsplit(x = newnames, split = "-", fixed = TRUE)[[1]][1]
      group2 <- strsplit(x = newnames, split = "-", fixed = TRUE)[[1]][2]
      orderMe <- c()
      orderMe <- append(x = orderMe, values = which(unique(groups) == group1))
      orderMe <- append(x = orderMe, values = which(unique(groups) == group2))
      orderMe <- orderMe[order(orderMe)]
      
      tempStart <- orderMe[1]
      tempEnd <- orderMe[2]
      ########################################################################## !!!
      # tempStart <- indComb[[ti]][1]
      # tempEnd <- indComb[[ti]][2]
      
      tempStart <- rights[tempStart]
      tempEnd <- lefts[tempEnd]
      tempMean <- (tempStart + tempEnd)/2
      littleSum <- difPretty/100
      segments(x0 = tempStart,
               x1 = tempEnd,
               y0 = sigHeights[i])
      segments(x0 = tempStart,
               y0 = sigHeights[i],
               y1 = sigHeights[i] - littleSum)
      segments(x0 = tempEnd,
               y0 = sigHeights[i],
               y1 = sigHeights[i] - littleSum)
      tempPval <- pvals[ti]
      
      if(tempPval > 0.05){
        tempText <- "ns"
      }
      if(tempPval <= 0.05){
        tempText <- "*"
      }
      if(tempPval <= 0.01){
        tempText <- "**"
      }
      if(tempPval <= 0.001){
        tempText <- "***"
      }
      if(tempPval <= 0.0001){
        tempText <- "****"
      }
      
      text(x = tempMean, y = textHeights[i], labels = tempText, cex = textCex)
    }
  }
  
}

photoBox2 <- function(is.already = TRUE,
                      nameDir,
                      where,
                      dat,
                      chosenQuality = 100,
                      chosenWidth = 600,
                      chosenHeight = 480,
                      pvalues,
                      groups2,
                      is.ANOVA = TRUE,
                      main3,
                      isNorm2 = TRUE){
  
  if(!(is.already)){
    where <- paste(where, nameDir, "/", sep = "")
    dir.create(path = where)
  }
  
  for(i in 1:nrow(dat)){
    fileName <- paste(rownames(dat)[i], ".jpeg", sep = "")
    # fileName <- paste(as.character(i), ".jpeg", sep = "") # 18/11/2022
    filePath <- paste(where, fileName, sep = "")
    jpeg(file = filePath,
         quality = chosenQuality,
         width = chosenWidth,
         height = chosenHeight)
    if(is.ANOVA){
      multiBox2(protValues = dat[rownames(dat)[i],],
                protName = rownames(dat)[i],
                groups = groups2,
                pvals = pvalues[i,],
                onlySig = TRUE,
                chosenPVals = FALSE,
                main2 = main3[i],
                isNorm = isNorm2)
    }else{
      multiBox2(protValues = dat[rownames(dat)[i],],
                protName = rownames(dat)[i],
                groups = groups2,
                pvals = pvalues[i],
                onlySig = TRUE,
                chosenPVals = FALSE,
                main2 = main3[i],
                isNorm = isNorm2)
    }
    
    dev.off()
  }
  
}

## 43) proteinsOverPVal():

proteinsOverPVal <- function(ttestMatrix){
  
  xAxis <- seq(from = 0.0001, to = 0.05, by = 0.0001)
  yAxis <- sapply(X = xAxis, FUN = function(x) {sum(ttestMatrix[,"adj.pval"] <= x)})
  plot(x = rev(xAxis),
       y = yAxis,
       type = "l",
       xlab = "P-value threshold",
       ylab = "Number of significant proteins",
       main = "Number of significant proteins considering a p-value threshold",
       xlim = range(pretty(xAxis)),
       ylim = range(pretty(yAxis)),
       col = "black",
       lwd = 1,
       xaxt = "n")
  axis(side = 1, at = pretty(xAxis), labels = rev(pretty(xAxis)))
  newX <- c(0.0001, 0.001, 0.01, 0.05)
  points(x = c((0.05 + 0.0001) - newX[-length(newX)], 0),
         y = sapply(X = newX, FUN = function(x) {sum(ttestMatrix[,"adj.pval"] <= x)}),
         pch = 21,
         col = "black",
         bg = "black",
         cex = 1)
  legend(x = "bottomleft", 
         legend = c("Significant proteins (t-test)"),
         inset = c(0.05, 0.1),
         pch = 21,
         pt.bg = "black",
         lty = 1,
         col = c("black"))
  
}

## 44) KEGG functions:

# 

keggProcesses <- function(rawData,
                          classesVector,
                          keyType = "UNIPROT",
                          is.pval.and.log = TRUE,
                          pval,
                          qval,
                          log2FC){
  
  # Loads necessary packages:
  if(!("package:dplyr" %in% base::search())){
    library(dplyr)
  }
  if(!("package:DESeq2" %in% base::search())){
    library(DESeq2)
  }
  if(!("package:AnnotationDbi" %in% base::search())){
    library(AnnotationDbi)
  }
  if(!("package:org.Hs.eg.db" %in% base::search())){
    library(org.Hs.eg.db)
  }
  if(!("package:pathview" %in% base::search())){
    library(pathview)
  }
  if(!("package:gage" %in% base::search())){
    library(gage)
  }
  if(!("package:gageData" %in% base::search())){
    library(gageData)
  }
  
  rawData <- rawData[rowSums(rawData) > 1,]
  
  sampleFrame <- data.frame("id" = colnames(rawData),
                            "condition" = classesVector)
  dds <- DESeqDataSetFromMatrix(countData = round(rawData),
                                colData = sampleFrame,
                                design =~ condition)
  dds <- DESeq(dds)
  
  res <- results(dds, contrast = c("condition",
                                   rev(unique(classesVector))))
  
  if(is.pval.and.log){
    res$pvalue <- pval[res@rownames]
    res$padj <- qval[res@rownames]
    res$log2FoldChange <- log2FC[res@rownames]
  }
  
  res <- res[order(res$pvalue),]
  res$symbol <- mapIds(org.Hs.eg.db,
                       keys = row.names(res), 
                       column = "SYMBOL",
                       keytype = keyType,
                       multiVals = "first")
  res$entrez <- mapIds(org.Hs.eg.db,
                       keys = row.names(res), 
                       column = "ENTREZID",
                       keytype = keyType,
                       multiVals = "first")
  res$name <- mapIds(org.Hs.eg.db,
                     keys = row.names(res), 
                     column = "GENENAME",
                     keytype = keyType,
                     multiVals = "first")
  
  data(kegg.sets.hs)
  
  # Generating list of protein data frames of hsa processes
  hsaList <- list()
  upOrDown <- res$log2FoldChange >= 0
  upOrDown[upOrDown == TRUE] <- "Up"
  upOrDown[upOrDown == "FALSE"] <- "Down"
  
  for(i in 1:length(kegg.sets.hs)){
    indices <- res$entrez %in% kegg.sets.hs[[i]]
    if(length(res@rownames[indices]) > 0){
      idata <- data.frame("kegg.process" = names(kegg.sets.hs)[i],
                          "proteins" = res@rownames[indices],
                          "description" = res$name[indices],
                          "gene.ID" = res$symbol[indices],
                          "qvalue" = res$padj[indices],
                          "is.sig.0.05" = res$padj[indices] <= 0.05,
                          "log2FC" = res$log2FoldChange[indices],
                          "is.up.or.down" = upOrDown[indices])
      hsaList[[names(kegg.sets.hs)[i]]] <- idata
    }
  }
  
  foldchanges <- res$log2FoldChange
  names(foldchanges) <- res$entrez
  
  keggres <- gage(foldchanges, gsets = kegg.sets.hs, same.dir = TRUE)
  for(i in 1:length(keggres)){
    if("exp1" %in% colnames(keggres[[i]])){
      keggres[[i]] <- keggres[[i]][, -which(colnames(keggres[[i]]) == "exp1")]
    }
  }
  
  
  listResults <- list()
  listResults[["bioProcesses"]] <- keggres
  listResults[["log2FC"]] <- foldchanges
  listResults[["hsaList"]] <- hsaList
  return(listResults)
  
}

keggNetworks <- function(keggres,
                         foldchanges,
                         selectSpecies = "hsa",
                         nPathways = 10,
                         setWorkSpace,
                         createDir = TRUE,
                         newDirName,
                         keggSetsHS = kegg.sets.hs,
                         is.log2FC.absent = FALSE){
  
  # Loads necessary packages:
  if(!("package:dplyr" %in% base::search())){
    library(dplyr)
  }
  if(!("package:DESeq2" %in% base::search())){
    library(DESeq2)
  }
  if(!("package:AnnotationDbi" %in% base::search())){
    library(AnnotationDbi)
  }
  if(!("package:org.Hs.eg.db" %in% base::search())){
    library(org.Hs.eg.db)
  }
  if(!("package:pathview" %in% base::search())){
    library(pathview)
  }
  if(!("package:gage" %in% base::search())){
    library(gage)
  }
  if(!("package:gageData" %in% base::search())){
    library(gageData)
  }
  
  originalWD <- getwd()
  
  if(createDir){
    completePath <- paste(setWorkSpace, newDirName, sep = "")
    dir.create(path = completePath)
  }else{
    completePath <- setWorkSpace
  }
  setwd(dir = completePath)
  
  dir.create(path = paste(completePath, "/alteredPathways", sep = ""))
  dir.create(path = paste(completePath, "/rawPathways", sep = ""))
  dir.create(path = paste(completePath, "/XML", sep = ""))
  
  keggrespathways <- data.frame(id=rownames(keggres$greater), keggres$greater) %>%
    tbl_df() %>% filter(row_number() <= nPathways) %>% .$id %>% as.character()
  
  names(keggSetsHS) <- substr(names(keggSetsHS), start = 1, stop = 8)
  
  keggresids <- substr(keggrespathways, start = 1, stop = 8)
  
  foldchanges <- round(x = foldchanges, digits = 2)
  
  if(is.log2FC.absent){
    lowCol <- "lightgrey"
    highCol <- "#377EB8"
  }else{
    lowCol <- "green"
    highCol <- "red"
  }
  
  plot_pathway <- function(pid) pathview(gene.data = foldchanges,
                                         pathway.id = pid,
                                         species = selectSpecies,
                                         new.signature = FALSE,
                                         bins = list(gene = 10, cpd = 10),
                                         low = list(gene = lowCol, cpd = "blue"),
                                         mid = list(gene = "gray", cpd = "gray"),
                                         high = list(gene = highCol, cpd = "orange"),
                                         limit = list(gene = max(abs(na.omit(foldchanges[keggSetsHS[[pid]]]))),
                                                      cpd = max(abs(na.omit(foldchanges[keggSetsHS[[pid]]])))),
                                         both.dirs = list(gene = TRUE, cpd = TRUE))
  
  tmp <- sapply(keggresids, function(pid) try(pathview(gene.data = foldchanges,
                                                       pathway.id = pid,
                                                       species = selectSpecies,
                                                       new.signature = FALSE,
                                                       bins = list(gene = 10, cpd = 10),
                                                       low = list(gene = lowCol, cpd = "blue"),
                                                       mid = list(gene = "gray", cpd = "gray"),
                                                       high = list(gene = highCol, cpd = "orange"),
                                                       limit = list(gene = max(abs(na.omit(foldchanges[keggSetsHS[[pid]]]))),
                                                                    cpd = max(abs(na.omit(foldchanges[keggSetsHS[[pid]]])))),
                                                       both.dirs = list(gene = TRUE, cpd = TRUE))))
  
  my.file.rename <- function(from, to) {
    todir <- dirname(to)
    if (!isTRUE(file.info(todir)$isdir)) dir.create(todir, recursive=TRUE)
    file.rename(from = from,  to = to)
  }
  
  allFilesWD <- list.files()
  allFilesWD <- allFilesWD[!(allFilesWD %in% c("alteredPathways", "rawPathways", "XML"))]
  for(i in 1:length(allFilesWD)){
    ifile <- allFilesWD[i]
    ifileFormat <- tail(strsplit(ifile, split="\\.")[[1]], n = 1)
    maybePathway <- strsplit(ifile, split="\\.")[[1]][2]
    if(ifileFormat == "xml"){
      invisible(my.file.rename(from = paste(getwd(), "/", ifile, sep = ""),
                               to = paste(getwd(), "/XML/", ifile, sep = "")))
    }else{
      if(maybePathway == "pathview"){
        invisible(my.file.rename(from = paste(getwd(), "/", ifile, sep = ""),
                                 to = paste(getwd(), "/alteredPathways/", ifile, sep = "")))
      }else{
        invisible(my.file.rename(from = paste(getwd(), "/", ifile, sep = ""),
                                 to = paste(getwd(), "/rawPathways/", ifile, sep = "")))
      }
    }
  }
  
  setwd(dir = originalWD)
  
}

## 45) stringnet():

# 

stringnet <- function(qvalue,
                      log2FC,
                      proteinNames,
                      descript,
                      clusteringAlgorithm = "fastgreedy",
                      isSmallNet = TRUE,
                      STRINGVer = "11.5",
                      selectedSpecies = 9606, # human
                      scoreThres = 400,
                      chosenPVal = 1,
                      isExcel = TRUE,
                      filesPath,
                      colSet = "greenred",
                      is.pval.title = FALSE){
  
  if(!("package:STRINGdb" %in% base::search())){
    library(STRINGdb)
  }
  if(!("package:itsadug" %in% base::search())){
    library(itsadug)
  }
  if(isExcel){
    if(!("package:xlsx" %in% base::search())){
      library(xlsx)
    }
  }
  
  print("Retrieving all protein interactions for selected species...")
  
  string_db <- STRINGdb$new(version = STRINGVer,
                            species = selectedSpecies,
                            score_threshold = scoreThres,
                            input_directory = "")
  
  idata <- data.frame("pvalue" = qvalue,
                      "logFC" = log2FC,
                      "protein" = proteinNames)
  
  mapped <- string_db$map(my_data_frame = idata,
                          my_data_frame_id_col_names = "protein",
                          removeUnmappedRows = TRUE)
  
  cat("\nCalculating main clusters...\n")
  
  stringClusters <- string_db$get_clusters(string_ids = mapped$STRING_id,
                                           algorithm = clusteringAlgorithm)
  
  ### Building interaction tables:
  
  print("Generating interaction tables...")
  
  translatorTable <- mapped[,c("protein", "STRING_id")]
  rownames(translatorTable) <- translatorTable[,"STRING_id"]
  translatorTable$gene.ID <- descript[translatorTable[,"protein"],"gene.ID"]
  
  for(i in 1:length(stringClusters)){
    for(j in 1:length(stringClusters[[i]])){
      stringClusters[[i]][j] <- translatorTable[stringClusters[[i]][j],"gene.ID"]
    }
  }
  
  clustersMatrix <- matrix(data = 0,
                           nrow = nrow(translatorTable),
                           ncol = length(stringClusters))
  colnames(clustersMatrix) <- sprintf("cluster%s", 1:length(stringClusters))
  rownames(clustersMatrix) <- translatorTable[,"gene.ID"]
  
  for(i in 1:ncol(clustersMatrix)){
    clustersMatrix[,i] <- as.numeric(rownames(clustersMatrix) %in% stringClusters[[i]])
  }
  
  matrixStartPoint <- string_db$get_interactions(translatorTable[,"STRING_id"])
  willItStop <- nrow(matrixStartPoint) == 0
  
  if(willItStop){
    
    print("No interactions between proteins were detected. STRING network representation was aborted.")
    
  }else{
    
    interactionsShell <- matrix(data = 0,
                                nrow = nrow(translatorTable),
                                ncol = nrow(translatorTable))
    rownames(interactionsShell) <- translatorTable[, "gene.ID"]
    colnames(interactionsShell) <- translatorTable[, "gene.ID"]
    
    for(i in 1:nrow(matrixStartPoint)){
      matrixStartPoint[i,1] <- translatorTable[matrixStartPoint[i,1],"gene.ID"]
      matrixStartPoint[i,2] <- translatorTable[matrixStartPoint[i,2],"gene.ID"]
      interactionsShell[matrixStartPoint[i,1], matrixStartPoint[i,2]] <- 1
    }
    
    tables <- list("individualInteractions" = matrixStartPoint,
                   "interactionsMatrix" = interactionsShell,
                   "clustersMatrix" = clustersMatrix)
    
    ###
    
    print("Plotting STRING network...")
    
    hits <- mapped$STRING_id
    dev.new()
    string_db$plot_network(hits)
    if(is.pval.title){
      mapped$logFC <- mapped$logFC + abs(rnorm(n = nrow(mapped), mean = 0.01, sd = 0.01))
    }
    mapped_pval <- string_db$add_diff_exp_color(subset(mapped,
                                                       pvalue <= chosenPVal),
                                                logFcColStr = "logFC")
    if(colSet == "greyblue"){
      mapped_pval[mapped_pval$pvalue <= 0.05,"color"] <- "#377EB8"
      mapped_pval[!(mapped_pval$pvalue <= 0.05),"color"] <- "#FFFFFFFF"
    }
    payload_id <- string_db$post_payload(mapped_pval$STRING_id,
                                         colors = mapped_pval$color)
    string_db$plot_network(hits, payload_id = payload_id)
    
    if(isSmallNet){
      insetLegendX <- 0.075
      posGradientX1 <- 0.751
      posGradientX2 <- posGradientX1 + 0.1745
      posGradient <- c(posGradientX1, 0.15, posGradientX2, 0.275)
      # xleft, ybottom, xright, ytop
      # textPosX <- 1287
      # textPosY <- 315
      # Relative positions:
      textPosX <- (posGradientX1 + posGradientX2)/2
      textPosY <- 0.325
    }else{
      insetLegendX <- 0.022
      posGradientX1 <- 0.805
      posGradientX2 <- posGradientX1 + 0.1745
      posGradient <- c(posGradientX1, 0.15, posGradientX2, 0.275)
      # xleft, ybottom, xright, ytop
      # textPosX <- 1407
      # textPosY <- 315
      # Relative positions:
      textPosX <- (posGradientX1 + posGradientX2)/2
      textPosY <- 0.325
    }
    
    enterYes <- ""
    while(enterYes != "Y"){
      enterYes <- readline(prompt = "Maximize new window. When ready, enter 'y/Y': ")
      enterYes <- toupper(enterYes)
    }
    
    print("Plotting legend...")
    
    legend(x = "bottomright",
           inset = c(insetLegendX, 0.4),
           legend = c(as.expression(bquote(bold("Known Interactions:"))), #1
                      "From curated database", #2
                      "From curated database", #3
                      "", #4
                      as.expression(bquote(bold("Predicted Interactions:"))), #5
                      "Gene neighbourhood", #6
                      "Gene fusion", #7
                      "Gene co-occurence", #8
                      "", #9
                      as.expression(bquote(bold("Other:"))), #10
                      "Text mining", #11
                      "Co-expression", #12
                      "Protein homology"), #13
           lty = 1,
           col = c(NA, #1
                   "#00FFFF", #2
                   "#FF00FF", #3
                   NA, #4
                   NA, #5
                   "#00FF00", #6
                   "#FF0000", #7
                   "#0000FF", #8
                   NA, #9
                   NA, #10
                   "#CCCC00", #11
                   "#000000", #12
                   "#6666CC"), #13
           lwd = 3,
           cex = 1.3)
    
    if(colSet == "greenred"){
      if(all(idata$logFC >= 0)){
        colorGradient <- c("white", "red")
      }
      if(all(idata$logFC < 0)){
        colorGradient <- c("green", "white")
      }
      if(!(all(idata$logFC >= 0)) & !(all(idata$logFC < 0))){
        colorGradient <- c("green", "white", "red")
      }
    }
    if(colSet == "greyblue"){
      colorGradient <- c("lightgrey", "darkgrey", "#377EB8")
    }
    
    if(is.pval.title){
      legend_image <- as.raster(matrix(colorRampPalette(colorGradient)(10),
                                       ncol = 1))
      rasterImage(legend_image,
                  xleft = -1,
                  xright = 1,
                  ybottom = -1,
                  ytop = 1,
                  angle = 0)
      
      try(gradientLegend(valRange = c(0, 1),
                         color = colorRampPalette(colorGradient)(10),
                         side = 1,
                         pos = posGradient,
                         length = 0.1,
                         depth = 0.1,
                         inside = TRUE,
                         coords = FALSE,
                         pos.num = NULL,
                         n.seg = 0,
                         border.col = "black",
                         dec = 0))
      
    }else{
      legend_image <- as.raster(matrix(colorRampPalette(colorGradient)(10),
                                       ncol = 1))
      rasterImage(legend_image,
                  xleft = -1,
                  xright = 1,
                  ybottom = -1,
                  ytop = 1,
                  angle = 0)
      
      if(all(idata$logFC >= 0) | all(idata$logFC < 0)){
        rangeValue <- round(c(min(idata$logFC), max(idata$logFC)), 2)
      }else{
        rangeValue <- round(max(abs(idata$logFC)), 2)
        rangeValue <- c(-rangeValue, rangeValue)
      }
      
      # rangeValue <- round(max(abs(idata$logFC)), 2)
      # valRange = round(c(min(idata$logFC), max(idata$logFC)), 2)
      gradientLegend(valRange = rangeValue,
                     color = colorRampPalette(colorGradient)(10),
                     side = 1,
                     pos = posGradient,
                     length = 0.1,
                     depth = 0.1,
                     inside = TRUE,
                     coords = FALSE,
                     pos.num = NULL,
                     n.seg = 5,
                     border.col = "black",
                     dec = 2)
    }
    
    op <- par("usr")
    par(usr = c(0, 1, 0, 1))
    if(is.pval.title){
      text(x = c(posGradient[1], posGradient[3]),
           y = 0.295,
           labels = c(0, 1),
           cex = 1)
      text(x = textPosX,
           y = textPosY,
           labels = c(as.expression(bquote(bold("Color code (0: not significant; 1: significant)")))),
           cex = 1.2)
    }else{
      text(x = textPosX,
           y = textPosY,
           labels = c(as.expression(bquote(bold("Protein abundance as log2(fold change):")))),
           cex = 1.2)
    }
    par(usr = op)
    
    if(isExcel){
      
      print("Generating excel sheets with protein network interactions...")
      
      write.xlsx2(x = tables[[1]],
                  file = filesPath,
                  col.names = TRUE,
                  row.names = FALSE,
                  sheetName = names(tables)[1],
                  append = FALSE)
      
      write.xlsx2(x = tables[[2]],
                  file = filesPath,
                  col.names = TRUE,
                  row.names = TRUE,
                  sheetName = names(tables)[2],
                  append = TRUE)
      
      write.xlsx2(x = tables[[3]],
                  file = filesPath,
                  col.names = TRUE,
                  row.names = TRUE,
                  sheetName = names(tables)[3],
                  append = TRUE)
      
    }
    
    print("Done.")
    
    return(tables)
    
  }
  
}

load(file = "C:/Users/Centaurus2/Desktop/bioinf/datos/chol_july04/rda/allExplained.rda")
ear <- allExplained$PFIC$`sensory perception of sound [GO:0007605]`
refinedEar <- ear[,c("q.value","log2.FC","protein.code")]
colnames(refinedEar) <- c("pvalue", "logFC", "protein")

stringnet(qvalue = refinedEar$pvalue,
          log2FC = refinedEar$logFC,
          proteinNames = refinedEar$protein,
          isSmallNet = TRUE,
          STRINGVer = "11.5",
          selectedSpecies = 9606,
          scoreThres = 400,
          chosenPVal = 1)

## 46) phosphoConverter():

# 

phosphoConverter <- function(chosenData){
  
  # Make sure the first column indicates the peptide, and the second column,
  # the proteins that have that peptide. The rest of the column have to contain
  # the data that is going to be replicated.
  
  backUpCols <- c(colnames(chosenData)[1:2],
                  "Is.shared", "Sharing.proteins",
                  colnames(chosenData)[3:ncol(chosenData)])
  
  emptyShell <- matrix(data = NA, nrow = nrow(chosenData), ncol = ncol(chosenData) + 2)
  
  i <- 1
  k <- 1
  
  while((nrow(chosenData) + 1) != i){
    
    iproteins <- unlist(strsplit(x = chosenData[i,2], split = "; ", fixed = TRUE))
    
    if(length(iproteins) > 1){
      addToShell <- matrix(data = NA,
                           nrow = length(iproteins) - 1,
                           ncol = ncol(emptyShell))
      emptyShell <- rbind(emptyShell, addToShell)
      for(j in 1:length(iproteins)){
        emptyShell[(k + j - 1), 1] <- chosenData[i, 1]
        emptyShell[(k + j - 1), 2] <- iproteins[j]
        emptyShell[(k + j - 1), 3] <- TRUE
        emptyShell[(k + j - 1), 4] <- chosenData[i,2]
        emptyShell[(k + j - 1), 5:ncol(emptyShell)] <- as.character(chosenData[i, 3:ncol(chosenData)])
      }
      k <- k + j
    }else{
      emptyShell[k,] <- c(as.character(chosenData[i,c(1,2)]), as.character(FALSE), as.character(chosenData[i,2:ncol(chosenData)]))
      k <- k + 1
    }
    
    i <- i + 1
    
  }
  
  shellRowNames <- sprintf(paste(emptyShell[,1], "..", "%s", sep = ""),
                           emptyShell[,2])
  shellRowNames <- gsub(pattern = "[",
                        replacement = "",
                        x = shellRowNames,
                        fixed = TRUE)
  shellRowNames <- gsub(pattern = "]",
                        replacement = "",
                        x = shellRowNames,
                        fixed = TRUE)
  rownames(emptyShell) <- shellRowNames
  colnames(emptyShell) <- backUpCols
  
  return(emptyShell)
  
}

## 47) plotProcessBars3():

# 

plotProcessBars3 <- function(processesArr,
                             howMany = 10,
                             main2 = "default",
                             processesExplainedList,
                             obviate.log2FC = FALSE,
                             factorPosition = 4/7){
  
  if(obviate.log2FC){
    red <- "#377EB8"
    lawn <- "#377EB8"
    blue <- "#E41A1C"
  }else{
    red <- "#E41A1C"
    lawn <- "#7CFC00"
    blue <- "#377EB8"
  }
  
  if(main2 == "default"){
    main2 <- "-log10(p-value) of altered GO processes"
  }
  
  processesArr <- processesArr[,"fisher.pvalue"]
  processesArr <- -log10(processesArr)
  processesArr <- processesArr[howMany:1]
  processesNames1 <- names(processesArr)
  processesNames2 <- gsub(pattern = "\\s\\[.*]",
                          replacement = "",
                          x = processesNames1)
  
  space1 <- 1.5
  width <- 1
  nSpaces <- howMany
  firstText <- width + space1
  textPositions <- c(firstText)
  saveValue <- firstText
  for(i in 1:(nSpaces-1)){
    saveValue <- saveValue + firstText
    textPositions <- append(x = textPositions, values = saveValue)
  }
  textExtra <- 0.5
  textPositions <- textPositions + textExtra
  
  specificExplained <- processesExplainedList[processesNames1]
  upOrDownVec <- c()
  for(i in 1:length(specificExplained)){
    logSum <- sum(specificExplained[[i]][,"log2.FC"])
    if(logSum < 0){
      upOrDownVec <- append(x = upOrDownVec, values = lawn)
    }
    if(logSum >= 0){
      upOrDownVec <- append(x = upOrDownVec, values = red)
    }
  }
  
  barplot(height = processesArr,
          horiz = TRUE,
          beside = TRUE,
          col = upOrDownVec,
          xlim = range(pretty(c(0, max(processesArr)))),
          main = main2,
          yaxt = "n",
          space = space1,
          xlab = "-log10(p-value)",
          ylab = "Biological processes")
  
  meanPoint <- range(pretty(c(0, max(processesArr))))[2] * factorPosition
  
  abline(v = -log10(0.05), lty = 2, col = blue, lwd = 2)
  text(x = meanPoint, y = textPositions, labels = processesNames2)
  
}

## 48) plotProcessBars2():

# 

plotProcessBars2 <- function(processesArr,
                             howMany = 10,
                             main2 = "default",
                             processesExplainedList,
                             obviate.log2FC = TRUE,
                             factorPosition = 4/7){
  
  if(obviate.log2FC){
    orange <- "skyblue"
    red <- "#377EB8"
    lawn <- "skyblue"
    sea <- "#377EB8"
    blue <- "#E41A1C"
  }else{
    orange <- "#FF8C00"
    red <- "#E41A1C"
    lawn <- "#7CFC00"
    sea <- "#20B2AA"
    blue <- "#377EB8"
  }
  
  
  downColors <- c(sea, lawn)
  upColors <- c(red, orange)
  
  if(main2 == "default"){
    main2 <- "-log10(p- and q-values) of altered GO processes"
  }
  
  processesArr <- processesArr[,c("fisher.qvalue","fisher.pvalue")]
  processesArr <- -log10(processesArr)
  processesArr <- processesArr[howMany:1,]
  processesArr <- t(processesArr)
  processesNames1 <- colnames(processesArr)
  processesNames2 <- gsub(pattern = "\\s\\[.*]",
                          replacement = "",
                          x = processesNames1)
  
  space1 <- howMany / 50
  space2 <- howMany * 0.2
  nSpaces <- howMany - 1
  firstSpace <- space2 + 1 + space1 + 1
  spacesPosition <- c(firstSpace)
  saveValue <- firstSpace
  for(i in 1:nSpaces){
    saveValue <- saveValue + firstSpace
    spacesPosition <- append(x = spacesPosition, values = saveValue)
  }
  spacesPosition <- spacesPosition + (space1 * 4)
  
  specificExplained <- processesExplainedList[processesNames1]
  upOrDownVec <- c()
  for(i in 1:length(specificExplained)){
    
    upOrDownCol <- specificExplained[[i]][,ncol(specificExplained[[i]])]
    
    if(length(upOrDownCol) == 1){
      mostCommon <- upOrDownCol
    }else{
      aggregateDF <- data.frame("log2.FC" = specificExplained[[i]][,"log2.FC"],
                                "is.Up.Or.Down" = upOrDownCol)
      rownames(aggregateDF) <- specificExplained[[i]][,"protein.code"]
      aggregateResults <- aggregate(aggregateDF$log2.FC,
                                    by = list(Category = aggregateDF$is.Up.Or.Down),
                                    FUN = sum)
      mostCommon <- aggregateResults[which.max(abs(aggregateResults$x)),1]
    }
    
    if(mostCommon == "Down"){
      upOrDownVec <- append(x = upOrDownVec, values = downColors)
    }
    if(mostCommon == "Up"){
      upOrDownVec <- append(x = upOrDownVec, values = upColors)
    }
    
  }
  
  barplot(height = processesArr,
          horiz = TRUE,
          beside = TRUE,
          col = upOrDownVec,
          xlim = range(pretty(processesArr)),
          main = main2,
          yaxt = "n",
          space = c(space1, space2),
          xlab = "-log10(p-/q-value)",
          ylab = "Biological processes")
  
  meanPoint <- range(pretty(processesArr))[2] * factorPosition
  
  abline(v = -log10(0.05), lty = 2, col = blue, lwd = 2)
  text(x = meanPoint, y = spacesPosition, labels = processesNames2)
  
}

## 49) printKEGGresults():

# 

printKEGGresults <- function(keggProcessesResults,
                             wanna.Excel = TRUE,
                             excelPath){
  
  if(wanna.Excel){
    if(!("package:xlsx" %in% base::search())){
      library(xlsx)
    }
  }
  
  excelKeggRes <- keggProcessesResults$bioProcesses$greater
  excelKeggRes <- cbind(excelKeggRes, rep(NA, nrow(excelKeggRes)), rep(NA, nrow(excelKeggRes)))
  colnames(excelKeggRes)[c((ncol(excelKeggRes)-1), ncol(excelKeggRes))] <- c("altered.proteins", "rate")
  
  for(i in 1:nrow(excelKeggRes)){
    
    itotal <- excelKeggRes[i,"set.size"]
    iname <- rownames(excelKeggRes)[i]
    isig <- sum(na.omit(keggProcessesResults$hsaList[[iname]][,"is.sig.0.05"]))
    irate <- isig/itotal
    excelKeggRes[i,(ncol(excelKeggRes)-1)] <- isig
    excelKeggRes[i,ncol(excelKeggRes)] <- irate
    
  }
  
  if(wanna.Excel){
    write.xlsx2(x = excelKeggRes,
                file = excelPath,
                row.names = TRUE,
                col.names = TRUE,
                sheetName = "allKEGGProcesses",
                append = FALSE)
  }
  
  return(excelKeggRes)
  
}

## 50) printKEGGtop():

# 

printKEGGtop <- function(keggProcessesResults,
                         howMany = 10,
                         excelPath){
  
  if(!("package:xlsx" %in% base::search())){
    library(xlsx)
  }
  
  KEGGtopProcesses <- keggProcessesResults$hsaList[rownames(keggProcessesResults$bioProcesses$greater)[1:howMany]]
  for(i in 1:howMany){
    
    isheetName <- paste("process", as.character(i), sep = "")
    if(i == 1){
      write.xlsx2(x = KEGGtopProcesses[[i]],
                  file = excelPath,
                  row.names = FALSE,
                  col.names = TRUE,
                  sheetName = isheetName,
                  append = FALSE)
    }else{
      write.xlsx2(x = KEGGtopProcesses[[i]],
                  file = excelPath,
                  row.names = FALSE,
                  col.names = TRUE,
                  sheetName = isheetName,
                  append = TRUE)
    }
    
  }
  
}

## 51) plotProteinsVSPVals():

# 

plotProteinsVSPVals <- function(allPValsMatrix,
                                plotTitle = "Number of significant proteins considering adjusted p-values",
                                chosenLineWidth = 2,
                                chosenPointSize = 1,
                                legendText = "default",
                                groups,
                                colorSet,
                                legCex = 1,
                                legPos = "bottomleft"){
  
  if(legendText == "default"){
    
    legendText <- c("Number of significant proteins (q-values from F-test)",
                    sprintf("Number of significant proteins (qvalues: 'Control' vs. %s)",
                            groups))
    
  }
  
  xAxis <- seq(from = 1 - 0.0001, to = 0, by = -0.0001)
  allYAxes <- matrix(data = NA, ncol = ncol(allPValsMatrix), nrow = length(xAxis))
  for(i in 1:ncol(allPValsMatrix)){
    icol <- allPValsMatrix[,i]
    allYAxes[,i] <- sapply(X = xAxis, FUN = function(x) sum(icol <= x))
  }
  rownames(allYAxes) <- format(xAxis, digits = 5)
  
  criticalPValues <- c("0.0001", "0.0010", "0.0100", "0.0500")
  
  for(i in 1:ncol(allYAxes)){
    
    if(i == 1){
      plot(x = xAxis,
           y = rev(allYAxes[,i]),
           ylim = range(pretty(c(0, max(allYAxes)))),
           main = plotTitle,
           xlab = "p-value",
           ylab = "Number of significant proteins",
           xaxt = "n",
           type = "l",
           col = colorSet[i],
           lwd = chosenLineWidth)
      axis(side = 1, at = pretty(xAxis), labels = rev(pretty(xAxis)))
      axis(side = 4, at = pretty(c(0, max(allYAxes))), labels = pretty(c(0, max(allYAxes))))
    }else{
      points(x = xAxis,
             y = rev(allYAxes[,i]),
             col = colorSet[i],
             type = "l",
             lwd = chosenLineWidth)
    }
    points(x = 1 - as.numeric(criticalPValues),
           y = allYAxes[criticalPValues,i],
           pch = 21,
           cex = chosenPointSize,
           col = "black",
           bg = colorSet[i])
    
  }
  
  legend(x = legPos,
         inset = c(0.025, 0.025),
         legend = legendText,
         pt.bg = colorSet,
         pch = 21,
         lty = 1,
         lwd = 2,
         pt.cex = 1.2,
         col = colorSet,
         cex = legCex)
  
  print(allYAxes[rev(criticalPValues),])
  
  return(allYAxes)
  
}

## 52) checkPackage():

# 

checkPackage <- function(packageLabel, repository = "CRAN"){
  
  if(!(packageLabel %in% rownames(installed.packages()))){
    
    if(repository == "CRAN"){
      print(paste("Installing ", packageLabel, " from CRAN...", sep = ""))
      install.packages(packageLabel)
    }
    if(repository == "Bioconductor"){
      print(paste("Installing ", packageLabel, " from Bioconductor...", sep = ""))
      BiocManager::install(packageLabel)
    }
    
  }else{
    
    print(paste(packageLabel, " is already installed.", sep = ""))
    
  }
  
  packageCode <- paste("package::", packageLabel)
  
  if(!(packageCode %in% base::search())){
    
    library(packageLabel, character.only = TRUE)
    print(paste(packageLabel, " successfully attached.", sep = ""))
    
  }else{
    
    print(paste(packageLabel, " was already attached.", sep = ""))
    
  }
  
}

## 53) obtainVolcanoANOVA():

# 

obtainVolcanoANOVA <- function(ANOVAtable,
                               adjANOVAtable,
                               controlClass = "Control",
                               diseaseClass,
                               invertOrder){
  
  if(invertOrder){
    
    saveDisease <- diseaseClass
    diseaseClass <- controlClass
    controlClass <- saveDisease
    
  }
  
  postHocCol <- paste("pval.", controlClass, "-", diseaseClass, sep = "")
  adjPostHocCol <- paste("adj.pval.", controlClass, "-", diseaseClass, sep = "")
  log2FCCol <- paste("log2.ratio.", controlClass, "-", diseaseClass, sep = "")
  
  volcanoData <- matrix(data = c(ANOVAtable[,postHocCol],
                                 adjANOVAtable[,adjPostHocCol],
                                 -log10(ANOVAtable[,postHocCol]),
                                 -log10(adjANOVAtable[,adjPostHocCol]),
                                 adjANOVAtable[,log2FCCol]),
                        ncol = 5)
  rownames(volcanoData) <- rownames(adjANOVAtable)
  colnames(volcanoData) <- c("pval",
                             "adj.pval",
                             "-log10.pval",
                             "-log10.adj.pval",
                             "log2.vec.FC")
  volcanoData <- volcanoData[order(volcanoData[,"pval"],
                                   decreasing = FALSE),]
  
  return(volcanoData)
  
}

## 54) averageProcessesAlterations():

# 

averageProcessesAlterations <- function(listSignificance,
                                        listExplained,
                                        howManyTop = 10){
  
  topP <- c()
  sigP <- c()
  
  for(i in 1:length(listSignificance)){
    
    sigBool <- listSignificance[[i]][,"fisher.pvalue"] <= 0.05
    isigP <- rownames(listSignificance[[i]])[sigBool]
    sigP <- append(x = sigP, values = isigP)
    
    itopP <- rownames(listSignificance[[i]])[1:howManyTop]
    topP <- append(x = topP, values = itopP)
    
  }
  
  topP <- unique(topP)
  sigP <- unique(sigP)
  
  sigArr <- matrix(data = NA,
                   ncol = length(listSignificance),
                   nrow = length(sigP))
  colnames(sigArr) <- names(listSignificance)
  rownames(sigArr) <- sigP
  
  for(i in 1:length(listSignificance)){
    
    iname <- names(listSignificance)[i]
    
    for(j in 1:length(sigP)){
      
      jname <- sigP[j]
      jLog2FC <- listExplained[[iname]][[jname]][,"log2.FC"]
      jmean <- mean(jLog2FC)
      sigArr[jname,iname] <- jmean
      
    }
    
  }
  
  results <- list("topMatrix" = sigArr[topP,],
                  "sigMatrix" = sigArr)
  return(results)
  
}

## 55) doubleGOClustering():

# 

doubleGOClustering <- function(avArr,
                               heatRes,
                               savingPath){
  
  packages <- c("GO.db", "GOxploreR",
                "cluster", "xlsx", "RColorBrewer", "dplyr", "dendextend")
  
  for(i in 1:length(packages)){
    
    istring <- paste("package:", packages[i], sep = "")
    if(!(istring %in% base::search())){
      print(paste("Loading ", packages[i], "...", sep = ""))
      library(packages[i], character.only = TRUE)
      print(paste("Package ", packages[i], " loaded.", sep = ""))
    }else{
      print(paste(packages[i], " was already loaded.", sep = ""))
    }
    
  }
  
  clusteringData <- t(scale(t(avArr))) # "avArr"
  # obtains the data matrix that was handled by "heat" function to create the
  # heat map.
  
  print("Getting optimal number of clusters from heat map dendrogram...")
  
  clusteringTopProcesses <- clusGap(x = clusteringData,
                                    FUNcluster = kmeans,
                                    K.max = 15,
                                    B = 1000)
  # using the "clusGap" function from "cluster" library, the heat map dendrogram
  # clustering results are grouped into an optimal number of clusters.
  
  noTopClusters <- maxSE(f = clusteringTopProcesses$Tab[,"gap"],
                         SE.f = clusteringTopProcesses$Tab[,"SE.sim"],
                         method = "firstSEmax",
                         SE.factor = 1)
  # using the "maxSE" function from "cluster" library the number of clusters is
  # retrieved.
  
  cutIt <- cutree(tree = hclust(d = as.dist((1-cor(x = t(clusteringData),
                                                   use = "pairwise.complete.obs"))/2),
                                method = "complete"),
                  k = noTopClusters)
  # heat map processes dendrogram is cut so the processes are ordered into the
  # indicated number of clusters.
  
  dendProcessesDF <- data.frame("noTerm" = 1:length(heatRes$rowMeans),
                                "GOTerm" = rev(attr(heatRes$rowMeans, which = "names")),
                                "cluster" = cutIt[rev(attr(heatRes$rowMeans, which = "names"))])
  # data frame that stores results from hierarchical clustering applied onto
  # the GO processes.
  
  write.xlsx2(x = dendProcessesDF,
              file = savingPath,
              col.names = TRUE,
              row.names = FALSE,
              sheetName = "singleClustering",
              append = FALSE)
  # saves hierarchical clustering processes order in an Excel file.
  
  xx <- as.list(GO.db::GOTERM) # saves all GO terms descriptions.
  
  allParents <- list() # will store all GO ancestors for each given GO identifier.
  
  GOMatrices <- list() # will store GO terms distances matrices associated to
  # the similarity of GO processes considering the number of common GO
  # ancestor terms.
  GOcommonClusterTerms <- list() # will store results of GO processes clustering
  # based on ancestor similarity.
  
  finalGODF <- as.data.frame(matrix(data = NA,
                                    nrow = length(names(cutIt)),
                                    ncol = 4))
  # Data frame that will store the results of double clustering, considering both
  # the heat map hierarchical clustering and the GO similarity matrix clustering.
  colnames(finalGODF) <- c("GONumber", "previousGONumber", "GOTerm", "GOAncestor")
  finalGODF[,1] <- 1:nrow(finalGODF) 
  l <- 1 # Variable that will help determine the row number of previous data
  # frame. This variable will control the order of the data frame rows, so
  # the processes are disposed as the final representation of the double
  # clustering, from the original processes heat map and GO similarity
  # clustering.
  
  qual_col_pals <- brewer.pal.info[brewer.pal.info$category == 'qual',]
  col_vector <- unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
  
  for(i in 1:max(cutIt)){
    
    print(paste("Retrieving GO processes belonging cluster ", as.character(i), "...", sep = ""))
    
    inames <- names(cutIt)[cutIt == i] # retrieves processes from heat map that
    # correspond to one of the deduced dendrogram clusters.
    
    print("Isolating GO identifiers...")
    
    ire <- regexpr(pattern = "\\[(.*?)]", text = inames) # extracts string
    # position of GO identifiers without their description.
    iGOterms <- substr(x = inames,
                       start = ire + 1,
                       stop = ire + attr(x = ire, which = "match.length") - 2)
    # isolates GO terms identifiers.
    clusterName <- paste("cluster", as.character(i), sep = "") # names cluster
    # considering their order in this loop.
    allParents[[clusterName]] <- list() # creates a new list to fill with cluster
    # GO terms ancestors.
    
    print("Calculating GO ancestor term for each GO identifier...")
    
    for(j in 1:length(iGOterms)){ # using GO.db library, this loop is going to
      # extract the ancestors of each GO term that belongs to current cluster in
      # form of a list.
      
      jGOterm <- iGOterms[j] # isolates GO term from cluster.
      jlist <- unname(unlist(as.list(GOBPANCESTOR[jGOterm]))) # gets all its GO
      # ancestors.
      jlist <- jlist[!(jlist == "all" | jlist == "GO:0008150")] # it does not
      # consider GO first and biological process nodes.
      jlist <- append(x = jlist, values = jGOterm) # incorporates the analyzed
      # GO identifier to the list.
      allParents[[clusterName]][[jGOterm]] <- jlist # includes them as part of
      # the previous created list. Lists elements are named after cluster GO
      # terms.
      
    }
    
    print("Creating GO similarity matrix shell...")
    
    GOSimArr <- matrix(data = NA,
                       nrow = length(iGOterms),
                       ncol = length(iGOterms)) # a similarity matrix shell is
    # generated. It contains as many columns as rows, and the number of columns
    # equals the number of GO term in the current analyzed cluster. This matrix
    # will contain a measure of similarity between terms of the cluster based on
    # the number of common ancestor GO terms each identifier has. This value
    # will be calculated as a rate between the number of common terms and the
    # union of all ancestor terms between the two identifiers that are being
    # compared.
    rownames(GOSimArr) <- iGOterms # names rows with cluster GO identifiers.
    colnames(GOSimArr) <- iGOterms # names columns with the same identifiers.
    
    print("Computing GO terms similarity...")
    
    # The next loop will compute the similarity between each of the GO terms
    # by calculating a ratio based on the common GO ancestors. If the matrix has
    # already computed the similarity value because of the loop algorithm design,
    # it will just continue with the next two terms.
    for(j in 1:length(allParents[[clusterName]])){
      
      jprocess <- unname(unlist(allParents[[clusterName]][j])) # ancestor terms
      # of a given GO identifier are retrieved from the list where they were all
      # stored.
      jname <- names(allParents[[clusterName]])[j] # current GO identifier to be
      # compared is saved.
      
      for(k in 1:length(allParents[[clusterName]])){ # inner loop that iterates
        # over the same group of GO identifiers.
        
        kname <- names(allParents[[clusterName]])[k] # inner loop GO identifier
        # is saved.
        
        if(is.na(GOSimArr[jname,kname])){ # similarity ratio will be computed 
          # only if the comparison between the two current identifiers has not
          # been made yet.
          
          kprocess <- unname(unlist(allParents[[clusterName]][k])) # inner loop
          # GO term ancestors are retrieved.
          kintersection <- length(intersect(jprocess, kprocess)) # number of
          # intersected GO ancestor terms is calculated.
          kunion <- length(union(jprocess, kprocess)) # union of all ancestors
          # is calculated.
          krate <- kintersection / kunion # ratio between the two previous numbers
          # is computed.
          
          # this rate is stored as one value in the similarity matrix between GO
          # identifiers.
          GOSimArr[jname, kname] <- krate
          GOSimArr[kname, jname] <- krate
          
        }
        
      }
      
    }
    
    GODistArr <- 1 - GOSimArr # a distance matrix is computed by computing the
    # difference between 1 and all similarity matrix elements. The closer to 0 a
    # value between two identifiers is, the more similar those two GO terms are. 
    
    GOMatrices[[clusterName]] <- GODistArr # distance matrix is saved for this
    # GO terms cluster.
    
    print("Plotting GO terms distance result:")
    
    plot(hclust(d = as.dist(GODistArr),
                method = "complete"),
         main = paste(clusterName, " dendrogram", sep = "")) # plots dendrogram
    # of current cluster GO terms using the previously computed distance matrix.
    
    # K-means clustering. Sometimes, based on GO distance matrix, leads to
    # elements closely located and to generating a unique cluster. That is why
    # we will be using another criteria to decide dendrogram subclusters.
    
    # iclustersGO <- clusGap(x = (GODistArr),
    #                        FUNcluster = kmeans,
    #                        K.max = nrow(GOSimArr) - 1,
    #                        B = 1000)
    # 
    # nClustersGO <- maxSE(f = iclustersGO$Tab[,"gap"],
    #                      SE.f = iclustersGO$Tab[,"SE.sim"],
    #                      method = "firstSEmax",
    #                      SE.factor = 1)
    
    # The next code line uses "dendextend" library to produce a set of subclusters
    # by pruning the recently generated dendrogram from nearly its root.
    rectHClust <- dendextend:::cutree.dendrogram(as.dendrogram(hclust(d = as.dist(GODistArr),
                                                                      method = "complete")),
                                                 h = 0.999)
    nClustersGO <- max(rectHClust) # retrieves number of clusters.
    
    continue <- "" # empty variable that will allow the user to change the number
    # of dendrogram clusters computed by the program.
    
    while(!(continue %in% c("N", "Y"))){
      continue <- readline(prompt = paste("Recommended number of dendrogram clusters: ",
                                          as.character(nClustersGO),
                                          ". Would you like to change it? [y/N] ",
                                          sep = ""))
      continue <- toupper(continue)
    }
    
    if(continue == "Y"){ # if the number of clusters is wanted to be different,
      # then this part of the code will be run and the user will specifically
      # determine the number of clusters they want.
      
      newNClusters <- ""
      
      while(class(newNClusters) != class(1)){
        newNClusters <- readline(prompt = "Please, enter new number of clusters: ")
        newNClusters <- as.numeric(newNClusters)
      }
      
      nClustersGO <- newNClusters
      
    }
    
    print(paste("Final number of dendrogram subclusters: ",
                as.character(nClustersGO),
                ".",
                sep = ""))
    
    rectHClust <- rect.hclust(tree = hclust(d = as.dist(GODistArr), method = "complete"),
                              k = nClustersGO,
                              border = sample(col_vector, nClustersGO))
    # finally establishes number of wanted clusters and colors plotted dendrogram.
    
    idfRes <- filter(dendProcessesDF, grepl(paste(iGOterms, collapse = "|"), GOTerm))
    # retrieves GO cluster terms from data frame containing all heat map GO terms.
    
    # write.xlsx2(file = paste(originalWorkSpace,
    #                          "5. alteredProcesses/GO/heat/",
    #                          "cluster", as.character(i), "TopGO.xlsx",
    #                          sep = ""),
    #             x = idfRes,
    #             sheetName = paste("cluster", as.character(i), "Processes", sep = ""),
    #             col.names = TRUE,
    #             row.names = FALSE,
    #             append = FALSE)
    # saves cluster GO terms as an Excel file.
    
    GOcommonClusterTerms[[clusterName]] <- list() # creates a new list inside
    # the object that records all common GO ancestor terms between GO identifiers
    # that belong to the same dendrogram subclusters.
    
    for(j in 1:length(rectHClust)){ # This loop iterates over each one of the
      # dendrogram subclusters.
      
      print(paste("Analyzing dendrogram subcluster ",
                  as.character(j),
                  ".",
                  sep = ""))
      
      subC <- paste("subCluster", as.character(j), sep = "") # creates subcluster
      # name.
      GOcommonClusterTerms[[clusterName]][[subC]] <- list() # creates a list
      # to include common GO ancestors for dendrogram subcluster GO terms.
      jj <- names(rectHClust[[j]]) # subcluster GO identifiers.
      
      print("Calculating most specific common GO ancestor...")
      jcommonTerms <- Reduce(intersect, allParents[[clusterName]][jj])
      # intersects common GO ancestors from GO identifiers of the same subcluster.
      jGOtermsDepth <- GOTermBPOnLevel(goterm = jcommonTerms)
      # using GOxploreR package, it retrieves GO depth of common GO ancestors.
      # The most specific term (that is, the one located in a deeper level of the
      # ontology) will be chosen to represent all the subcluster terms
      # simultaneously.
      GOcommonClusterTerms[[clusterName]][[subC]][["depthMatrix"]] <- jGOtermsDepth
      # saves generated data frame by using the GOxploreR ontology to obtain
      # GO common ancestors depth level in the ontology.
      
      if(length(jj) == 1){ # if there is only one GO identifier in the subcluster:
        
        print(paste("Chosen common GO ancestor for subcluster ",
                    as.character(j),
                    ": '",
                    jj,
                    "' (",
                    Term(xx[[jj]]),
                    ").",
                    sep = ""))
        jFinalTerm <- paste(Term(xx[[jj]]),
                            " [",
                            jj,
                            "]",
                            sep = "")
        # The same GO identifier is chosen as the subcluster representative.
        
      }else{ # if there are multiple GO identifiers in the subcluster:
        
        jmax <- jGOtermsDepth[,"Level"] == max(jGOtermsDepth[,"Level"])
        # the most specific GO ancestor term is chosen as the subcluster
        # representative.
        print(paste("Chosen common GO ancestor for subcluster ",
                    as.character(j),
                    ": '",
                    jGOtermsDepth[jmax, "Term"],
                    "' (",
                    Term(xx[[jGOtermsDepth[jmax, "Term"]]]),
                    ").",
                    sep = ""))
        jFinalTerm <- paste(Term(xx[[jGOtermsDepth[jmax, "Term"]]]),
                            " [",
                            jGOtermsDepth[jmax, "Term"],
                            "]",
                            sep = "")
        
      }
      
      GOcommonClusterTerms[[clusterName]][[subC]][["chosenAncestor"]] <- jFinalTerm
      # representative GO term is saved.
      
      jdfRes <- filter(dendProcessesDF, grepl(paste(jj, collapse = "|"), GOTerm))
      # subcluster processes are retrieved from the data frame containing all
      # analyzed processes.
      
      finalGODF[l:(l + nrow(jdfRes) - 1), c(2:3)] <- jdfRes
      finalGODF[l, 4] <- paste(jFinalTerm,
                               " (cluster ", as.character(i),
                               ", subcluster ", as.character(j),
                               ")",
                               sep = "")
      
      l <- l + nrow(jdfRes)
      
      # write.xlsx2(file = paste(originalWorkSpace,
      #                          "5. alteredProcesses/GO/heat/",
      #                          "cluster", as.character(i), "TopGO.xlsx",
      #                          sep = ""),
      #             x = jdfRes,
      #             sheetName = paste("subcluster", as.character(j), "Processes", sep = ""),
      #             col.names = TRUE,
      #             row.names = FALSE,
      #             append = TRUE)
      # subcluster processes are saved into an Excel file sheet.
      
    }
    
  }
  
  finalGODF[is.na(finalGODF[,4]),4] <- ""
  
  write.xlsx2(x = finalGODF,
              file = savingPath,
              col.names = TRUE,
              row.names = FALSE,
              sheetName = "doubleClustering",
              append = TRUE) # saves double clustering results in a previously
  # created Excel file.
  
  results <- list("allParents" = allParents,
                  "GOMatrices" = GOMatrices,
                  "GOcommonClusterTerms" = GOcommonClusterTerms,
                  "finalGODF" = finalGODF)
  # stores all generated results in a list.
  
  return(results)
  
}

## 56) ldAnalysis():

# 

ldAnalysis <- function(LDAmodel, # LDA model obtained with caret.
                       modelData, # complete data set (also considering classes
                       # column) used to obtain the model, with all samples
                       # (both training and test sets).
                       subDataTest, # test data subset without classes column.
                       subDataTrain, # training data subset without classes
                       # column.
                       realClassesVector, # all sample classes vector (as
                       # factor).
                       testClassesVector, # test samples predicted classes
                       # vector (as factor).
                       LD1 = 1, # first linear component to be represented.
                       LD2 = 2, # second linear component to be represented.
                       cexLDA = 1, # LDA plot point size.
                       legendPosition = "topleft", # plot legend position.
                       modelPalette){ # plot colors to be used.
  
  if(!("package:caret" %in% base::search())){
    print("'caret' library required. Attaching 'caret'...")
    library(caret)
    print("'caret' attached.")
  }else{
    print("'caret' library already attached.")
  }
  
  print("Calculating predicted values...")
  
  predAllLDA <- predict(object = LDAmodel, newdata = modelData[,-ncol(modelData)])
  predTestLDA <- predict(object = LDAmodel, newdata = subDataTest)
  
  probsTrain <- predict(object = LDAmodel,
                        newdata = subDataTrain,
                        type = "prob")
  probsTest <- predict(object = LDAmodel,
                       newdata = subDataTest,
                       type = "prob")
  
  allProbsLDA <- rbind(probsTrain, probsTest)[rownames(modelData),]
  
  allPredClassLDA <- apply(X = allProbsLDA,
                           MARGIN = 1,
                           FUN = function(x) colnames(allProbsLDA)[which.max(x)])
  
  confMatTest <- confusionMatrix(data = predTestLDA, testClassesVector)
  confMatAll <- confusionMatrix(data = predAllLDA, realClassesVector)
  
  print(confMatTest)
  print(confMatAll)
  
  print("Computing LDA values...")
  
  plotLDA <- as.matrix(modelData[,-ncol(modelData)]) %*% LDAmodel$finalModel$scaling
  
  LD1Char <- paste("LD", as.character(LD1), sep = "")
  LD2Char <- paste("LD", as.character(LD2), sep = "")
  
  LDATitle <- paste("Linear Discriminant Analysis (LDA) (",
                    LD1Char, " vs. ", LD2Char, ")", sep = "")
  LDATitlePred <- paste(LDATitle, " (real classes)", sep = "")
  LDATitleReal <- paste(LDATitle, " (predicted classes)", sep = "")
  LDATitleCorrect <- paste(LDATitle, " (correct/incorrect classification)", sep = "")
  
  titleVector <- c(LDATitlePred, LDATitleReal, LDATitleCorrect)
  
  classesVector <- list("allRealClasses" = realClassesVector,
                        "allPredictedClasses" = allPredClassLDA)
  
  print("Plotting LDA graphic representations...")
  
  for(h in 1:length(titleVector)){
    
    htitle <- titleVector[h]
    
    plot(x = plotLDA[,LD1Char],
         y = plotLDA[,LD2Char],
         main = htitle,
         xlab = LD1Char,
         ylab = LD2Char,
         xlim = range(pretty(plotLDA[,LD1Char])),
         ylim = range(pretty(plotLDA[,LD2Char])),
         pch = 21,
         cex = cexLDA,
         col = "black")
    
    if(h != length(titleVector)){
      
      hclasses <- classesVector[[h]]
      
      for(i in 1:length(unique(realClassesVector))){
        
        iclass <- unique(realClassesVector)[i]
        ibool <- hclasses == iclass
        icolor <- modelPalette[unique(realClassesVector) == iclass]
        ix <- plotLDA[ibool,LD1Char]
        iy <- plotLDA[ibool,LD2Char]
        points(x = ix,
               y = iy,
               col = "black",
               bg = icolor,
               pch = 21,
               cex = cexLDA)
        
      }
      
      legend(x = legendPosition,
             legend = unique(realClassesVector),
             pch = 21,
             pt.bg = modelPalette)
      
    }else{
      
      trueClass <- classesVector[[1]] == classesVector[[2]]
      falseClass <- !(trueClass)
      trueOrFalse <- list("true" = trueClass,
                          "false" = falseClass)
      TFColors <- c("forestgreen", "red")
      
      for(i in 1:length(trueOrFalse)){
        
        ibool <- trueOrFalse[[i]]
        icolor <- TFColors[i]
        ix <- plotLDA[ibool,LD1Char]
        iy <- plotLDA[ibool,LD2Char]
        points(x = ix,
               y = iy,
               col = "black",
               bg = icolor,
               pch = 21,
               cex = cexLDA)
        
      }
      
      legend(x = legendPosition,
             legend = c("Correct classification",
                        "Incorrect classification"),
             pch = 21,
             pt.bg = TFColors)
      
    }
    
  }
  
  
  resultsList <- list("confMatrixTest" = confMatTest,
                      "confMatrixAll" = confMatAll,
                      "probsTrain" = probsTrain,
                      "probsTest" = probsTest,
                      "allProbs" = allProbsLDA,
                      "ldaMatrix" = plotLDA)
  
  print("Done.")
  
  return(resultsList)
  
}

## 57) SVMplotter():

# 

SVMplotter <- function(datasetTrain, # original training data set, including
                       # the class column.
                       datasetTest,
                       classColumn, # Class column name or index.
                       inputSVM, # SVM model to predict test data set classes.
                       var1, # Name of the variable that will represent the
                       # horizontal axis in plots.
                       var2, # Name of the variable that will represent the
                       # vertical axis in plots.
                       sigmas = seq(0.1, 0.4, length = 5), # sigma set of
                       # values.
                       Cs = seq(0.1, 2, length = 5), # C parameter set of
                       # values.
                       svmMethod = "svmRadial",
                       setSeed = TRUE,
                       Seed = 1,
                       cvtype = "LOOCV", # cross validation method.
                       k = 10, # number of repeats of k-fold cross validation.
                       wantToScale = FALSE,
                       colorSelection, # classes colors.
                       cexPoint = 1,
                       isLeg,
                       legendPosition = "topleft", # legend position.
                       legendCex = 0.8, # legend size.
                       lightFactor = 0.6, # boundary colors lightening factor.
                       gridPCH = 15, # grid point type.
                       gridSize = 1.7){ # grid point size.
  
  libraries <- c("caret", "e1071", "kernlab", "colorspace")
  
  for(i in 1:length(libraries)){
    
    istr <- paste("package:", libraries[i], sep = "")
    if(!(istr %in% base::search())){
      print(paste("Attaching ", libraries[i], "...", sep = ""))
      library(libraries[i], character.only = TRUE)
      print(paste(libraries[i], " succesfully attached.", sep = ""))
    }else{
      print(paste(libraries[i], " already attached.", sep = ""))
    }
    
  }
  
  if(setSeed){
    set.seed(Seed)
  }
  
  datasetAll <- rbind(datasetTrain, datasetTest)
  
  classNameVariable <- apply(X = datasetTrain,
                             MARGIN = 2,
                             FUN = function(x) all(x == datasetTrain[,classColumn]))
  classNameVariable <- colnames(datasetTrain)[which(classNameVariable)]
  
  SVMFormula <- formula(paste(classNameVariable, " ~ ",
                              var1, " + ", var2,
                              sep = ""))
  
  print("Generating two features classifier...")
  
  if(cvtype == "LOOCV"){
    
    if(svmMethod == "svmLinear"){
      twoFeatSVM <- train(form = SVMFormula,
                          data = datasetTrain,
                          method = svmMethod,
                          trControl = trainControl(method = cvtype,
                                                   classProbs = TRUE),
                          tuneGrid = expand.grid(C = Cs))
    }else{
      twoFeatSVM <- train(form = SVMFormula,
                          data = datasetTrain,
                          method = svmMethod,
                          trControl = trainControl(method = cvtype,
                                                   classProbs = TRUE),
                          tuneGrid = expand.grid(sigma = sigmas,
                                                 C = Cs))
    }
    
    
    
  }
  if(cvtype == "cv"){
    
    if(svmMethod == "svmLinear"){
      twoFeatSVM <- train(form = SVMFormula,
                          data = datasetTrain,
                          method = svmMethod,
                          trControl = trainControl(method = cvtype,
                                                   number = k,
                                                   classProbs = TRUE),
                          tuneGrid = expand.grid(C = Cs))
    }
    else{
      twoFeatSVM <- train(form = SVMFormula,
                          data = datasetTrain,
                          method = svmMethod,
                          trControl = trainControl(method = cvtype,
                                                   number = k,
                                                   classProbs = TRUE),
                          tuneGrid = expand.grid(sigma = sigmas,
                                                 C = Cs))
    }
    
  }
  if(cvtype == "None"){
    
    twoFeatSVM <- svm(formula = SVMFormula,
                      data = datasetTrain,
                      kernel = svmMethod,
                      cost = Cs,
                      gamma = sigmas,
                      scale = wantToScale)
    
  }
  
  print("Computing Support Vector Classifiers decision boundaries...")
  
  xycoef <- 5
  lengthOut <- 1001
  
  xsummand <- mean(datasetTrain[,var1])/xycoef
  xmax_SVMgrid <- max(datasetTrain[,var1]) + xsummand
  xmin_SVMgrid <- min(datasetTrain[,var1]) - xsummand
  
  ysummand <- mean(datasetTrain[,var2])/xycoef
  ymax_SVMgrid <- max(datasetTrain[,var2]) + ysummand
  ymin_SVMgrid <- min(datasetTrain[,var2]) - ysummand
  
  x_SVMgrid <- seq(xmin_SVMgrid, xmax_SVMgrid, length.out = lengthOut)
  y_SVMgrid <- seq(ymin_SVMgrid, ymax_SVMgrid, length.out = lengthOut)
  
  SVMgrid <- expand.grid(x1 = x_SVMgrid, x2 = y_SVMgrid)
  colnames(SVMgrid) <- c(var1, var2)
  gridClasses <- predict(twoFeatSVM, SVMgrid)
  SVMgrid <- cbind(SVMgrid, gridClasses)
  
  print("Plotting Support Vector Machine plots...")
  
  plotTitle <- paste("Support Vector Machines plot (",
                     var1,
                     " vs. ",
                     var2,
                     ")",
                     sep = "")
  
  plotTitleReal <- paste(plotTitle, " (real classes)", sep = "")
  plotTitlePred <- paste(plotTitle, " (predicted classes)", sep = "")
  plotTitleCorrect <- paste(plotTitle, " (correct/incorrect class)", sep = "")
  allPlotTitles <- c(plotTitleReal, plotTitlePred, plotTitleCorrect)
  
  allTestPred <- datasetTest
  datasetTestPred <- predict(inputSVM,
                             datasetTest[,-which(colnames(datasetTest) == classNameVariable)])
  allTestPred[,classColumn] <- datasetTestPred
  allTestPred <- rbind(datasetTrain, allTestPred)
  
  twoDataSets <- list(datasetAll, allTestPred)
  
  singleClasses <- as.character(unique(datasetAll[,classColumn]))
  lsc <- length(singleClasses)
  
  colorList <- list()
  colorListLight <- list()
  for(i in 1:length(unique(datasetTrain[,classColumn]))){
    iclass <- as.character(unique(datasetTrain[,classColumn]))[i]
    colorList[[iclass]] <- colorSelection[i]
    colorListLight[[iclass]] <- lighten(col = colorSelection[i],
                                        amount = lightFactor)
  }
  
  for(h in 1:length(allPlotTitles)){
    
    htitle <- allPlotTitles[h]
    
    plot(x = datasetAll[,var1],
         y = datasetAll[,var2],
         pch = 21,
         col = "black",
         xlab = var1,
         ylab = var2,
         xlim = range(pretty(datasetAll[,var1])),
         ylim = range(pretty(datasetAll[,var2])),
         main = htitle,
         cex = cexPoint)
    
    for(i in 1:length(unique(SVMgrid[,ncol(SVMgrid)]))){
      
      iclass <- as.character(unique(SVMgrid[,ncol(SVMgrid)]))[i]
      ibool <- as.character(SVMgrid[,ncol(SVMgrid)]) == iclass
      points(x = SVMgrid[ibool, var1],
             y = SVMgrid[ibool, var2],
             pch = gridPCH,
             cex = gridSize,
             col = colorListLight[[iclass]])
      
    }
    
    if(h != length(allPlotTitles)){
      
      hdataset <- twoDataSets[[h]]
      
      for(j in 1:lsc){
        
        jclass <- unique(hdataset[,classColumn])[j]
        jbool <- hdataset[,classColumn] == jclass
        points(x = hdataset[jbool,var1],
               y = hdataset[jbool,var2],
               pch = 21,
               col = "black",
               bg = colorList[[as.character(jclass)]],
               cex = cexPoint)
        
      }
      
      if(isLeg){
        legend(x = legendPosition,
               legend = c(singleClasses,
                          sprintf("SVM boundary ('%s' vs. rest)",
                                  singleClasses)),
               pch = c(rep(21, lsc), rep(gridPCH, lsc)),
               col = c(rep("black", lsc), unlist(colorListLight)),
               pt.bg = c(unlist(colorList), rep(NA, lsc)),
               cex = legendCex)
      }
      
    }else{
      
      okOrNot <- twoDataSets[[1]][,classColumn] == twoDataSets[[2]][,classColumn]
      not <- !(okOrNot)
      listOkNot <- list(okOrNot, not)
      OONCoolors <- c("forestgreen", "red2")
      
      for(i in 1:length(listOkNot)){
        
        points(x = datasetAll[listOkNot[[i]],var1],
               y = datasetAll[listOkNot[[i]],var2],
               pch = 21,
               col = "black",
               bg = OONCoolors[i],
               cex = cexPoint)
        
      }
      
      if(isLeg){
        legend(x = legendPosition,
               legend = c("Correct classifications",
                          "Incorrect classifications",
                          sprintf("SVM boundary ('%s' vs. rest)",
                                  singleClasses)),
               pch = c(rep(21, 2), rep(gridPCH, lsc)),
               col = c(rep("black", 2), unlist(colorListLight)),
               pt.bg = c(OONCoolors, rep(NA, lsc)),
               cex = legendCex)
      }
      
    }
    
  }
  
}

## 58) recursiveRandomForest4():

# 

recursiveRandomForest4 <- function(dataset,
                                   groups,
                                   treeNumber = 1000,
                                   retentionProportion = 0.8,
                                   chosenIterationsNumber = 5,
                                   withNormalization = TRUE,
                                   topNumber = 50,
                                   iterationsBest = 100,
                                   searchForBest = TRUE,
                                   howManyFeats = 8,
                                   MDSoptimization = TRUE,
                                   K = 3,
                                   clusterDistance = "euclidean",
                                   clusterMethod = "complete"){
  
  if(!("package:randomForest" %in% base::search())){
    library(randomForest)
  }
  
  importanceMatrix <- matrix(data = 0,
                             nrow = ncol(dataset),
                             ncol = 4)
  rownames(importanceMatrix) <- colnames(dataset)
  colnames(importanceMatrix) <- c("feature.index",
                                  "importance",
                                  "normalized.importance",
                                  "standard.cumulative")
  importanceMatrix[,"feature.index"] <- 1:nrow(importanceMatrix)
  
  iterations <- 1
  
  while(iterations <= chosenIterationsNumber){
    
    print(paste("Iteration: ", as.character(iterations), sep = ""))
    tempDataset <- dataset
    
    retentionLoop <- 1
    
    while(!(is.null(ncol(tempDataset)))){
      
      tempRF <- randomForest(x = tempDataset,
                             y = groups,
                             importance = TRUE,
                             ntree = treeNumber)
      
      tempImportance <- tempRF$importance
      
      vecImp <- tempImportance[,"MeanDecreaseAccuracy"]
      
      boolImp <- vecImp > 0
      boolNoImp <- vecImp < 0
      
      if(withNormalization){
        sumImp <- sum(vecImp[boolImp])
        sumNoImp <- sum(vecImp[boolNoImp])
        vecImp[boolImp] <- vecImp[boolImp] / sumImp
        vecImp[boolNoImp] <- vecImp[boolNoImp] / sumNoImp
      }
      
      importanceMatrix[rownames(tempImportance),"importance"] <-
        importanceMatrix[rownames(tempImportance),"importance"] + vecImp
      
      newOrder <- order(vecImp, decreasing = TRUE)
      tempImportance <- tempImportance[newOrder,]
      # View(tempImportance)
      
      retention <- floor(nrow(tempImportance) * retentionProportion)
      print(paste("Retained features (iteration: ",
                  as.character(iterations),
                  "; retention loop: ",
                  as.character(retentionLoop),
                  "): ",
                  as.character(retention),
                  sep = ""))
      featsRetained <- rownames(tempImportance)[1:retention]
      
      tempDataset <- tempDataset[,featsRetained]
      
      retentionLoop <- retentionLoop + 1
    }
    
    iterations <- iterations + 1
  }
  
  orderedMatrix <- order(importanceMatrix[,"importance"], decreasing = TRUE)
  orderedMatrix <- importanceMatrix[orderedMatrix,]
  
  boolOrdGreat <- orderedMatrix[,"importance"] > 0
  boolOrdLess <- orderedMatrix[,"importance"] < 0
  
  sumGreat <- sum(orderedMatrix[boolOrdGreat,"importance"])
  sumLess <- sum(orderedMatrix[boolOrdLess,"importance"])
  
  orderedMatrix[boolOrdGreat,"normalized.importance"] <-
    orderedMatrix[boolOrdGreat,"importance"] / sumGreat
  orderedMatrix[boolOrdLess,"normalized.importance"] <-
    -(orderedMatrix[boolOrdLess,"importance"] / sumLess)
  
  orderedMatrix[,"standard.cumulative"] <- cumsum(orderedMatrix[,"normalized.importance"])
  
  print("Importance matrix calculation ended. Generating best random forest.")
  
  iterations <- 1
  
  computeMDSscore <- function(K2,
                              proxMatrix,
                              clusterDistance2,
                              clusterMethod2,
                              groups2,
                              tempDataset2){
    
    MDSmatrix <- cmdscale(d = 1 - proxMatrix, k = K2)
    colnames(MDSmatrix) <- sprintf("MDS%s", 1:K)
    
    if(clusterDistance == "correlation"){
      MDSdist <- cor(t(MDSmatrix), use = "pairwise.complete.obs", method = "pearson")
      MDSdist <- as.dist(1 - MDSdist)
    }else{
      MDSdist <- dist(x = MDSmatrix, method = clusterDistance2)
    }
    
    MDSclust <- hclust(MDSdist, method = clusterMethod2)
    # plot(MDSclust)
    sampleClustered <- cutree(MDSclust, k = nlevels(groups2))
    doubleClustArr <- matrix(data = NA, ncol = 2, nrow = nrow(tempDataset2))
    rownames(doubleClustArr) <- rownames(tempDataset2)
    colnames(doubleClustArr) <- c("hclustPred", "real")
    doubleClustArr[,"real"] <- as.character(groups2)
    
    for(s in 1:max(sampleClustered)){
      ssamples <- names(sampleClustered)[sampleClustered == s]
      sclass <- doubleClustArr[ssamples,"real"]
      sclass <- names(which.max(table(sclass)))
      doubleClustArr[ssamples,"hclustPred"] <- sclass
    }
    
    innerMDSscore2 <- doubleClustArr[,"hclustPred"] == doubleClustArr[,"real"]
    innerMDSscore2 <- sum(innerMDSscore2) / length(innerMDSscore2)
    
    return(innerMDSscore2)
    
  }
  
  oobFeats <- c()
  oobBest <- 1
  outerMDSscore <- 0
  
  top <- rownames(orderedMatrix)[1:topNumber]
  
  bestDataset <- dataset[,top]
  
  while(iterations <= iterationsBest){
    
    tempDataset <- bestDataset
    if(searchForBest){
      print(paste("Number of iteration: ", as.character(iterations), sep = ""))
    }
    
    if(searchForBest){
      
      while(!(is.null(ncol(tempDataset)))){
        
        tempRF <- randomForest(x = tempDataset,
                               y = groups,
                               importance = TRUE,
                               proximity = TRUE,
                               ntree = treeNumber)
        
        conf <- tempRF$confusion[,-ncol(tempRF$confusion)]
        oob <- 1 - (sum(diag(conf)) / sum(sum(conf)))
        
        if(MDSoptimization){
          
          ########################################################################
          
          innerMDSscore <- computeMDSscore(K2 = K,
                                           proxMatrix = tempRF$proximity,
                                           clusterDistance2 = clusterDistance,
                                           clusterMethod2 = clusterMethod,
                                           groups2 = groups,
                                           tempDataset2 = tempDataset)
          
          ########################################################################
          
          if(oob < oobBest){
            print(paste("New found classifier. OOB = ",
                        as.character(round(oob, 5)),
                        ".", sep = ""))
            print(paste("New MDS score found. MDS score = ",
                        as.character(round(innerMDSscore, 5)),
                        ".", sep = ""))
            oobBest <- oob
            oobFeats <- colnames(tempDataset)
            bestRF <- tempRF
            outerMDSscore <- innerMDSscore
          }
          
          if(oob == oobBest){
            if(outerMDSscore < innerMDSscore){
              print(paste("New found classifier with same OOB. OOB = ",
                          as.character(round(oob, 5)),
                          ".", sep = ""))
              print(paste("New MDS score found. MDS score = ",
                          as.character(round(innerMDSscore, 5)),
                          ".", sep = ""))
              oobBest <- oob
              oobFeats <- colnames(tempDataset)
              bestRF <- tempRF
              outerMDSscore <- innerMDSscore
            }
          }
          
        }else{
          
          if(oob < oobBest){
            print(paste("New found classifier. OOB = ",
                        as.character(round(oob, 5)),
                        ".", sep = ""))
            oobBest <- oob
            oobFeats <- colnames(tempDataset)
            bestRF <- tempRF
          }
          
        }
        
        importanceRF <- tempRF$importance[,"MeanDecreaseAccuracy"]
        retainedFeats <- rownames(tempRF$importance[order(importanceRF, decreasing = TRUE),])
        retainedFeats <- retainedFeats[-length(retainedFeats)]
        tempDataset <- tempDataset[,retainedFeats]
        
      }
      
    }else{
      
      while(!(is.null(ncol(tempDataset)))){
        
        tempRF <- randomForest(x = tempDataset,
                               y = groups,
                               importance = TRUE,
                               proximity = TRUE,
                               ntree = treeNumber)
        
        if(ncol(tempDataset) == howManyFeats){
          
          print(paste("Number of iteration (selected number of features: ",
                      as.character(howManyFeats),
                      "): ",
                      as.character(iterations),
                      sep = ""))
          
          conf <- tempRF$confusion[,-ncol(tempRF$confusion)]
          oob <- 1 - (sum(diag(conf)) / sum(sum(conf)))
          
          if(MDSoptimization){
            
            ########################################################################
            
            innerMDSscore <- computeMDSscore(K2 = K,
                                             proxMatrix = tempRF$proximity,
                                             clusterDistance2 = clusterDistance,
                                             clusterMethod2 = clusterMethod,
                                             groups2 = groups,
                                             tempDataset2 = tempDataset)
            
            ########################################################################
            
            if(oob < oobBest){
              print(paste("New found classifier. OOB = ",
                          as.character(round(oob, 5)),
                          ".", sep = ""))
              print(paste("New MDS score found. MDS score = ",
                          as.character(round(innerMDSscore, 5)),
                          ".", sep = ""))
              oobBest <- oob
              oobFeats <- colnames(tempDataset)
              bestRF <- tempRF
              outerMDSscore <- innerMDSscore
            }
            
            if(oob == oobBest){
              if(outerMDSscore < innerMDSscore){
                print(paste("New found classifier with same OOB. OOB = ",
                            as.character(round(oob, 5)),
                            ".", sep = ""))
                print(paste("New MDS score found. MDS score = ",
                            as.character(round(innerMDSscore, 5)),
                            ".", sep = ""))
                oobBest <- oob
                oobFeats <- colnames(tempDataset)
                bestRF <- tempRF
                outerMDSscore <- innerMDSscore
              }
            }
            
          }else{
            
            if(oob < oobBest){
              print(paste("New found classifier. OOB: ",
                          as.character(round(oob, 5))))
              oobBest <- oob
              oobFeats <- colnames(tempDataset)
              bestRF <- tempRF
            }
            
          }
          
        }
        
        importanceRF <- tempRF$importance[,"MeanDecreaseAccuracy"]
        retainedFeats <- rownames(tempRF$importance[order(importanceRF, decreasing = TRUE),])
        retainedFeats <- retainedFeats[-length(retainedFeats)]
        tempDataset <- tempDataset[,retainedFeats]
        
      }
      
    }
    
    iterations <- iterations + 1
    
    if(MDSoptimization){
      if(oobBest == 0 & outerMDSscore == 1){
        print(paste("Potential optimal classifier found. Stoping feature and classifier search"))
        break
      }
    }else{
      if(oobBest == 0){
        print(paste("Potential optimal classifier found. Stoping feature and classifier search"))
        break
      }
    }
    
  }
  
  print("Done.")
  
  resultsList <- list()
  resultsList[[1]] <- orderedMatrix
  resultsList[[2]] <- oobFeats
  resultsList[[3]] <- bestRF
  
  names(resultsList) <- c("importance.matrix", "chosen.features", "best.RF")
  
  return(resultsList)
  
}

## 59) thatWasSoObvious():

# Finds the most significant proteins between all contrasts in data. It is fed
# by the results of ANOVA.

thatWasSoObvious <- function(ANOVAMatrix,
                              nProteins = 1){
  
  qValuesIndex <- grep(x = colnames(ANOVAMatrix),
                       pattern = "qvalue.Ftest",
                       fixed = TRUE)
  log2Indices <- grep(x = colnames(ANOVAMatrix),
                      pattern = "log",
                      fixed = TRUE)
  
  contrastsMatrix <- ANOVAMatrix[,(qValuesIndex + 1):(log2Indices[1] - 1)]
  
  bestFeats <- c()
  featsMatrix <- matrix(data = NA,
                        ncol = ncol(contrastsMatrix),
                        nrow = nProteins)
  colnames(featsMatrix) <- colnames(contrastsMatrix)
  rownames(featsMatrix) <- 1:nProteins
  for(i in 1:ncol(contrastsMatrix)){
    iordCol <- contrastsMatrix[,i][order(contrastsMatrix[,i], decreasing = FALSE)]
    inames <- names(iordCol)[1:nProteins]
    bestFeats <- append(x = bestFeats,
                        values = inames)
    featsMatrix[,i] <- inames
  }
  bestFeats <- unique(bestFeats)
  
  return(list("bestFeats" = bestFeats,
              "featsMatrix" = featsMatrix))
  
}

## recursiveRandomForest5()

# 

recursiveRandomForest5 <- function(dataset,
                                   groups,
                                   treeNumber = 1000,
                                   retentionByProp = FALSE,
                                   retentionProportion = 0.8,
                                   retentionLoops = 30,
                                   chosenIterationsNumber = 5,
                                   pValueMethod = "fdr",
                                   pValueThres = 0.05,
                                   classifierMethod = "importancePValue"){ # c("importancePValue", "randomThreshold")
  
  if(!("package:randomForest" %in% base::search())){
    library(randomForest)
  }
  
  if(retentionByProp){
    
    retentionProportion2 <- retentionProportion
    
  }else{
    
    howManyLoops <- function(nfeat, wantedLoops){
      prob <- seq(1 - 0.001, 0.001, by = -0.001)
      iterationsVector <- c()
      for(i in 1:length(prob)){
        remaining <- c()
        remember <- nfeat
        k <- 1
        while(remember > 1){
          remember <- floor(remember * prob[i])
          remaining <- append(x = remaining, values = remember)
        }
        iterationsVector <- append(x = iterationsVector, values = length(remaining))
      }
      
      return(prob[iterationsVector == wantedLoops])
    }
    
    retentionProportion2 <- howManyLoops(nfeat = ncol(dataset), wantedLoops = retentionLoops)[1]
    if(is.na(retentionProportion2)){
      print("The number of features in the chosen data set is relatively small. A single feature will be eliminated by step instead.")
      retentionProportion2 <- 0.99
    }
    
  }
  
  rrfIterator <- function(innerDataSet,
                          innerGroups,
                          innerTreeNumber,
                          innerRetentionProportion,
                          innerChosenIterations,
                          isRandomized,
                          innerPValueMethod,
                          innerPValueThres){
    
    if(isRandomized){
      print("Recursive binary random forest: Randomized importance measurement")
    }else{
      print("Recursive binary random forest: Importance measurement.")
    }
    
    listImportanceMatrix <- list()
    
    for(i in 1:length(unique(innerGroups))){
      
      igroupsVector <- as.character(innerGroups)
      igroup <- unique(igroupsVector)[i]
      
      cat("\n")
      print(paste("Group that is being compared to rest: ", igroup, ".", sep = ""))
      
      igroupsVector[igroupsVector != igroup] <- "Other"
      if(isRandomized){
        igroupsVector <- sample(igroupsVector)
      }
      igroupsVector <- as.factor(igroupsVector)
      
      importanceMatrix <- matrix(data = 0,
                                 nrow = ncol(innerDataSet),
                                 ncol = 6)
      rownames(importanceMatrix) <- colnames(innerDataSet)
      colnames(importanceMatrix) <- c("feature.index",
                                      "importance",
                                      "importance.pvalue",
                                      paste("is.significant.", as.character(pValueThres), sep = ""),
                                      "normalized.importance",
                                      "standard.cumulative")
      importanceMatrix[,"feature.index"] <- 1:nrow(importanceMatrix)
      
      iterations <- 1
      
      while(iterations <= innerChosenIterations){
        
        print(paste("Iteration for recursive feature elimination: ",
                    as.character(iterations),
                    ".",
                    sep = ""))
        tempDataSet <- innerDataSet
        
        retentionLoop <- 1
        
        while(!(is.null(ncol(tempDataSet)))){
          
          tempRF <- randomForest(x = tempDataSet,
                                 y = igroupsVector,
                                 importance = TRUE,
                                 ntree = innerTreeNumber)
          
          tempImportance <- tempRF$importance
          
          vecImp <- tempImportance[,"MeanDecreaseAccuracy"]
          
          importanceMatrix[rownames(tempImportance),"importance"] <-
            importanceMatrix[rownames(tempImportance),"importance"] + vecImp
          
          newOrder <- order(vecImp, decreasing = TRUE)
          tempImportance <- tempImportance[newOrder,]
          
          retention <- floor(nrow(tempImportance) * innerRetentionProportion)
          print(paste("Retained features (iteration: ",
                      as.character(iterations),
                      "; retention loop: ",
                      as.character(retentionLoop),
                      "): ",
                      as.character(retention),
                      ".",
                      sep = ""))
          
          featsRetained <- rownames(tempImportance)[1:retention]
          tempDataSet <- tempDataSet[,featsRetained]
          
          retentionLoop <- retentionLoop + 1
          
        }
        
        iterations <- iterations + 1
        
      }
      
      orderedMatrix <- order(importanceMatrix[,"importance"], decreasing = TRUE)
      orderedMatrix <- importanceMatrix[orderedMatrix,]
      
      boolOrdGreat <- orderedMatrix[,"importance"] > 0
      boolOrdLess <- orderedMatrix[,"importance"] < 0
      
      sumGreat <- sum(orderedMatrix[boolOrdGreat,"importance"])
      sumLess <- sum(orderedMatrix[boolOrdLess,"importance"])
      
      orderedMatrix[boolOrdGreat,"normalized.importance"] <-
        orderedMatrix[boolOrdGreat,"importance"] / sumGreat
      orderedMatrix[boolOrdLess,"normalized.importance"] <-
        -(orderedMatrix[boolOrdLess,"importance"] / sumLess)
      
      orderedMatrix[,"standard.cumulative"] <- cumsum(orderedMatrix[,"normalized.importance"])
      
      # Importance p-value calculation
      
      # importanceDensity <- density(x = orderedMatrix[,"importance"],
      #                              n = 10000) # more theoretically correct.
      importanceDensity <- density(x = orderedMatrix[,"importance"],
                                   n = 10000,
                                   from = min(orderedMatrix[, "importance"]),
                                   to = max(orderedMatrix[, "importance"]))
      densityX <- importanceDensity$x
      xBin <- densityX[2] - densityX[1]
      densityY <- importanceDensity$y
      normalizationValue <- sum(densityY) * xBin
      importancePValues <- sapply(X = orderedMatrix[,"importance"],
                                  FUN = function(z)
                                    sum(densityY[densityX >= z] * xBin)) / normalizationValue
      
      orderedMatrix[, "importance.pvalue"] <- importancePValues
      orderedMatrix[, paste("is.significant.",
                            as.character(pValueThres),
                            sep = "")] <- importancePValues <= innerPValueThres
      
      listImportanceMatrix[[as.character(igroup)]] <- orderedMatrix
      
    }
    
    return(listImportanceMatrix)
    
  }
  
  cat("\n")
  noRandResults <- rrfIterator(innerDataSet = dataset,
                               innerGroups = groups,
                               innerTreeNumber = treeNumber,
                               innerRetentionProportion = retentionProportion2,
                               innerChosenIterations = chosenIterationsNumber,
                               isRandomized = FALSE,
                               innerPValueMethod = pValueMethod,
                               innerPValueThres = pValueThres)
  cat("\n")
  randResults <- rrfIterator(innerDataSet = dataset,
                             innerGroups = groups,
                             innerTreeNumber = treeNumber,
                             innerRetentionProportion = retentionProportion2,
                             innerChosenIterations = chosenIterationsNumber,
                             isRandomized = TRUE,
                             innerPValueMethod = pValueMethod,
                             innerPValueThres = pValueThres)
  
  randThresList <- lapply(X = randResults,
                          FUN = function(x) max(x[,"importance"]))
  
  cat("\n")
  print("Importance matrix calculation ended. Generating best random forest.")
  
  listBinaryClassifiers <- list()
  allSigFeats <- c()
  
  for(i in 1:length(unique(groups))){
    
    igroupsVector <- as.character(groups)
    igroup <- unique(igroupsVector)[i]
    
    igroupsVector[igroupsVector != igroup] <- "Other"
    igroupsVector <- as.factor(igroupsVector)
    
    if(classifierMethod == "importancePValue"){
      sigFeats <- as.logical(noRandResults[[igroup]][,paste("is.significant.",
                                                            as.character(pValueThres),
                                                            sep = "")])
      sigFeats <- rownames(noRandResults[[igroup]])[sigFeats]
    }
    if(classifierMethod == "randomThreshold"){
      sigFeats <- noRandResults[[igroup]][,"importance"] > max(randResults[[igroup]][,"importance"])
      sigFeats <- rownames(noRandResults[[igroup]])[sigFeats]
    }
    
    d <- dataset[, sigFeats]
    if(length(sigFeats) == 1){
      d <- matrix(data = d, ncol = 1)
      colnames(d) <- sigFeats
      if(length(rownames(d)) > 0){
        rownames(d) <- rownames(dataset)
      }
    }
    
    listBinaryClassifiers[[igroup]] <- list("classifier" = randomForest(x = d,
                                                                        y = igroupsVector,
                                                                        importance = TRUE,
                                                                        proximity = TRUE,
                                                                        ntree = treeNumber),
                                            "features" = sigFeats)
    
    allSigFeats <- append(x = allSigFeats, values = sigFeats)
    
  }
  
  allSigFeats <- unique(allSigFeats)
  
  ngroups <- length(unique(groups))
  uniqueClassBestFeats <- unique(unlist(lapply(X = noRandResults,
                                               FUN = function(x) rownames(x)[1:ngroups])))
  unifyingClassifier <- list("classifier" = randomForest(x = dataset[,uniqueClassBestFeats],
                                                         y = groups,
                                                         importance = TRUE,
                                                         proximity = TRUE,
                                                         ntree = treeNumber),
                             "features" = uniqueClassBestFeats)
  
  resultsList <- list("noRandResults" = noRandResults,
                      "randResults" = randResults,
                      "randThresList" = randThresList,
                      "listBinaryClassifiers" = listBinaryClassifiers,
                      "allSigFeats" = allSigFeats,
                      "unifyingClassifier" = unifyingClassifier)
  
  print("Done.")
  
  return(resultsList)
  
}

## plot3D():

# 

plot3D <- function(data3D,
                   classVector,
                   classColors,
                   main3D = "3D plot",
                   dimension1Name,
                   dimension2Name,
                   dimension3Name,
                   cex3D = 1.2,
                   cexLegend = 1.5,
                   xAxisLimits = NULL,
                   yAxisLimits = NULL,
                   zAxisLimits = NULL,
                   par3D = 1){
  
  if(!("package:rgl" %in% base::search())){
    library(rgl)
  }
  
  classesOnlyOnce <- unique(classVector)
  namedColors <- classColors
  names(namedColors) <- classesOnlyOnce
  completeColorVector <- namedColors[classVector]
  
  if(is.null(xAxisLimits)){
    xDif <- pretty(c(min(data3D[,1]), max(data3D[,1])))[2] -
      pretty(c(min(data3D[,1]), max(data3D[,1])))[1]
    xRangeMin <- min(data3D[,1]) - xDif
    xRangeMax <- max(data3D[,1]) + xDif
    xRange <- range(pretty(c(xRangeMin, xRangeMax)))
  }else{
    xRange <- c(xAxisLimits[1], xAxisLimits[2])
  }
  
  if(is.null(yAxisLimits)){
    yDif <- pretty(c(min(data3D[,2]), max(data3D[,2])))[2] -
      pretty(c(min(data3D[,2]), max(data3D[,2])))[1]
    yRangeMin <- min(data3D[,2]) - yDif
    yRangeMax <- max(data3D[,2]) + yDif
    yRange <- range(pretty(c(yRangeMin, yRangeMax)))
  }else{
    yRange <- c(yAxisLimits[1], yAxisLimits[2])
  }
  
  if(is.null(zAxisLimits)){
    zDif <- pretty(c(min(data3D[,3]), max(data3D[,3])))[2] -
      pretty(c(min(data3D[,3]), max(data3D[,3])))[1]
    zRangeMin <- min(data3D[,3]) - zDif
    zRangeMax <- max(data3D[,3]) + zDif
    zRange <- range(pretty(c(zRangeMin, zRangeMax)))
  }else{
    zRange <- c(zAxisLimits[1], zAxisLimits[2])
  }
  
  dimensionNames <- colnames(data3D)
  
  if(is.null(dimensionNames[1])){
    dimension1Name <- "Dimension 1"
  }
  if(is.null(dimensionNames[2])){
    dimension2Name <- "Dimension 2"
  }
  if(is.null(dimensionNames[3])){
    dimension3Name <- "Dimension 3"
  }
  
  par3d(cex = par3D)
  
  plot3d(x = data3D[,1],
         y = data3D[,2],
         z = data3D[,3],
         main = main3D,
         xlab = dimensionNames[1],
         ylab = dimensionNames[2],
         zlab = dimensionNames[3],
         type = "s",
         size = cex3D,
         col = completeColorVector,
         xlim = xRange,
         ylim = yRange,
         zlim = zRange)
  
  legend3d(x = "topright",
           legend = classesOnlyOnce,
           col = classColors,
           pch = 19,
           cex = cexLegend,
           inset = c(0.05))
  
}

plot3D(data3D = rbind(trainingData2[,sigFeatures2],
                      testData2[,sigFeatures2]),
       classVector = c(trainingVector5, testVector5),
       classColors = RColorBrewer::brewer.pal(n = 8, name = "Set2")[c(1:length(unique(trainingVector5)))],
       main3D = "3D plot")

## multiROC2():

multiROC2 <- function(realClasses,
                      probabilities){
  
  if(!("package:verification" %in% search())){
    library(verification)
  }
  
  allClasses <- unique(realClasses)
  allClasses <- allClasses[order(allClasses)]
  
  if(length(allClasses) == 2){
    
    controlClass <- allClasses[1]
    casesClass <- allClasses[2]
    
    newX <- as.numeric(realClasses == casesClass)
    predProb <- probabilities[,casesClass] # should have lower values associated
    # to control class.
    
    finallyAGoodROC <- verification::roc.plot(x = newX, # a binary observation
                                              # (coded{0, 1})
                                              pred = predProb, # a probability
                                              # prediction
                                              xlab =  "1 - specificity",
                                              ylab = "Sensitivity"
                                              )
    
    return(finallyAGoodROC)
    
  }else{ # I'm not sure if this will need a value conversion for probabilities. 
    
    listOfROCs <- list()
    
    for(i in 1:length(allClasses)){
      
      iclass <- allClasses[i]
      irealClasses <- as.numeric(realClasses != iclass)
      ipredProb <- probabilities[,iclass]
      iROC <- verification::roc.plot(x = irealClasses, # a binary observation
                                     # (coded{0, 1})
                                     pred = ipredProb, # a probability
                                     # prediction
                                     xlab =  "1 - specificity",
                                     ylab = "Sensitivity"
                                     )
      listOfROCs[[iclass]] <- iROC
      
    }
    
    return(listOfROCs)
    
  }
  
}

## rrf6():

# 

recursiveRandomForest6 <- function(dataset,
                                   groups,
                                   treeNumber = 1000,
                                   retentionByProp = FALSE,
                                   retentionProportion = 0.8,
                                   retentionLoops = 30,
                                   chosenIterationsNumber = 5,
                                   pValueThres = 0.05,
                                   classifierMethod = "elbowMethodPositive",
                                   isElbowPlot = TRUE){
  
  if(!("package:randomForest" %in% base::search())){
    library(randomForest)
  }
  
  if(retentionByProp){
    
    retentionProportion2 <- retentionProportion
    
  }else{
    
    howManyLoops <- function(nfeat, wantedLoops){
      prob <- seq(1 - 0.001, 0.001, by = -0.001)
      iterationsVector <- c()
      for(i in 1:length(prob)){
        remaining <- c()
        remember <- nfeat
        k <- 1
        while(remember > 1){
          remember <- floor(remember * prob[i])
          remaining <- append(x = remaining, values = remember)
        }
        iterationsVector <- append(x = iterationsVector, values = length(remaining))
      }
      
      return(prob[iterationsVector == wantedLoops])
    }
    
    retentionProportion2 <- howManyLoops(nfeat = ncol(dataset), wantedLoops = retentionLoops)[1]
    if(is.na(retentionProportion2)){
      print("The number of features in the chosen data set is relatively small. A single feature will be eliminated by step instead.")
      retentionProportion2 <- 0.99
    }
    
  }
  
  rrfIterator <- function(innerDataSet,
                          innerGroups,
                          innerTreeNumber,
                          innerRetentionProportion,
                          innerChosenIterations,
                          isRandomized,
                          innerPValueThres,
                          isElbowPlot2){
    
    if(isRandomized){
      print("Recursive binary random forest: Randomized importance measurement")
    }else{
      print("Recursive binary random forest: Importance measurement.")
    }
    
    listImportanceMatrix <- list()
    
    for(i in 1:length(unique(innerGroups))){
      
      igroupsVector <- as.character(innerGroups)
      igroup <- unique(igroupsVector)[i]
      
      cat("\n")
      print(paste("Group that is being compared to rest: ", igroup, ".", sep = ""))
      
      igroupsVector[igroupsVector != igroup] <- "Other"
      if(isRandomized){
        igroupsVector <- sample(igroupsVector)
      }
      igroupsVector <- as.factor(igroupsVector)
      
      importanceMatrix <- matrix(data = 0,
                                 nrow = ncol(innerDataSet),
                                 ncol = 10)
      rownames(importanceMatrix) <- colnames(innerDataSet)
      colnames(importanceMatrix) <- c("feature.index",
                                      "importance",
                                      "normalized.importance",
                                      "standard.cumulative",
                                      "importance.pvalue",
                                      paste("is.significant.", as.character(pValueThres), sep = ""),
                                      "y0.elbow.method",
                                      "is.elbow.method",
                                      "y0.elbow.method.positive",
                                      "is.elbow.method.positive")
      importanceMatrix[,"feature.index"] <- 1:nrow(importanceMatrix)
      
      iterations <- 1
      
      while(iterations <= innerChosenIterations){
        
        print(paste("Iteration for recursive feature elimination: ",
                    as.character(iterations),
                    ".",
                    sep = ""))
        tempDataSet <- innerDataSet
        
        retentionLoop <- 1
        
        while(!(is.null(ncol(tempDataSet)))){
          
          tempRF <- randomForest(x = tempDataSet,
                                 y = igroupsVector,
                                 importance = TRUE,
                                 ntree = innerTreeNumber)
          
          tempImportance <- tempRF$importance
          
          vecImp <- tempImportance[,"MeanDecreaseAccuracy"]
          
          importanceMatrix[rownames(tempImportance),"importance"] <-
            importanceMatrix[rownames(tempImportance),"importance"] + vecImp
          
          newOrder <- order(vecImp, decreasing = TRUE)
          tempImportance <- tempImportance[newOrder,]
          
          retention <- floor(nrow(tempImportance) * innerRetentionProportion)
          print(paste("Retained features (iteration: ",
                      as.character(iterations),
                      "; retention loop: ",
                      as.character(retentionLoop),
                      "): ",
                      as.character(retention),
                      ".",
                      sep = ""))
          
          featsRetained <- rownames(tempImportance)[1:retention]
          tempDataSet <- tempDataSet[,featsRetained]
          
          retentionLoop <- retentionLoop + 1
          
        }
        
        iterations <- iterations + 1
        
      }
      
      orderedMatrix <- order(importanceMatrix[,"importance"], decreasing = TRUE)
      orderedMatrix <- importanceMatrix[orderedMatrix,]
      
      boolOrdGreat <- orderedMatrix[,"importance"] > 0
      boolOrdLess <- orderedMatrix[,"importance"] < 0
      
      sumGreat <- sum(orderedMatrix[boolOrdGreat,"importance"])
      sumLess <- sum(orderedMatrix[boolOrdLess,"importance"])
      
      orderedMatrix[boolOrdGreat,"normalized.importance"] <-
        orderedMatrix[boolOrdGreat,"importance"] / sumGreat
      orderedMatrix[boolOrdLess,"normalized.importance"] <-
        -(orderedMatrix[boolOrdLess,"importance"] / sumLess)
      
      orderedMatrix[,"standard.cumulative"] <- cumsum(orderedMatrix[,"normalized.importance"])
      
      # Importance p-value calculation
      
      # importanceDensity <- density(x = orderedMatrix[,"importance"],
      #                              n = 10000) # more theoretically correct.
      importanceDensity <- density(x = orderedMatrix[,"importance"],
                                   n = 10000,
                                   from = min(orderedMatrix[, "importance"]),
                                   to = max(orderedMatrix[, "importance"]))
      densityX <- importanceDensity$x
      xBin <- densityX[2] - densityX[1]
      densityY <- importanceDensity$y
      normalizationValue <- sum(densityY) * xBin
      importancePValues <- sapply(X = orderedMatrix[,"importance"],
                                  FUN = function(z)
                                    sum(densityY[densityX >= z] * xBin)) / normalizationValue
      
      orderedMatrix[, "importance.pvalue"] <- importancePValues
      orderedMatrix[, paste("is.significant.",
                            as.character(pValueThres),
                            sep = "")] <- importancePValues <= innerPValueThres
      
      # Elbow method on feature importance:
      
      slopeCalculation_x <- c(1, nrow(orderedMatrix))
      slopeCalculation_y <- c(max(orderedMatrix[,"importance"]),
                              min(orderedMatrix[,"importance"]))
      slope <- (slopeCalculation_y[2] - slopeCalculation_y[1]) /
        (slopeCalculation_x[2] - slopeCalculation_x[1])
      interceptors <- c()
      for(j in 1:nrow(orderedMatrix)){
        jx <- j
        jy <- orderedMatrix[j,"importance"]
        jinterceptor <- jy - jx * slope
        interceptors <- append(x = interceptors, values = jinterceptor)
      }
      
      orderedMatrix[,"y0.elbow.method"] <- interceptors
      orderedMatrix[,"is.elbow.method"] <- as.numeric(1:nrow(orderedMatrix) <
                                                        which.min(interceptors))
      
      # Elbow method on feature importance (positive importances only):
      
      positiveImp <- rownames(orderedMatrix)[orderedMatrix[,"importance"] >= 0]
      nPositiveImp <- length(positiveImp)
      slopeCalculation_x <- c(1, nPositiveImp)
      slopeCalculation_y <- c(max(orderedMatrix[positiveImp,"importance"]),
                              min(orderedMatrix[positiveImp,"importance"]))
      
      slope <- (slopeCalculation_y[2] - slopeCalculation_y[1]) /
        (slopeCalculation_x[2] - slopeCalculation_x[1])
      interceptorsPositive <- c()
      for(j in 1:nPositiveImp){
        jx <- j
        jy <- orderedMatrix[positiveImp[j],"importance"]
        jinterceptor <- jy - jx * slope
        interceptorsPositive <- append(x = interceptorsPositive, values = jinterceptor)
      }
      
      orderedMatrix[,"y0.elbow.method.positive"] <- c(interceptorsPositive,
                                                      rep(NA, (nrow(orderedMatrix) - nPositiveImp)))
      orderedMatrix[,"is.elbow.method.positive"] <- c(as.numeric(1:nPositiveImp <
                                                                   which.min(interceptorsPositive)),
                                                      rep(0, (nrow(orderedMatrix) - nPositiveImp)))
      
      if(isElbowPlot2){
        
        titlePart2 <- paste("('",
                            as.character(unique(igroupsVector))[1],
                            "' vs. '",
                            as.character(unique(igroupsVector))[2],
                            "')",
                            sep = "")
        
        if(isRandomized){
          titlePart3 <- "(randomization results)"
        }else{
          titlePart3 <- "(standard results)"
        }
        
        elbowPlotTitle <- paste("Elbow method on feature importance ",
                                titlePart2,
                                " ",
                                titlePart3,
                                sep = "")
        
        plot(x = 1:nrow(orderedMatrix),
             y = orderedMatrix[,"normalized.importance"],
             xlim = range(pretty(c(0,nrow(orderedMatrix)))),
             ylim = range(pretty(orderedMatrix[,"normalized.importance"])),
             xlab = "Feature index",
             ylab = "Random forest importance value",
             main = elbowPlotTitle,
             pch = 21,
             col = "black",
             bg = c(rep("red", (which.min(interceptors) - 1) ),
                    rep("royalblue3", (nrow(orderedMatrix) - which.min(interceptors)) + 1) ),
             cex = 1)
        
        legend(x = "topright",
               legend = c("Features selected",
                          "Features excluded"),
               inset = c(0.02, 0.04),
               pch = 21,
               col = "black",
               pt.bg = c("red", "royalblue3"),
               cex = 1)
        
        elbowPlotTitle <- paste(elbowPlotTitle,
                                " (+)",
                                sep = "")
        
        plot(x = 1:nPositiveImp,
             y = orderedMatrix[positiveImp,"normalized.importance"],
             xlim = range(pretty(c(0,nPositiveImp))),
             ylim = range(pretty(orderedMatrix[positiveImp,"normalized.importance"])),
             xlab = "Feature index",
             ylab = "Random forest importance value",
             main = elbowPlotTitle,
             pch = 21,
             col = "black",
             bg = c(rep("red", (which.min(interceptorsPositive) - 1) ),
                    rep("royalblue3", (nPositiveImp - which.min(interceptorsPositive) + 1)) ),
             cex = 1)
        
        legend(x = "topright",
               legend = c("Features selected",
                          "Features excluded"),
               inset = c(0.02, 0.04),
               pch = 21,
               col = "black",
               pt.bg = c("red", "royalblue3"),
               cex = 1)
        
      }
      
      listImportanceMatrix[[as.character(igroup)]] <- orderedMatrix
      
    }
    
    return(listImportanceMatrix)
    
  }
  
  cat("\n")
  noRandResults <- rrfIterator(innerDataSet = dataset,
                               innerGroups = groups,
                               innerTreeNumber = treeNumber,
                               innerRetentionProportion = retentionProportion2,
                               innerChosenIterations = chosenIterationsNumber,
                               isRandomized = FALSE,
                               innerPValueThres = pValueThres,
                               isElbowPlot2 = isElbowPlot)
  cat("\n")
  randResults <- rrfIterator(innerDataSet = dataset,
                             innerGroups = groups,
                             innerTreeNumber = treeNumber,
                             innerRetentionProportion = retentionProportion2,
                             innerChosenIterations = chosenIterationsNumber,
                             isRandomized = TRUE,
                             innerPValueThres = pValueThres,
                             isElbowPlot2 = isElbowPlot)
  
  randThresList <- lapply(X = randResults,
                          FUN = function(x) max(x[,"normalized.importance"]))
  
  cat("\n")
  print("Importance matrix calculation ended. Generating best random forest.")
  
  listBinaryClassifiers <- list()
  allSigFeats <- c()
  
  for(i in 1:length(unique(groups))){
    
    igroupsVector <- as.character(groups)
    igroup <- unique(igroupsVector)[i]
    
    igroupsVector[igroupsVector != igroup] <- "Other"
    igroupsVector <- as.factor(igroupsVector)
    
    if(classifierMethod == "importancePValue"){
      sigFeats <- as.logical(noRandResults[[igroup]][,paste("is.significant.",
                                                            as.character(pValueThres),
                                                            sep = "")])
      sigFeats <- rownames(noRandResults[[igroup]])[sigFeats]
    }
    if(classifierMethod == "randomThreshold"){
      sigFeats <- noRandResults[[igroup]][,"normalized.importance"] >
        max(randResults[[igroup]][,"normalized.importance"])
      sigFeats <- rownames(noRandResults[[igroup]])[sigFeats]
    }
    if(classifierMethod == "elbowMethod"){
      sigFeats <- noRandResults[[igroup]][,"is.elbow.method"] == 1
      sigFeats <- rownames(noRandResults[[igroup]])[sigFeats]
    }
    if(classifierMethod == "elbowMethodPositive"){
      sigFeats <- noRandResults[[igroup]][,"is.elbow.method.positive"] == 1
      sigFeats <- rownames(noRandResults[[igroup]])[sigFeats]
    }
    
    d <- dataset[, sigFeats]
    if(length(sigFeats) == 1){
      d <- matrix(data = d, ncol = 1)
      colnames(d) <- sigFeats
      if(length(rownames(d)) > 0){
        rownames(d) <- rownames(dataset)
      }
    }
    
    listBinaryClassifiers[[igroup]] <- list("classifier" = randomForest(x = d,
                                                                        y = igroupsVector,
                                                                        importance = TRUE,
                                                                        proximity = TRUE,
                                                                        ntree = treeNumber),
                                            "features" = sigFeats)
    
    allSigFeats <- append(x = allSigFeats, values = sigFeats)
    
  }
  
  allSigFeats <- unique(allSigFeats)
  
  ngroups <- length(unique(groups))
  uniqueClassBestFeats <- unique(unlist(lapply(X = noRandResults,
                                               FUN = function(x) rownames(x)[1:ngroups])))
  if(length(uniqueClassBestFeats) == 1){
    dataForLastRF <- as.matrix(dataset[,uniqueClassBestFeats])
    colnames(dataForLastRF) <- uniqueClassBestFeats
  }else{
    dataForLastRF <- dataset[,uniqueClassBestFeats]
  }
  unifyingClassifier <- list("classifier" = randomForest(x = dataForLastRF,
                                                         y = as.factor(groups),
                                                         importance = TRUE,
                                                         proximity = TRUE,
                                                         ntree = treeNumber),
                             "features" = uniqueClassBestFeats)
  
  resultsList <- list("noRandResults" = noRandResults,
                      "randResults" = randResults,
                      "randThresList" = randThresList,
                      "listBinaryClassifiers" = listBinaryClassifiers,
                      "allSigFeats" = allSigFeats,
                      "unifyingClassifier" = unifyingClassifier)
  
  print("Done.")
  
  return(resultsList)
  
}

## plotUMAP():

# 

plotUMAP <- function(UMAPdata,
                     UMAPlabels,
                     UMAPdimension1 = 1,
                     UMAPdimension2 = 2,
                     UMAPcolors = NULL,
                     UMAPncomponents = 2,
                     UMAPRandomState = 1,
                     mainUMAPtitle,
                     legPos = "topright",
                     legSize = 1,
                     legInset = c(0, 0),
                     cexPoints = 1){
  
  # By default:
  # k- nearest neighbors = 15
  # Distance metric = euclidean
  # Epochs = 200
  # Minimum distance = 0.1
  # Mix ratio = 1
  # Local connectivity = 1
  # Bandwidth = 1
  # Alpha = 1
  # Gamma = 1
  # Negative sample rate = 5
  # Spread = 1
  
  if(!("package:umap" %in% search())){
    library(umap)
  }
  if(!("package:RColorBrewer" %in% search())){
    library(RColorBrewer)
  }
  
  umapdefault <- umap.defaults
  
  if(!(is.na(UMAPRandomState))){
    umapdefault$random_state <- UMAPRandomState
  }
  
  trueUMAPncomponents <- max(c(UMAPdimension1, UMAPdimension2, UMAPncomponents))
  if(trueUMAPncomponents > 2){
    umapdefault$n_components <- trueUMAPncomponents
  }
  
  UMAPlabels <- as.character(UMAPlabels)
  uniqueClasses <- unique(UMAPlabels)
  
  if(is.null(UMAPcolors)){
    if(length(uniqueClasses) <= 8){
      trueUMAPcolors <- RColorBrewer::brewer.pal(n = length(uniqueClasses), name = "Set1")
    }else{
      trueUMAPcolors <- c(RColorBrewer::brewer.pal(n = 8, name = "Set1"),
                          RColorBrewer::brewer.pal(n = length(uniqueClasses) - 8, name = "Set2"))
    }
    
  }else{
    trueUMAPcolors <- UMAPcolors
  }
  
  
  if(is.na(mainUMAPtitle)){
    UMAPtitle <- "UMAP"
  }else{
    UMAPtitle <- mainUMAPtitle
  }
  
  data.umap <- umap::umap(d = UMAPdata,
                          config = umapdefault,
                          method = "naive",
                          preserve.seed = TRUE)
  
  umapxlab <- paste("UMAP dimension ", as.character(UMAPdimension1), sep = "")
  umapylab <- paste("UMAP dimension ", as.character(UMAPdimension2), sep = "")
  
  plot(x = data.umap$layout[,UMAPdimension1],
       y = data.umap$layout[,UMAPdimension2],
       pch = 21,
       cex = cexPoints,
       col = "black",
       main = mainUMAPtitle,
       xlab = umapxlab,
       ylab = umapylab,
       xlim = range(pretty(data.umap$layout[,1])),
       ylim = range(pretty(data.umap$layout[,2])))
  
  for(i in 1:length(uniqueClasses)){
    
    iclass <- uniqueClasses[i]
    icolor <- trueUMAPcolors[i]
    ibool <- UMAPlabels == iclass
    ix <- data.umap$layout[ibool,UMAPdimension1]
    iy <- data.umap$layout[ibool,UMAPdimension2]
    points(x = ix,
           y = iy,
           pch = 21,
           col = "black",
           bg = icolor,
           cex = cexPoints)
    
  }
  
  legend(x = legPos,
         legend = c(uniqueClasses),
         pch = 21,
         col = "black",
         pt.bg = trueUMAPcolors,
         cex = legSize,
         inset = legInset)
  
  return(data.umap)
  
}

## DBSCAN():

# 

DBSCAN <- function(myDataSet,
                   automatic = TRUE,
                   legPos = "topleft",
                   legInset = c(0, 0),
                   legSize = 1,
                   cexPoints = 1){
  
  randomNColorSet <- function(ncolors){
    
    if(!("package:RColorBrewer" %in% search())){
      library(RColorBrewer)
    }
    
    qual_col_pals <- RColorBrewer::brewer.pal.info[brewer.pal.info$category == 'qual',]
    col_vector <- unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
    col_vector <- sample(col_vector, ncolors)
    return(col_vector)
    
  }
  
  newElbowMethod2 <- function(numericalVector,
                              wannaPlot = TRUE){
    
    numericalVector <- numericalVector[order(numericalVector, decreasing = TRUE)]
    
    dy <- numericalVector[length(numericalVector)] - numericalVector[1]
    dx <- length(numericalVector) - 1
    originalSlope <- dy/dx 
    
    newElbowRes <- c()
    
    for(i in 1:(length(numericalVector))){
      intercept <- numericalVector[i] - (originalSlope * i)
      newElbowRes <- append(x = newElbowRes, values = intercept)
    }
    
    finalIndex <- which.min(newElbowRes)
    finalValue <- numericalVector[finalIndex]
    
    if(wannaPlot){
      
      repBlack <- rep("black", length(numericalVector))
      
      plot(x = 1:length(numericalVector),
           y = numericalVector,
           xlim = range(pretty(1:length(numericalVector))),
           ylim = range(pretty(numericalVector)),
           xlab = "x",
           ylab = "y",
           main = "Elbow method analysis (elbow point indicated)",
           pch = 21,
           col = "black",
           bg = repBlack,
           cex = 0.7)
      
      points(x = c(length(numericalVector), 1),
             y = c(numericalVector[length(numericalVector)], numericalVector[1]),
             type = "l",
             col = "forestgreen",
             lty = 1,
             lwd = 2)
      
      y2 <- newElbowRes[finalIndex] + originalSlope * length(numericalVector)
      newdy <- numericalVector[length(numericalVector)] - y2
      y1 <- numericalVector[1] - newdy
      
      points(x = rev(c(length(numericalVector), 1)),
             y = c(y1, y2),
             type = "l",
             col = "forestgreen",
             lty = 1,
             lwd = 2)
      points(x = finalIndex,
             y = numericalVector[finalIndex],
             cex = 0.7,
             col = "red",
             bg = "red",
             pch = 21)
      
      legend(x = "topright",
             legend = c(paste("Calculated elbow point index: ",
                              as.character(round(x = finalIndex, digits = 4)),
                              sep = ""),
                        paste("Calculated elbow point value: ",
                              as.character(round(x = finalValue, digits = 4)),
                              sep = "")),
             inset = c(0.02, 0.02))
      
    }
    
    return(list("interceptors" = newElbowRes,
                "finalIndex" = finalIndex,
                "finalValue" = finalValue))
    
  }
  
  if(!("package:dbscan" %in% search())){
    library(dbscan)
  }
  
  chosenK <- 2 * ncol(myDataSet)
  kdist <- dbscan::kNNdist(x = myDataSet, k = chosenK)
  kdist <- kdist[order(kdist, decreasing = TRUE)]
  names(kdist) <- 1:length(kdist)
  
  if(automatic){
    elbowResults <- newElbowMethod2(numericalVector = kdist, wannaPlot = TRUE)
    chosenEps <- elbowResults[["finalValue"]]
  }else{
    plot(x = 1:length(kdist),
         y = kdist,
         xlim = range(pretty(1:length(kdist))),
         ylim = range(pretty(kdist)),
         xlab = "k",
         ylab = "kNN distance",
         main = paste("kNN distance plot (k = ", as.character(chosenK), ")", sep = ""),
         pch = 21,
         cex = 0.8,
         col = "black",
         bg = "black")
    
    print(kdist)
    
    chosenEps <- as.numeric(readline(prompt = "Enter epsilon: "))
  }
  
  dbres <- fpc::dbscan(data = myDataSet, eps = chosenEps, MinPts = chosenK)
  
  if(0 %in% dbres$cluster){
    dbresCluster <- dbres$cluster + 1
  }else{
    dbresCluster <- dbres$cluster
  }
  
  selectedColors <- randomNColorSet(ncolors = max(dbresCluster))
  clustIntoColors <- sapply(X = dbresCluster, FUN = function(x) selectedColors[x])
  
  plot(x = myDataSet[,1],
       y = myDataSet[,2],
       xlim = range(pretty(myDataSet[,1])),
       ylim = range(pretty(myDataSet[,2])),
       xlab = "x",
       ylab = "y",
       main = "DBSCAN analysis (predicted groups)",
       pch = 21,
       col = "black",
       bg = clustIntoColors,
       cex = cexPoints)
  
  legend(x = legPos,
         legend = sprintf("DBSCAN cluster %s", 1:max(dbresCluster)),
         pch = 21,
         col = "black",
         pt.bg = selectedColors,
         inset = legInset,
         cex = legSize)
  
  if(automatic){
    dblist <- list("elbowResults" = elbowResults,
                   "kNNdist" = kdist,
                   "DBSCAN" = dbres)
  }else{
    dblist <- list("kNNdist" = kdist,
                   "DBSCAN" = dbres)
  }
  
  return(dblist)
  
}

## 

# 

howManyLoops <- function(nfeat, wantedLoops){
  prob <- seq(1 - 0.001, 0.001, by = -0.001)
  iterationsVector <- c()
  for(i in 1:length(prob)){
    remaining <- c()
    remember <- nfeat
    k <- 1
    while(remember > 1){
      remember <- floor(remember * prob[i])
      remaining <- append(x = remaining, values = remember)
    }
    iterationsVector <- append(x = iterationsVector, values = length(remaining))
  }
  
  return(prob[iterationsVector == wantedLoops])
}

## RFClassEx():

# 

RFClassEx <- function(rfObject,
                      trueClassesOrder,
                      classesColors,
                      cexMain = 1.4,
                      cexAxisNumbers = 1.3,
                      cexPlotAxis = 1.2,
                      tiltAngle = 40,
                      cexLabels = 1.2,
                      cexLeg = 1.3,
                      legInset = c(0.02, 0.02),
                      adjText = c(1, 1),
                      yLabelsPosition = -0.01){
  
  if(!("package:randomForest" %in% base::search())){
    catMe <- paste("randomForest library wasn't attached. Attaching library...\n")
    cat(catMe)
    library(randomForest)
    catMe <- paste("Done.\n")
    cat(catMe)
  }
  
  namedColorVector <- classesColors
  names(namedColorVector) <- trueClassesOrder
  
  impArr <- rfObject[["importance"]][, trueClassesOrder]
  impArr[impArr < 0] <- 0
  nFeatures <- nrow(impArr)
  
  barplotData <- t(impArr[order(colSums(t(impArr)),decreasing = TRUE),])
  
  percentTableValues <- t(apply(X = t(barplotData),
                                MARGIN = 1,
                                FUN = function(x) (x / sum(x)) * 100))
  
  barplot(height = barplotData,
          xaxt = "n",
          col = classesColors,
          ylab = "Class mean decrease accuracy (importance value)",
          ylim = range(pretty(c(0, max(t(apply(X = impArr,
                                               MARGIN = 1,
                                               FUN = cumsum)))))),
          yaxt = "n",
          main = "Class feature importance barplot",
          cex.main = cexMain,
          cex.lab = cexPlotAxis)
  
  axis(side = 2,
       at = pretty(c(0, max(t(apply(X = impArr, MARGIN = 1, FUN = cumsum))))),
       labels = pretty(c(0, max(t(apply(X = impArr, MARGIN = 1, FUN = cumsum))))),
       las = 1,
       cex.axis = cexAxisNumbers)
  
  spaceBetweenBars <- 0.2
  barWidth <- 1
  root <- (spaceBetweenBars + barWidth/2)
  centersDistance <- (spaceBetweenBars + barWidth)
  xAxis <- c( root, (root + (1:(ncol(barplotData) - 1) * centersDistance)) )
  
  text(x = xAxis,
       y = yLabelsPosition,
       labels = colnames(barplotData),
       xpd = NA, # allows external text
       cex = cexLabels,
       srt = tiltAngle, # tilt angle
       adj = adjText
       )
  
  legend(x = "topright",
         legend = trueClassesOrder,
         col = "black",
         pch = 22,
         pt.bg = classesColors,
         cex = cexLeg,
         inset = legInset)
  
  return(list("barplotData" = barplotData,
              "percentTable" = percentTableValues))
  
}

## fortuna():

# 

fortuna <- function(dataset,
                    groups, # as.factor(groups)
                    treeNumber = 1000,
                    retentionByProp = FALSE,
                    retentionProportion = 0.8,
                    retentionLoops = 30,
                    chosenIterationsNumber = 30,
                    # NAsubstitution = "none", # "none", "sampling", "zero"
                    isBinaryApproach = FALSE,
                    combBinaryClassMethod = "elbow", # "k", "elbow", "p"
                    chosenPValue = 0.05,
                    pAdjMethod = "fdr",
                    kFeats = 20,
                    isElbowPlot = TRUE){
  
  if(!("package:randomForest" %in% base::search())){
    library(randomForest)
  }
  
  if(!(retentionByProp)){
    
    howManyLoops <- function(nfeat, wantedLoops){
      prob <- seq(1 - 0.001, 0.001, by = -0.001)
      iterationsVector <- c()
      for(i in 1:length(prob)){
        remaining <- c()
        remember <- nfeat
        while(remember > 1){
          remember <- floor(remember * prob[i])
          remaining <- append(x = remaining, values = remember)
        }
        iterationsVector <- append(x = iterationsVector, values = length(remaining))
      }
      
      return(prob[iterationsVector == wantedLoops])
      
    }
    
    retentionProportion <- howManyLoops(nfeat = ncol(dataset),
                                        wantedLoops = retentionLoops)[1]
    if(is.na(retentionProportion)){
      cat(paste("The number of features in the chosen data set is relatively ",
                "small. A single feature will be eliminated by step instead.\n",
                sep = ""))
      retentionProportion <- 0.99
      chosenIterationsNumber <- ncol(dataset)
    }
    
  }
  
  fortunaRandomizer <- function(dat,
                                wannaCBind = TRUE){
    
    rndmArr <- apply(X = dat,
                     MARGIN = 2,
                     FUN = function(x) sample(x))
    
    colnames(rndmArr) <- sprintf("rndm.%s", colnames(dat))
    rownames(rndmArr) <- sprintf("rndm.%s", rownames(dat))
    
    if(wannaCBind){
      savedRows <- c(rownames(dat), rownames(rndmArr))
      savedCols <- c(colnames(dat), colnames(rndmArr))
      rndmArr <- cbind(dat, rndmArr)
      if(is.null(rownames(rndmArr))){
        rownames(rndmArr) <- savedRows
      }
      if(is.null(colnames(rndmArr))){
        colnames(rndmArr) <- savedCols
      }
      return(rndmArr)
    }else{
      return(rndmArr)
    }
    
  }
  
  rrfIterator <- function(innerDataSet,
                          innerGroups,
                          innerTreeNumber,
                          innerRetentionProportion,
                          innerRetentionLoops,
                          # innerNAsubstitution,
                          innerIsElbowPlot
  ){
    
    importanceMatrix <- matrix(data = 0,
                               nrow = ncol(innerDataSet),
                               ncol = 8)
    rownames(importanceMatrix) <- colnames(innerDataSet)
    colnames(importanceMatrix) <- c("feature.index",
                                    "importance",
                                    "normalized.importance",
                                    "standard.cumulative",
                                    "binomial.pvalue",
                                    "adj.pvalue",
                                    "y0.elbow.method",
                                    "is.elbow.method")
    importanceMatrix[,"feature.index"] <- 1:nrow(importanceMatrix)
    
    iterations <- 1
    
    innerChosenIterationsNumber <- 0
    remember <- ncol(innerDataSet)
    while(remember > 1){
      remember <- floor(remember * innerRetentionProportion)
      innerChosenIterationsNumber <- innerChosenIterationsNumber + 1
    }
    
    hitArr <- matrix(data = NA,
                     nrow = innerChosenIterationsNumber * 2  * innerRetentionLoops,
                     ncol = ncol(dataset),
                     dimnames = list(NULL, colnames(dataset)))
    
    while(iterations <= innerRetentionLoops){
      
      cat(paste("Iteration for recursive feature elimination: ",
                as.character(iterations),
                ".\n",
                sep = ""))
      tempDataSet <- innerDataSet
      
      retentionLoop <- 1
      
      allFeatsEliminated <- c()
      
      while(!(is.null(ncol(tempDataSet)))){
        
        rndm_tempDataSet <- fortunaRandomizer(dat = tempDataSet,
                                              wannaCBind = TRUE)
        
        rndm_tempRF <- randomForest(x = rndm_tempDataSet,
                                    y = innerGroups,
                                    importance = TRUE,
                                    ntree = innerTreeNumber)
        
        rndm_Imp <- rndm_tempRF[["importance"]][,"MeanDecreaseAccuracy"]
        
        tempFeats <- colnames(tempDataSet)
        
        boolRndm <- grepl(pattern = "rndm",
                          x = names(rndm_Imp),
                          fixed = TRUE)
        
        for(i in 1:length(tempFeats)){
          
          ifeat <- tempFeats[i]
          iboolBoth <- grepl(pattern = ifeat,
                             x = names(rndm_Imp),
                             fixed = TRUE)
          iboolOriginal <- !(boolRndm) & iboolBoth
          iboolRndm <- boolRndm & iboolBoth
          ihitOrNot <- as.numeric(rndm_Imp[iboolOriginal] > rndm_Imp[iboolRndm])
          hitArr[which(is.na(hitArr[,ifeat]))[1],ifeat] <- ihitOrNot
          
        }
        
        tempRF <- randomForest(x = tempDataSet,
                               y = innerGroups,
                               importance = TRUE,
                               ntree = innerTreeNumber)
        
        tempImportance <- tempRF$importance
        
        vecImp <- tempImportance[,"MeanDecreaseAccuracy"]
        
        importanceMatrix[rownames(tempImportance),"importance"] <-
          importanceMatrix[rownames(tempImportance),"importance"] + vecImp
        
        newOrder <- order(vecImp, decreasing = TRUE)
        tempImportance <- tempImportance[newOrder,]
        
        retention <- floor(nrow(tempImportance) * innerRetentionProportion)
        cat(paste("Retained features (iteration: ",
                  as.character(iterations),
                  "; retention loop: ",
                  as.character(retentionLoop),
                  "): ",
                  as.character(retention),
                  ".\n",
                  sep = ""))
        
        featsRetained <- rownames(tempImportance)[1:retention]
        
        featsEliminated <- rownames(tempImportance)[!(rownames(tempImportance) %in% featsRetained)]
        
        allFeatsEliminated <- append(x = allFeatsEliminated,
                                     values = featsEliminated)
        
        for(i in 1:length(featsRetained)){
          ifeatRetained <- featsRetained[i]
          iindex <- which(is.na(hitArr[,ifeatRetained]))[1]
          hitArr[iindex, ifeatRetained] <- 1
        }
        
        for(i in 1:length(allFeatsEliminated)){
          ifeatEliminated <- allFeatsEliminated[i]
          iindex <- which(is.na(hitArr[,ifeatEliminated]))[1]
          hitArr[iindex, ifeatEliminated] <- 0
        }
        
        tempDataSet <- tempDataSet[,featsRetained]
        
        retentionLoop <- retentionLoop + 1
        
      }
      
      iterations <- iterations + 1
      
    }
    
    # if(innerNAsubstitution == "zero"){
    #   hitArr[is.na(hitArr)] <- 0
    # }
    # if(innerNAsubstitution == "sampling"){
    #   for(i in 1:ncol(hitArr)){
    #     ibool <- is.na(hitArr[,i])
    #     ihit <- hitArr[!ibool, i]
    #     isample <- sample(x = ihit, size = sum(ibool), replace = TRUE)
    #     hitArr[ibool, i]<- isample
    #   }
    # }
    # if(innerNAsubstitution == "none"){
    #   
    # }
    
    for(i in 1:ncol(hitArr)){
      
      ibool <- is.na(hitArr[,i])
      ihit <- hitArr[!ibool, i]
      isample <- sample(x = ihit, size = sum(ibool), replace = TRUE)
      hitArr[ibool, i]<- isample
      
    }
    
    hitArrSize <- prod(dim(hitArr))
    totalHits <- sum(hitArr, na.rm = TRUE) # na.rm
    pHit <- totalHits / hitArrSize
    
    allPValues <- apply(X = hitArr,
                        MARGIN = 2,
                        FUN = function(x) binom.test(x = sum(x, na.rm = TRUE), # na.rm
                                                     n = length(x), # No na.omit()
                                                     p = pHit,
                                                     alternative = "greater")$p.value)
    
    importanceMatrix[, "binomial.pvalue"] <- allPValues[rownames(importanceMatrix)]
    importanceMatrix[, "adj.pvalue"] <- p.adjust(p = allPValues[rownames(importanceMatrix)],
                                                 method = pAdjMethod)
    
    orderMatrix <- order(importanceMatrix[,"importance"], decreasing = TRUE)
    importanceMatrix <- importanceMatrix[orderMatrix,]
    
    boolOrdGreat <- importanceMatrix[,"importance"] > 0
    boolOrdLess <- importanceMatrix[,"importance"] < 0
    
    sumGreat <- sum(importanceMatrix[boolOrdGreat,"importance"])
    sumLess <- sum(importanceMatrix[boolOrdLess,"importance"])
    
    importanceMatrix[boolOrdGreat,"normalized.importance"] <-
      importanceMatrix[boolOrdGreat,"importance"] / sumGreat
    importanceMatrix[boolOrdLess,"normalized.importance"] <-
      -(importanceMatrix[boolOrdLess,"importance"] / sumLess)
    
    importanceMatrix[,"standard.cumulative"] <- cumsum(importanceMatrix[,"normalized.importance"])
    
    # Elbow method on feature importance (positive importances only):
    
    positiveImp <- rownames(importanceMatrix)[importanceMatrix[,"importance"] >= 0]
    nPositiveImp <- length(positiveImp)
    slopeCalculation_x <- c(1, nPositiveImp)
    slopeCalculation_y <- c(max(importanceMatrix[positiveImp,"importance"]),
                            min(importanceMatrix[positiveImp,"importance"]))
    
    slope <- (slopeCalculation_y[2] - slopeCalculation_y[1]) /
      (slopeCalculation_x[2] - slopeCalculation_x[1])
    interceptorsPositive <- c()
    for(j in 1:nPositiveImp){
      jx <- j
      jy <- importanceMatrix[positiveImp[j],"importance"]
      jinterceptor <- jy - jx * slope
      interceptorsPositive <- append(x = interceptorsPositive, values = jinterceptor)
    }
    
    importanceMatrix[,"y0.elbow.method"] <- c(interceptorsPositive,
                                              rep(NA, (nrow(importanceMatrix) - nPositiveImp)))
    importanceMatrix[,"is.elbow.method"] <- c(as.numeric(1:nPositiveImp < 
                                                           which.min(interceptorsPositive)),
                                              rep(0, (nrow(importanceMatrix) - nPositiveImp)))
    
    if(innerIsElbowPlot){
      
      if(length(unique(as.character(innerGroups))) == 2){
        
        if(unique(as.character(innerGroups))[1] == "Other" &
           unique(as.character(innerGroups))[2] != "Other"){
          firstClass <- unique(as.character(innerGroups))[2]
          secondClass <- unique(as.character(innerGroups))[1]
        }
        if(unique(as.character(innerGroups))[2] == "Other" &
           unique(as.character(innerGroups))[1] != "Other"){
          firstClass <- unique(as.character(innerGroups))[1]
          secondClass <- unique(as.character(innerGroups))[2]
        }
        if(unique(as.character(innerGroups))[1] != "Other" &
           unique(as.character(innerGroups))[2] != "Other"){
          firstClass <- unique(as.character(innerGroups))[1]
          secondClass <- unique(as.character(innerGroups))[2]
        }
        
        elbowPlotTitle <- paste("Elbow method on feature importance ('",
                                firstClass,
                                "' vs. '",
                                secondClass,
                                "')",
                                sep = "")
      }else{
        elbowPlotTitle <- paste("Elbow method on feature importance",
                                sep = "")
      }
      
      plot(x = 1:sum(importanceMatrix[,"is.elbow.method"]),
           y = importanceMatrix[1:sum(importanceMatrix[,"is.elbow.method"]),
                                "normalized.importance"],
           xlim = range(pretty(c(1,nrow(importanceMatrix)))),
           xaxt = "n",
           ylim = range(pretty(importanceMatrix[,"normalized.importance"])),
           xlab = "Feature index",
           ylab = "Random forest importance value",
           main = elbowPlotTitle,
           type = "l",
           col = "red",
           lwd = 2.5)
      
      axis(side = 1,
           at = unique(as.integer(pretty(c(1,nrow(importanceMatrix))))),
           labels = unique(as.integer(pretty(c(1,nrow(importanceMatrix)))))
      )
      
      points(x = sum(importanceMatrix[,"is.elbow.method"]):nrow(importanceMatrix),
             y = importanceMatrix[sum(importanceMatrix[,"is.elbow.method"]):nrow(importanceMatrix),
                                  "normalized.importance"],
             type = "l",
             col = "royalblue3",
             lwd = 2.5)
      
      legend(x = "topright",
             legend = c("Features selected",
                        "Features excluded"),
             inset = c(0.02, 0.04),
             pch = 21,
             col = "black",
             pt.bg = c("red", "royalblue3"),
             cex = 1.3)
      
    }
    
    return(list("impArr" = importanceMatrix,
                "hitArr" = hitArr))
    
  }
  
  if(length(unique(as.character(groups))) == 2){
    isBinaryApproach <- FALSE
  }
  
  if(!(isBinaryApproach)){
    
    cat("\nNon-binary feature selection and classification approach chosen.\n")
    
    binaryImpMatrix <- rrfIterator(innerDataSet = dataset,
                                   innerGroups = groups,
                                   innerTreeNumber = treeNumber,
                                   # innerNAsubstitution = NAsubstitution,
                                   innerRetentionProportion = retentionProportion,
                                   innerRetentionLoops = retentionLoops,
                                   innerIsElbowPlot = isElbowPlot
    )
    
    if(combBinaryClassMethod == "elbow"){
      chosenFeatures <-
        rownames(binaryImpMatrix[["impArr"]])[as.logical(binaryImpMatrix[["impArr"]][,"is.elbow.method"])]
    }
    if(combBinaryClassMethod == "p"){
      chosenFeatures <-
        rownames(binaryImpMatrix[["impArr"]])[binaryImpMatrix[["impArr"]][,"adj.pvalue"] <= chosenPValue]
    }
    if(combBinaryClassMethod == "k"){
      chosenFeatures <- rownames(binaryImpMatrix[["impArr"]])[1:kFeats]
    }
    
    finalRF <- randomForest(x = dataset[,chosenFeatures],
                            y = groups,
                            ntree = treeNumber,
                            importance = TRUE,
                            proximity = TRUE)
    
    return(list("importance.matrix" = binaryImpMatrix,
                "selected.features" = chosenFeatures,
                "RF.classifier" = finalRF)
    )
    
  }else{
    
    cat("\nBinary feature selection and classification approach chosen.\n")
    
    listOfBinaryClassifiers <- list()
    allChosenFeatures <- c()
    
    for(i in 1:nlevels(groups)){
      
      iclass <- unique(as.character(groups))[i]
      igroups <- as.character(groups)
      igroups[igroups != iclass] <- "Other"
      igroups <- as.factor(igroups)
      
      cat(paste("\nChosen class in binary procedure: '", iclass, "'.\n", sep = ""))
      
      ibinaryImpMatrix <- rrfIterator(innerDataSet = dataset,
                                      innerGroups = igroups,
                                      innerTreeNumber = treeNumber,
                                      # innerNAsubstitution = NAsubstitution,
                                      innerRetentionProportion = retentionProportion,
                                      innerRetentionLoops = retentionLoops,
                                      innerIsElbowPlot = isElbowPlot
      )
      
      if(combBinaryClassMethod == "elbow"){
        ichosenFeatures <-
          rownames(ibinaryImpMatrix[["impArr"]])[as.logical(ibinaryImpMatrix[["impArr"]][,"is.elbow.method"])]
      }
      if(combBinaryClassMethod == "p"){
        ichosenFeatures <-
          rownames(ibinaryImpMatrix[["impArr"]])[ibinaryImpMatrix[["impArr"]][,"adj.pvalue"] <= chosenPValue]
      }
      if(combBinaryClassMethod == "k"){
        ichosenFeatures <- rownames(ibinaryImpMatrix[["impArr"]])[1:kFeats]
      }
      
      allChosenFeatures <- append(x = allChosenFeatures, values = ichosenFeatures)
      
      ibinaryRF <- randomForest(x = dataset[,ichosenFeatures],
                                y = igroups,
                                ntree = treeNumber,
                                importance = TRUE,
                                proximity = TRUE)
      
      listOfBinaryClassifiers[[iclass]] <- list("importance.matrix" = ibinaryImpMatrix,
                                                "chosen.features" = ichosenFeatures,
                                                "RF.classifier" = ibinaryRF)
      
    }
    
    allChosenFeatures <- unique(allChosenFeatures)
    
    finalRF <- randomForest(x = dataset[, allChosenFeatures],
                            y = groups,
                            ntree = treeNumber,
                            importance = TRUE,
                            proximity = TRUE)
    
    return(list("binary.classifiers" = listOfBinaryClassifiers,
                "selected.features" = allChosenFeatures,
                "RF.classifier" = finalRF))
    
  }
  
}

## wrapperCholestasis2():

# 

wrapperCholestasis2 <- function(startData,
                                classColumn,
                                defaultGrid = NULL,
                                crossValidation,
                                bootSamples = 100,
                                chosenAlgorithm,
                                RFchosenNTree = 1000){
  
  ## Libraries loaded: checked
  
  if(!("package:caret" %in% base::search())){
    library(caret)
  }
  if(!("package:randomForest" %in% base::search())){
    library(randomForest)
  }
  if(!("package:adabag" %in% base::search())){
    library(adabag)
  }
  if(!("package:xgboost" %in% base::search())){
    library(xgboost)
  }
  if(!("package:e1071" %in% base::search())){
    library(e1071)
  }
  if(!("package:MASS" %in% base::search())){
    library(MASS)
  }
  
  ## Cross-validation method selection: checked
  
  if(crossValidation == "boot"| crossValidation == "bootstrap"){
    
    crossValidation <- "bootstrap"
    trainC <- trainControl(method = "boot",
                           number = bootSamples,
                           classProbs = TRUE,
                           allowParallel = FALSE)
  }
  if(crossValidation == "LOOCV"){
    trainC <- trainControl(method = "LOOCV",
                           classProbs = TRUE)
  }
  
  ## Empty variables to save classifiers results:
  
  accVector <- c()
  featsList <- list()
  
  ## Total number of variables:
  
  allFeats <- colnames(startData)
  allFeats <- allFeats[-which(allFeats == classColumn)]
  lenFeats <- length(allFeats)
  
  ## 
  
  keepAddingFeats <- c()
  
  a <- 1
  
  ##
  
  if(chosenAlgorithm == "rf"){
    algorithmCompleteName <- "random forest"
  }
  if(chosenAlgorithm == "ada" |
     chosenAlgorithm == "adaboost" |
     chosenAlgorithm == "AdaBoost.M1"){
    chosenAlgorithm <- "AdaBoost.M1"
    algorithmCompleteName <- "AdaBoost M1"
  }
  if(chosenAlgorithm == "xgb" |
     chosenAlgorithm == "xgbTree" |
     chosenAlgorithm == "xgboost"){
    chosenAlgorithm <- "xgbTree"
    algorithmCompleteName <- "Extreme Gradient Boosting"
  }
  if(chosenAlgorithm == "nb"){
    algorithmCompleteName <- "naive Bayes"
  }
  if(chosenAlgorithm == "knn"){
    algorithmCompleteName <- "k-nearest neighbors"
  }
  if(chosenAlgorithm == "svm" |
     chosenAlgorithm == "svmRadial"){
    chosenAlgorithm <- "svmRadial"
    algorithmCompleteName <- "support vector machines"
  }
  if(chosenAlgorithm == "lda"){
    chosenAlgorithm <- "lda"
    algorithmCompleteName <- "Linear Discriminant Analysis"
  }
  if(chosenAlgorithm == "qda"){
    chosenAlgorithm <- "qda"
    algorithmCompleteName <- "Quadratic Discriminant Analysis"
  }
  if(chosenAlgorithm == "glm" |
     chosenAlgorithm == "glmnet" |
     chosenAlgorithm == "logistic"){
    chosenAlgorithm <- "glmnet"
    algorithmCompleteName <- "Logistic Regression"
    
    logRegAccVec <- c()
    
    if(nlevels(startData[,classColumn]) > 2){
      logRegFamily <- "multinomial"
    }else{
      logRegFamily <- "binomial"
    }
    
  }
  
  if(chosenAlgorithm == "glmnet"){
    
    allComb2by2 <- combn(x = allFeats, m = 2)
    
    a <- 3 # It seems that logistic regression classifier depends on at least
    # 2 features to work.
    
    catMe <- paste("Sequential forward feature selection (on ",
                   algorithmCompleteName,
                   " algorithm): ",
                   "Current number of ", "features selected: ",
                   as.character(0), ".\n",
                   sep = "")
    cat(catMe)
    
    for(i in 1:ncol(allComb2by2)){
      
      icomb <- allComb2by2[,i]
      
      modelpreformula <- paste(classColumn, " ~ ",
                               paste(icomb, collapse = " + "), # !!!
                               sep = "")
      
      modelformula <- formula(modelpreformula)
      
      catMe <- paste("Formula that is going to be used: '",
                     as.character(modelpreformula), "'.\n",
                     sep = "")
      cat(catMe)
      
      isError <- TRUE
      
      while(isError){
        
        model <- try(train(modelformula,
                           data = startData,
                           method = chosenAlgorithm,
                           trControl = trainC,
                           family = logRegFamily))
        
        if(all(class(model) != c("train", "train.formula"))){
          catMe <- paste("An error has ocurred while generating the ",
                         algorithmCompleteName,
                         " classifier. ",
                         "Trying to build another classifier...\n",
                         sep = "")
          cat(catMe)
          isError <- TRUE
        }else{
          catMe <- paste("Classifier successfully generated.\n", sep = "")
          cat(catMe)
          isError <- FALSE
        }
        
      }
      
      logRegAccVec <- append(x = logRegAccVec, values = max(model$results$Accuracy))
      
    }
    
    accVector <- c(0, max(logRegAccVec))
    chosenLogRegFeats <- allComb2by2[,which.max(logRegAccVec)]
    keepAddingFeats <- append(x = keepAddingFeats,
                              values = chosenLogRegFeats)
    featsList[[1]] <- chosenLogRegFeats[1]
    featsList[[2]] <- chosenLogRegFeats
    
  }
  
  while(lenFeats >= a){
    
    catMe <- paste("Sequential forward feature selection (on ",
                   algorithmCompleteName,
                   " algorithm): ",
                   "Current number of ", "features selected: ",
                   as.character(a - 1), ".\n",
                   sep = "")
    cat(catMe)
    
    resetAccVec <- c()
    resetFeatsList <- list()
    
    setDiffFeats <- setdiff(x = allFeats, y = keepAddingFeats)
    
    for(i in 1:length(setDiffFeats)){
      
      ifeat <- setDiffFeats[i]
      
      catMe <- paste("Current feature selected: ", ifeat, ".\n", sep = "")
      cat(catMe)
      
      if(a == 1){
        modelpreformula <- paste(classColumn, " ~ ", ifeat, sep = "")
      }else{
        modelpreformula <- paste(classColumn, " ~ ",
                                 paste(keepAddingFeats, collapse = " + "), # !!!
                                 " + ",
                                 ifeat,
                                 sep = "")
      }
      
      modelformula <- formula(modelpreformula)
      
      catMe <- paste("Formula that is going to be used: '",
                     as.character(modelpreformula), "'.\n",
                     sep = "")
      cat(catMe)
      
      isError <- TRUE
      
      while(isError){
        
        # Depending on the algorithm, a set of specific arguments will be
        # necessary:
        
        if(chosenAlgorithm == "rf"){
          model <- try(train(modelformula,
                             data = startData,
                             method = chosenAlgorithm,
                             trControl = trainC,
                             ntree = RFchosenNTree # Specific for random forest!
          )
          )
        }
        if(chosenAlgorithm == "nb" |
           chosenAlgorithm == "knn" |
           chosenAlgorithm == "lda" |
           chosenAlgorithm == "qda"){
          
          model <- try(train(modelformula,
                             data = startData,
                             method = chosenAlgorithm,
                             trControl = trainC
          )
          )
          
        }
        if(chosenAlgorithm == "AdaBoost.M1" |
           chosenAlgorithm == "xgbTree" |
           chosenAlgorithm == "svmRadial"){
          
          if(is.null(defaultGrid)){
            
            model <- try(train(modelformula,
                               data = startData,
                               method = chosenAlgorithm,
                               trControl = trainC))
            
          }else{
            
            model <- try(train(modelformula,
                               data = startData,
                               method = chosenAlgorithm,
                               trControl = trainC,
                               tuneGrid = defaultGrid))
            
          }
          
        }
        if(chosenAlgorithm == "glmnet"){
          
          # # classes_logReg_colName <- strsplit(x = modelpreformula,
          # #                                    split = " ~ ",
          # #                                    fixed = TRUE)[[1]][1]
          # startData_logReg_colName <- strsplit(x = modelpreformula,
          #                                      split = " ~ ",
          #                                      fixed = TRUE)[[1]][2]
          # startData_logReg_colName <- strsplit(x = startData_logReg_colName,
          #                                      split = " + ",
          #                                      fixed = TRUE)[[1]]
          # # classes_logReg <- startData[,classes_logReg_colName]
          # startData_logReg <- as.matrix(startData[,startData_logReg_colName,
          #                                         drop = FALSE])
          
          model <- try(train(modelformula,
                             data = startData,
                             method = chosenAlgorithm,
                             trControl = trainC,
                             family = logRegFamily))
        }
        
        if(all(class(model) != c("train", "train.formula"))){
          catMe <- paste("An error has ocurred while generating the ",
                         algorithmCompleteName,
                         " classifier. ",
                         "Trying to build another classifier...\n",
                         sep = "")
          cat(catMe)
          isError <- TRUE
        }else{
          catMe <- paste("Classifier successfully generated.\n", sep = "")
          cat(catMe)
          isError <- FALSE
        }
        
      }
      
      if(crossValidation == "LOOCV"){
        
        # Maybe, I'll receive some errors from this code chunk. I've perceived
        # that not all models are structured the same way after creating them
        # by using caret
        
        resetAccVec <- append(x = resetAccVec, values = max(model$results$Accuracy))
        resetFeatsList[[i]] <- colnames(model$trainingData)[-1]
        
      }
      
      if(crossValidation == "bootstrap"){
        
        # predTrainClasses <- as.character(predict(object = model,
        #                                          newdata = startData[,-which(colnames(startData) == classColumn)]))
        # homeMadeAcc <- sum(predTrainClasses == as.character(startData[,classColumn])) /
        #   length(predTrainClasses)
        # resetAccVec <- append(x = resetAccVec, values = homeMadeAcc)
        # resetFeatsList[[i]] <- colnames(model$trainingData)[-1]
        resetAccVec <- append(x = resetAccVec, values = max(model$results$Accuracy))
        resetFeatsList[[i]] <- colnames(model$trainingData)[-1]
        
      }
      
    }
    
    whichMaxResetAccVec <- which.max(resetAccVec)[1]
    whichMaxFeats <- resetFeatsList[[whichMaxResetAccVec]]
    
    keepAddingFeats <- whichMaxFeats
    
    accVector <- append(x = accVector, values = max(resetAccVec)[1])
    featsList[[a]] <- keepAddingFeats
    
    a <- a + 1
    
    if(chosenAlgorithm == "qda" &
       ( a == min(table(startData[, classColumn]))[1] |
         a == nlevels(startData[, classColumn])
       )
    ){
      catMe <- paste("QDA from MASS library does not support data sizes that ",
                     "are more reduced than or equal to the number of features ",
                     "that are being used. Feature selection procedure will ",
                     "end here.\n",
                     sep = "")
      cat(catMe)
      a <- lenFeats + 1
    }
    
  }
  
  maxAccVector <- which.max(accVector)
  maxFeatsList <- featsList[[maxAccVector]]
  modelpreformula <- paste(classColumn,
                           " ~ ",
                           paste(maxFeatsList, collapse = " + "),
                           sep = "")
  modelformula <- as.formula(modelpreformula)
  
  # Implementar aqu el ltimo modelo, y llevrtelo
  
  isError <- TRUE
  
  while(isError){
    
    # Depending on the algorithm, a set of specific arguments will be
    # necessary:
    
    if(chosenAlgorithm == "rf"){
      model <- try(train(modelformula,
                         data = startData,
                         method = chosenAlgorithm,
                         trControl = trainC,
                         ntree = RFchosenNTree # Specific for random forest!
      )
      )
    }
    if(chosenAlgorithm == "nb" |
       chosenAlgorithm == "knn" |
       chosenAlgorithm == "lda" |
       chosenAlgorithm == "qda"){
      
      model <- try(train(modelformula,
                         data = startData,
                         method = chosenAlgorithm,
                         trControl = trainC
      )
      )
      
    }
    if(chosenAlgorithm == "AdaBoost.M1" |
       chosenAlgorithm == "xgbTree" |
       chosenAlgorithm == "svmRadial"){
      
      if(is.null(defaultGrid)){
        
        model <- try(train(modelformula,
                           data = startData,
                           method = chosenAlgorithm,
                           trControl = trainC))
        
      }else{
        
        model <- try(train(modelformula,
                           data = startData,
                           method = chosenAlgorithm,
                           trControl = trainC,
                           tuneGrid = defaultGrid))
        
      }
      
    }
    if(chosenAlgorithm == "glmnet"){
      
      model <- try(train(modelformula,
                         data = startData,
                         method = chosenAlgorithm,
                         trControl = trainC,
                         family = logRegFamily))
      
    }
    
    if(all(class(model) != c("train", "train.formula"))){
      catMe <- paste("An error has ocurred while generating ",
                     algorithmCompleteName,
                     " classifier. ",
                     "Trying to build another classifier...\n",
                     sep = "")
      cat(catMe)
      isError <- TRUE
    }else{
      catMe <- paste("Classifier successfully generated.\n", sep = "")
      cat(catMe)
      isError <- FALSE
    }
    
  }
  
  finalMain <- paste(toupper(substring(text = algorithmCompleteName,
                                       first = 1,
                                       last = 1)),
                     substring(text = algorithmCompleteName,
                               first = 2,
                               last = nchar(algorithmCompleteName)),
                     " wrapper algorithm results (classifier accuracy as a ",
                     "function of number of features)",
                     sep = "")
  
  plot(x = unlist(lapply(X = featsList, FUN = length)),
       y = accVector,
       main = finalMain,
       xlab = "Number of features",
       ylab = "Accuracy (proportion)",
       xlim = range(pretty(unlist(lapply(X = featsList, FUN = length)))),
       ylim = c(0, 1),
       cex = 1.1,
       pch = 21,
       col = "black",
       bg = "black")
  points(x = unlist(lapply(X = featsList, FUN = length)),
         y = accVector,
         type = "l",
         lty = 1,
         lwd = 2)
  
  return(list("finalClassifier" = model,
              "accVector" = accVector,
              "featsList" = featsList,
              "bestAccuracy" = max(accVector),
              "bestFeats" = maxFeatsList))
  
  
}

## 

# 

corMatrix <- function(dataMatrix,
                      colorRange = c("firebrick", "white", "forestgreen"),
                      defaultColorRange = 10,
                      corMethod = "cor",
                      adaptMargins = c(5.1, 4.1, 4.1, 3.1),
                      cexMain = 2,
                      mainTitle = "Correlation matrix between features",
                      fmtKey = "%.2f",
                      corTagsPos = 3,
                      corTagsOffset = 0.2,
                      corDigits = 2, 
                      corTagsCex = 0.9,
                      axisRowCex = 0.75,
                      axisColCex = 0.75,
                      argsLabelsCex = 0.55,
                      argsLabelsCorrection = 0.3){
  
  if(corMethod == "nlcor"){
    if(!("package:nlcor" %in% base::search())){
      library(nlcor)
    }
  }
  
  if(!("package:plot.matrix" %in% base::search())){
    library(plot.matrix)
  }
  
  allFeatPairs <- t(combn(x = colnames(dataMatrix), m = 2))
  allFeatPairs <- rbind(allFeatPairs,
                        cbind(colnames(dataMatrix),
                              colnames(dataMatrix)))
  corArr <- matrix(NA,
                   nrow = ncol(dataMatrix),
                   ncol = ncol(dataMatrix),
                   dimnames = list(colnames(dataMatrix),
                                   colnames(dataMatrix)))
  pValArr <- corArr
  
  for(i in 1:nrow(allFeatPairs)){
    
    firstElement <- allFeatPairs[i, 1]
    secondElement <- allFeatPairs[i, 2]
    xData <- dataMatrix[, firstElement]
    yData <- dataMatrix[, secondElement]
    
    if(corMethod == "cor"){
      corCoeff <- cor(x = xData, y = yData)
      corPVal <- cor.test(x = xData, y = yData)$p.value
    }
    if(corMethod == "nlcor"){
      corRes <- nlcor(x = xData, y = yData, plt = FALSE)
      corCoeff <- corRes$cor.estimate
      corPVal <- corRes$adjusted.p.value
    }
    
    corArr[firstElement, secondElement] <- corCoeff
    corArr[secondElement, firstElement] <- corCoeff
    pValArr[firstElement, secondElement] <- corPVal
    pValArr[secondElement, firstElement] <- corPVal
    
  }
  
  # par(mar = c(5.1, 
  #             4.1, 
  #             4.1, 
  #             2.1
  #             )
  #     ) # default parameters
  
  par(mar = adaptMargins)
  # adapt margins
  
  completeCorRange <- seq(from = 1,
                          to = -1,
                          length.out = defaultColorRange + 1)
  minCorArr <- min(corArr)
  colorRange <- rev(colorRange)
  newColorRange <-
    rev(colorRampPalette(colorRange)(defaultColorRange)[1:(which(completeCorRange <= minCorArr)[1] - 1)])
  
  plotCorArr <- plot(corArr,
                     col = newColorRange,
                     main = mainTitle,
                     cex.main = cexMain,
                     # text.cell = list(pos = corTagsPos, # tag up
                     #                  offset = corTagsOffset,
                     #                  # space fractions it has moved down when
                     #                  # pos = 3.
                     #                  cex = corTagsCex # tag size.
                     #                  ),
                     fmt.key = fmtKey,
                     # digits = 2,
                     xlab = "",
                     ylab = "",
                     axis.row = list(cex.axis = axisRowCex, las = 1),
                     axis.col = list(cex.axis = axisRowCex, las = 2))
  
  par(mar = adaptMargins)
  
  plotCorArr <- plot(corArr,
                     col = newColorRange,
                     main = mainTitle,
                     cex.main = cexMain,
                     text.cell = list(pos = corTagsPos, # tag up
                                      offset = corTagsOffset,
                                      # space fractions it has moved down when
                                      # pos = 3.
                                      cex = corTagsCex # tag size.
                     ),
                     # fmt.key = "%.2f",
                     digits = corDigits,
                     xlab = "",
                     ylab = "",
                     axis.row = list(cex.axis = axisRowCex, las = 1),
                     axis.col = list(cex.axis = axisColCex, las = 2))
  
  for (i in 1:nrow(corArr)){
    for (j in 1:ncol(corArr)){
      args <- plotCorArr$cell.text[[i,j]]
      if(pValArr[i, j] < 0.0001){
        args$labels <- paste("(< 0.0001)", sep = "")
      }else{
        args$labels <- paste0('(', fmt(pValArr[i, j], 4), ')')
      }
      args$cex <- argsLabelsCex
      args$y <- args$y - argsLabelsCorrection
      do.call(text, args)
    }
  }
  
  return(list("corArr" = corArr, "pvalue" = pValArr))
  
}

## 

# 

plotClusterComb <- function(combResList,
                            dat,
                            classVec,
                            chosenCor = "pearson",
                            namedColorVector,
                            cexPoint = 3,
                            cexTitle = 2.75,
                            cexAxesLabels = 1.8,
                            cexAxesMarks = 2,
                            legPositions = NULL,
                            isLeg = TRUE,
                            legCex = 1.75,
                            legInset = c(0, 0.02),
                            setDir,
                            chosenWidth = 1200,
                            chosenHeight = 800,
                            legPointsCex = 2.5){
  
  if(chosenCor == "nlcor"){
    if(!("package:nlcor" %in% base::search())){
      library(nlcor)
    }
  }
  
  allDirs <- sprintf(paste(setDir, "/%s", sep = ""),
                     names(combResList))
  
  if(is.null(legPositions)){
    mergedArr <- Reduce(function(...) merge(..., all = T), combResList)
    legPositions <- rep("top", nrow(mergedArr)) 
  }
  
  klegPos <- 1
  
  for(i in 1:length(combResList)){
    
    dir.create(allDirs[i])
    
    for(j in 1:nrow(combResList[[i]])){
      
      firstElement <- combResList[[i]][j, 1]
      secondElement <- combResList[[i]][j, 2]
      
      xData <- dat[, firstElement]
      yData <- dat[, secondElement]
      
      xPretty <- pretty(xData)
      yPretty <- pretty(yData)
      
      xAxisLab <- paste(firstElement,
                        " normalized abundance values",
                        sep = "")
      yAxisLab <- paste(secondElement,
                        " normalized abundance values",
                        sep = "")
      
      mainTitle <- paste("Abundance levels (",
                         firstElement,
                         ", ",
                         secondElement,
                         ")",
                         sep = "")
      
      jfileName <- paste(allDirs[i],
                         "/",
                         firstElement,
                         "_",
                         secondElement,
                         ".png",
                         sep = "")
      
      jpeg(file = jfileName,
           width = chosenWidth,
           height = chosenHeight)
      
      plot(x = xData,
           y = yData,
           xlim = range(xPretty),
           ylim = range(yPretty),
           xaxt = "n",
           yaxt = "n",
           xlab = xAxisLab,
           ylab = yAxisLab,
           pch = 21,
           cex = cexPoint,
           main = mainTitle,
           cex.main = cexTitle,
           col = "black",
           bg = namedColorVector[classVec],
           cex.lab = cexAxesLabels)
      axis(side = 1, at = xPretty, labels = xPretty, las = 1, cex.axis = cexAxesMarks)
      axis(side = 2, at = yPretty, labels = yPretty, las = 1, cex.axis = cexAxesMarks)
      
      if(chosenCor == "nlcor"){
        
        corRes <- nlcor(x = xData, y = yData, plt = FALSE)
        corCoeff <- round(corRes$cor.estimate, 4)
        corPValue <- corRes$adjusted.p.value
        
      }
      if(chosenCor == "pearson"){
        
        corCoeff <- round(cor(x = xData, y = yData), 4)
        corPValue <- cor.test(x = xData, y = yData)$p.value
        
      }
      
      corCoeffLeg <- paste("Correlation coefficient: ",
                           as.character(corCoeff),
                           sep = "")
      
      if(corPValue < 0.0001){
        corPValue <- "< 0.0001"
        corPValueLeg <- paste("Correlation p-value ",
                              corPValue,
                              sep = "")
      }else{
        corPValue <- round(corPValue, 4)
        corPValueLeg <- paste("Correlation p-value: ",
                              corPValue,
                              sep = "")
      }
      
      if(isLeg){
        
        legendText <- c(names(namedColorVector),
                        corCoeffLeg,
                        corPValueLeg)
        legendPtBg <- c(namedColorVector, NA, NA)
        legendPch <- c(rep(21, length(namedColorVector)), NA, NA)
        legendCol <- c(rep("black", length(namedColorVector)), NA, NA)
        legend(cex = legCex,
               pt.bg = legendPtBg,
               pch = legendPch,
               legend = legendText,
               x = legPositions[klegPos],
               pt.cex = legPointsCex,
               inset = legInset)
        
        klegPos <- klegPos + 1
        
      }
      
      dev.off()
      
    }
    
  }
  
}
